{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "a155FEl8mZS-"
   },
   "source": [
    "# TEXT PRE-PROCESSING"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "va8Bo3SPml__"
   },
   "source": [
    "## READ DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 191
    },
    "id": "IuTLetKtmojR",
    "outputId": "01ceca5b-41d6-4ba8-a63e-81f8e37d5165"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>time</th>\n",
       "      <th>review</th>\n",
       "      <th>formal-trans</th>\n",
       "      <th>aspek</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Intan Diah Pratiwi</td>\n",
       "      <td>3 hari yang lalu</td>\n",
       "      <td>Taman kota yang juga menyimpan nilai sejarah p...</td>\n",
       "      <td>Taman Tugu Pahlawan biasa dijadikan tempat ber...</td>\n",
       "      <td>fasilitas</td>\n",
       "      <td>netral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Wahyudi RJ</td>\n",
       "      <td>3 minggu yang lalu</td>\n",
       "      <td>Gowes seputar Tugu Pahlawan Surabaya</td>\n",
       "      <td>Bersepeda seputar Tugu Pahlawan Surabaya</td>\n",
       "      <td>fasilitas</td>\n",
       "      <td>netral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Centi_pade XxX</td>\n",
       "      <td>3 minggu yang lalu</td>\n",
       "      <td>Lokasi strategis tempat nya juga luas puas kal...</td>\n",
       "      <td>Lokasi strategis tempatnya juga luas puas kala...</td>\n",
       "      <td>fasilitas</td>\n",
       "      <td>positif</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Oktigaffelini P Yarisyah</td>\n",
       "      <td>4 minggu yang lalu</td>\n",
       "      <td>Tempat ini sangat cocok jika dijadikan wisata ...</td>\n",
       "      <td>Tetapi jika kesini siang siang jangan lupa baw...</td>\n",
       "      <td>fasilitas</td>\n",
       "      <td>negatif</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Qalbun Saliim</td>\n",
       "      <td>sebulan yang lalu</td>\n",
       "      <td>Tugu Pahlawan adalah salah satu tujuan wisata ...</td>\n",
       "      <td>Di dalam monumen ini, Anda bisa menjelajahi mu...</td>\n",
       "      <td>fasilitas</td>\n",
       "      <td>positif</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       name                time  ...      aspek    label\n",
       "0        Intan Diah Pratiwi    3 hari yang lalu  ...  fasilitas   netral\n",
       "1                Wahyudi RJ  3 minggu yang lalu  ...  fasilitas   netral\n",
       "2            Centi_pade XxX  3 minggu yang lalu  ...  fasilitas  positif\n",
       "3  Oktigaffelini P Yarisyah  4 minggu yang lalu  ...  fasilitas  negatif\n",
       "4             Qalbun Saliim   sebulan yang lalu  ...  fasilitas  positif\n",
       "\n",
       "[5 rows x 6 columns]"
      ]
     },
     "execution_count": 88,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd \n",
    "import numpy as np\n",
    "\n",
    "#baca data\n",
    "df = pd.read_excel('Copy of aspekFasilitas.xlsx')\n",
    "# df = df.drop(columns='ID')\n",
    "df = df.drop(columns='Unnamed: 0')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eCO-mpMkmgbx"
   },
   "source": [
    "## CLEANSING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "CDsqjmykn2Y5"
   },
   "outputs": [],
   "source": [
    "import string\n",
    "import re\n",
    "\n",
    "def cleansing(text): \n",
    "    text = [re.sub('[0-9]', '', i) for i in text] # remove numbering\n",
    "    text = [re.sub('[^a-zA-Z]', ' ', i) for i in text] # remove non alphabetical char\n",
    "    text = \"\".join([c for c in text if c not in string.punctuation]) # remove punct\n",
    "    text = text.replace('\\n',' ') # remove enter\n",
    "    return text\n",
    "\n",
    "# def remove_enter(text):\n",
    "#     text = text.replace('\\n',' ')\n",
    "#     return text\n",
    "\n",
    "df['cleansing'] = df['formal-trans'].apply(lambda x: cleansing(x))\n",
    "# df['cleansing'] = df['formal-trans'].apply(lambda x: cleansing(x))\n",
    "# df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vq0M_zS9n-ye"
   },
   "source": [
    "## CASE FOLDING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 335
    },
    "id": "aF-32w7AoBIm",
    "outputId": "9846aa1d-3b65-4633-c46c-d79a6cf659d1"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>time</th>\n",
       "      <th>review</th>\n",
       "      <th>formal-trans</th>\n",
       "      <th>aspek</th>\n",
       "      <th>label</th>\n",
       "      <th>cleansing</th>\n",
       "      <th>case_folding</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Intan Diah Pratiwi</td>\n",
       "      <td>3 hari yang lalu</td>\n",
       "      <td>Taman kota yang juga menyimpan nilai sejarah p...</td>\n",
       "      <td>Taman Tugu Pahlawan biasa dijadikan tempat ber...</td>\n",
       "      <td>fasilitas</td>\n",
       "      <td>netral</td>\n",
       "      <td>Taman Tugu Pahlawan biasa dijadikan tempat ber...</td>\n",
       "      <td>taman tugu pahlawan biasa dijadikan tempat ber...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Wahyudi RJ</td>\n",
       "      <td>3 minggu yang lalu</td>\n",
       "      <td>Gowes seputar Tugu Pahlawan Surabaya</td>\n",
       "      <td>Bersepeda seputar Tugu Pahlawan Surabaya</td>\n",
       "      <td>fasilitas</td>\n",
       "      <td>netral</td>\n",
       "      <td>Bersepeda seputar Tugu Pahlawan Surabaya</td>\n",
       "      <td>bersepeda seputar tugu pahlawan surabaya</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Centi_pade XxX</td>\n",
       "      <td>3 minggu yang lalu</td>\n",
       "      <td>Lokasi strategis tempat nya juga luas puas kal...</td>\n",
       "      <td>Lokasi strategis tempatnya juga luas puas kala...</td>\n",
       "      <td>fasilitas</td>\n",
       "      <td>positif</td>\n",
       "      <td>Lokasi strategis tempatnya juga luas puas kala...</td>\n",
       "      <td>lokasi strategis tempatnya juga luas puas kala...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Oktigaffelini P Yarisyah</td>\n",
       "      <td>4 minggu yang lalu</td>\n",
       "      <td>Tempat ini sangat cocok jika dijadikan wisata ...</td>\n",
       "      <td>Tetapi jika kesini siang siang jangan lupa baw...</td>\n",
       "      <td>fasilitas</td>\n",
       "      <td>negatif</td>\n",
       "      <td>Tetapi jika kesini siang siang jangan lupa baw...</td>\n",
       "      <td>tetapi jika kesini siang siang jangan lupa baw...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Qalbun Saliim</td>\n",
       "      <td>sebulan yang lalu</td>\n",
       "      <td>Tugu Pahlawan adalah salah satu tujuan wisata ...</td>\n",
       "      <td>Di dalam monumen ini, Anda bisa menjelajahi mu...</td>\n",
       "      <td>fasilitas</td>\n",
       "      <td>positif</td>\n",
       "      <td>Di dalam monumen ini  Anda bisa menjelajahi mu...</td>\n",
       "      <td>di dalam monumen ini  anda bisa menjelajahi mu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>kepoin dong</td>\n",
       "      <td>sebulan yang lalu</td>\n",
       "      <td>tempat bersejarah yg di rawat</td>\n",
       "      <td>tempat bersejarah yang dirawat</td>\n",
       "      <td>fasilitas</td>\n",
       "      <td>positif</td>\n",
       "      <td>tempat bersejarah yang dirawat</td>\n",
       "      <td>tempat bersejarah yang dirawat</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Erik Chosiin</td>\n",
       "      <td>sebulan yang lalu</td>\n",
       "      <td>Luas dan bersih . Bisa memepelajari sejarah ba...</td>\n",
       "      <td>Luas</td>\n",
       "      <td>fasilitas</td>\n",
       "      <td>netral</td>\n",
       "      <td>Luas</td>\n",
       "      <td>luas</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>super MOTO</td>\n",
       "      <td>sebulan yang lalu</td>\n",
       "      <td>INSIDER'S GUIDE / SURABAYAWisata Sejarah di Tu...</td>\n",
       "      <td>kawasan alun-alun yang berupa Fasilitas berupa...</td>\n",
       "      <td>fasilitas</td>\n",
       "      <td>positif</td>\n",
       "      <td>kawasan alun alun yang berupa Fasilitas berupa...</td>\n",
       "      <td>kawasan alun alun yang berupa fasilitas berupa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Ulung Tri Topan Putra Samodra</td>\n",
       "      <td>sebulan yang lalu</td>\n",
       "      <td>Salah satu objek wisata yg berada di pusat kot...</td>\n",
       "      <td>Salah satu objek wisata yang berada di pusat k...</td>\n",
       "      <td>fasilitas</td>\n",
       "      <td>netral</td>\n",
       "      <td>Salah satu objek wisata yang berada di pusat k...</td>\n",
       "      <td>salah satu objek wisata yang berada di pusat k...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Sembako Njungkir Harganya</td>\n",
       "      <td>sebulan yang lalu</td>\n",
       "      <td>Enak buat joging pagi</td>\n",
       "      <td>Enak buat lari pelan-pelan pagi</td>\n",
       "      <td>fasilitas</td>\n",
       "      <td>positif</td>\n",
       "      <td>Enak buat lari pelan pelan pagi</td>\n",
       "      <td>enak buat lari pelan pelan pagi</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            name  ...                                       case_folding\n",
       "0             Intan Diah Pratiwi  ...  taman tugu pahlawan biasa dijadikan tempat ber...\n",
       "1                     Wahyudi RJ  ...           bersepeda seputar tugu pahlawan surabaya\n",
       "2                 Centi_pade XxX  ...  lokasi strategis tempatnya juga luas puas kala...\n",
       "3       Oktigaffelini P Yarisyah  ...  tetapi jika kesini siang siang jangan lupa baw...\n",
       "4                  Qalbun Saliim  ...  di dalam monumen ini  anda bisa menjelajahi mu...\n",
       "5                    kepoin dong  ...                     tempat bersejarah yang dirawat\n",
       "6                   Erik Chosiin  ...                                               luas\n",
       "7                     super MOTO  ...  kawasan alun alun yang berupa fasilitas berupa...\n",
       "8  Ulung Tri Topan Putra Samodra  ...  salah satu objek wisata yang berada di pusat k...\n",
       "9      Sembako Njungkir Harganya  ...                    enak buat lari pelan pelan pagi\n",
       "\n",
       "[10 rows x 8 columns]"
      ]
     },
     "execution_count": 90,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Step 2: Case Folding \n",
    "def caseFolding(text): \n",
    "    text = text.lower()\n",
    "    return(text)\n",
    "\n",
    "df['case_folding'] = df['cleansing'].apply(lambda x: caseFolding(x))\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2P0mNwz1oOij"
   },
   "source": [
    "## TOKENIZING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 497
    },
    "id": "cdy6LK7boQY1",
    "outputId": "46725144-6408-4e6c-8565-e188878af335"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>time</th>\n",
       "      <th>review</th>\n",
       "      <th>formal-trans</th>\n",
       "      <th>aspek</th>\n",
       "      <th>label</th>\n",
       "      <th>cleansing</th>\n",
       "      <th>case_folding</th>\n",
       "      <th>tokenize</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Intan Diah Pratiwi</td>\n",
       "      <td>3 hari yang lalu</td>\n",
       "      <td>Taman kota yang juga menyimpan nilai sejarah p...</td>\n",
       "      <td>Taman Tugu Pahlawan biasa dijadikan tempat ber...</td>\n",
       "      <td>fasilitas</td>\n",
       "      <td>netral</td>\n",
       "      <td>Taman Tugu Pahlawan biasa dijadikan tempat ber...</td>\n",
       "      <td>taman tugu pahlawan biasa dijadikan tempat ber...</td>\n",
       "      <td>[taman, tugu, pahlawan, biasa, dijadikan, temp...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Wahyudi RJ</td>\n",
       "      <td>3 minggu yang lalu</td>\n",
       "      <td>Gowes seputar Tugu Pahlawan Surabaya</td>\n",
       "      <td>Bersepeda seputar Tugu Pahlawan Surabaya</td>\n",
       "      <td>fasilitas</td>\n",
       "      <td>netral</td>\n",
       "      <td>Bersepeda seputar Tugu Pahlawan Surabaya</td>\n",
       "      <td>bersepeda seputar tugu pahlawan surabaya</td>\n",
       "      <td>[bersepeda, seputar, tugu, pahlawan, surabaya]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Centi_pade XxX</td>\n",
       "      <td>3 minggu yang lalu</td>\n",
       "      <td>Lokasi strategis tempat nya juga luas puas kal...</td>\n",
       "      <td>Lokasi strategis tempatnya juga luas puas kala...</td>\n",
       "      <td>fasilitas</td>\n",
       "      <td>positif</td>\n",
       "      <td>Lokasi strategis tempatnya juga luas puas kala...</td>\n",
       "      <td>lokasi strategis tempatnya juga luas puas kala...</td>\n",
       "      <td>[lokasi, strategis, tempatnya, juga, luas, pua...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Oktigaffelini P Yarisyah</td>\n",
       "      <td>4 minggu yang lalu</td>\n",
       "      <td>Tempat ini sangat cocok jika dijadikan wisata ...</td>\n",
       "      <td>Tetapi jika kesini siang siang jangan lupa baw...</td>\n",
       "      <td>fasilitas</td>\n",
       "      <td>negatif</td>\n",
       "      <td>Tetapi jika kesini siang siang jangan lupa baw...</td>\n",
       "      <td>tetapi jika kesini siang siang jangan lupa baw...</td>\n",
       "      <td>[tetapi, jika, kesini, siang, siang, jangan, l...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Qalbun Saliim</td>\n",
       "      <td>sebulan yang lalu</td>\n",
       "      <td>Tugu Pahlawan adalah salah satu tujuan wisata ...</td>\n",
       "      <td>Di dalam monumen ini, Anda bisa menjelajahi mu...</td>\n",
       "      <td>fasilitas</td>\n",
       "      <td>positif</td>\n",
       "      <td>Di dalam monumen ini  Anda bisa menjelajahi mu...</td>\n",
       "      <td>di dalam monumen ini  anda bisa menjelajahi mu...</td>\n",
       "      <td>[di, dalam, monumen, ini, anda, bisa, menjelaj...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>kepoin dong</td>\n",
       "      <td>sebulan yang lalu</td>\n",
       "      <td>tempat bersejarah yg di rawat</td>\n",
       "      <td>tempat bersejarah yang dirawat</td>\n",
       "      <td>fasilitas</td>\n",
       "      <td>positif</td>\n",
       "      <td>tempat bersejarah yang dirawat</td>\n",
       "      <td>tempat bersejarah yang dirawat</td>\n",
       "      <td>[tempat, bersejarah, yang, dirawat]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Erik Chosiin</td>\n",
       "      <td>sebulan yang lalu</td>\n",
       "      <td>Luas dan bersih . Bisa memepelajari sejarah ba...</td>\n",
       "      <td>Luas</td>\n",
       "      <td>fasilitas</td>\n",
       "      <td>netral</td>\n",
       "      <td>Luas</td>\n",
       "      <td>luas</td>\n",
       "      <td>[luas]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>super MOTO</td>\n",
       "      <td>sebulan yang lalu</td>\n",
       "      <td>INSIDER'S GUIDE / SURABAYAWisata Sejarah di Tu...</td>\n",
       "      <td>kawasan alun-alun yang berupa Fasilitas berupa...</td>\n",
       "      <td>fasilitas</td>\n",
       "      <td>positif</td>\n",
       "      <td>kawasan alun alun yang berupa Fasilitas berupa...</td>\n",
       "      <td>kawasan alun alun yang berupa fasilitas berupa...</td>\n",
       "      <td>[kawasan, alun, alun, yang, berupa, fasilitas,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Ulung Tri Topan Putra Samodra</td>\n",
       "      <td>sebulan yang lalu</td>\n",
       "      <td>Salah satu objek wisata yg berada di pusat kot...</td>\n",
       "      <td>Salah satu objek wisata yang berada di pusat k...</td>\n",
       "      <td>fasilitas</td>\n",
       "      <td>netral</td>\n",
       "      <td>Salah satu objek wisata yang berada di pusat k...</td>\n",
       "      <td>salah satu objek wisata yang berada di pusat k...</td>\n",
       "      <td>[salah, satu, objek, wisata, yang, berada, di,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Sembako Njungkir Harganya</td>\n",
       "      <td>sebulan yang lalu</td>\n",
       "      <td>Enak buat joging pagi</td>\n",
       "      <td>Enak buat lari pelan-pelan pagi</td>\n",
       "      <td>fasilitas</td>\n",
       "      <td>positif</td>\n",
       "      <td>Enak buat lari pelan pelan pagi</td>\n",
       "      <td>enak buat lari pelan pelan pagi</td>\n",
       "      <td>[enak, buat, lari, pelan, pelan, pagi]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            name  ...                                           tokenize\n",
       "0             Intan Diah Pratiwi  ...  [taman, tugu, pahlawan, biasa, dijadikan, temp...\n",
       "1                     Wahyudi RJ  ...     [bersepeda, seputar, tugu, pahlawan, surabaya]\n",
       "2                 Centi_pade XxX  ...  [lokasi, strategis, tempatnya, juga, luas, pua...\n",
       "3       Oktigaffelini P Yarisyah  ...  [tetapi, jika, kesini, siang, siang, jangan, l...\n",
       "4                  Qalbun Saliim  ...  [di, dalam, monumen, ini, anda, bisa, menjelaj...\n",
       "5                    kepoin dong  ...                [tempat, bersejarah, yang, dirawat]\n",
       "6                   Erik Chosiin  ...                                             [luas]\n",
       "7                     super MOTO  ...  [kawasan, alun, alun, yang, berupa, fasilitas,...\n",
       "8  Ulung Tri Topan Putra Samodra  ...  [salah, satu, objek, wisata, yang, berada, di,...\n",
       "9      Sembako Njungkir Harganya  ...             [enak, buat, lari, pelan, pelan, pagi]\n",
       "\n",
       "[10 rows x 9 columns]"
      ]
     },
     "execution_count": 91,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Step 3: Tokenize\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "\n",
    "tokenizer = RegexpTokenizer(r'\\w+')\n",
    "df['tokenize'] = df['case_folding'].apply(lambda x: tokenizer.tokenize(x))\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2h7qPy1E5v6T",
    "outputId": "31e2dfa2-3535-4010-ed8b-7924f2154d5c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting Sastrawi\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/6f/4b/bab676953da3103003730b8fcdfadbdd20f333d4add10af949dd5c51e6ed/Sastrawi-1.0.1-py2.py3-none-any.whl (209kB)\n",
      "\r",
      "\u001b[K     |█▋                              | 10kB 17.0MB/s eta 0:00:01\r",
      "\u001b[K     |███▏                            | 20kB 9.5MB/s eta 0:00:01\r",
      "\u001b[K     |████▊                           | 30kB 7.7MB/s eta 0:00:01\r",
      "\u001b[K     |██████▎                         | 40kB 7.0MB/s eta 0:00:01\r",
      "\u001b[K     |███████▉                        | 51kB 4.3MB/s eta 0:00:01\r",
      "\u001b[K     |█████████▍                      | 61kB 4.9MB/s eta 0:00:01\r",
      "\u001b[K     |███████████                     | 71kB 5.3MB/s eta 0:00:01\r",
      "\u001b[K     |████████████▌                   | 81kB 5.3MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████                  | 92kB 5.6MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████▋                | 102kB 5.5MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████████▏              | 112kB 5.5MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████████▊             | 122kB 5.5MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████████▎           | 133kB 5.5MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████████████▉          | 143kB 5.5MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████████████▍        | 153kB 5.5MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████████████████       | 163kB 5.5MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████████████████▋     | 174kB 5.5MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████████████████▏   | 184kB 5.5MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████████████████████▊  | 194kB 5.5MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████████████████████▎| 204kB 5.5MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████████████████████| 215kB 5.5MB/s \n",
      "\u001b[?25hInstalling collected packages: Sastrawi\n",
      "Successfully installed Sastrawi-1.0.1\n"
     ]
    }
   ],
   "source": [
    "pip install Sastrawi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "38daivjnoRHv"
   },
   "source": [
    "## STEMMING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 497
    },
    "id": "rfVG6M9doXp4",
    "outputId": "ddf8cca2-adb0-444d-9dca-669f7f166b5e"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>time</th>\n",
       "      <th>review</th>\n",
       "      <th>formal-trans</th>\n",
       "      <th>aspek</th>\n",
       "      <th>label</th>\n",
       "      <th>cleansing</th>\n",
       "      <th>case_folding</th>\n",
       "      <th>tokenize</th>\n",
       "      <th>stemmed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Intan Diah Pratiwi</td>\n",
       "      <td>3 hari yang lalu</td>\n",
       "      <td>Taman kota yang juga menyimpan nilai sejarah p...</td>\n",
       "      <td>Taman Tugu Pahlawan biasa dijadikan tempat ber...</td>\n",
       "      <td>fasilitas</td>\n",
       "      <td>netral</td>\n",
       "      <td>Taman Tugu Pahlawan biasa dijadikan tempat ber...</td>\n",
       "      <td>taman tugu pahlawan biasa dijadikan tempat ber...</td>\n",
       "      <td>[taman, tugu, pahlawan, biasa, dijadikan, temp...</td>\n",
       "      <td>[taman, tugu, pahlawan, biasa, jadi, tempat, s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Wahyudi RJ</td>\n",
       "      <td>3 minggu yang lalu</td>\n",
       "      <td>Gowes seputar Tugu Pahlawan Surabaya</td>\n",
       "      <td>Bersepeda seputar Tugu Pahlawan Surabaya</td>\n",
       "      <td>fasilitas</td>\n",
       "      <td>netral</td>\n",
       "      <td>Bersepeda seputar Tugu Pahlawan Surabaya</td>\n",
       "      <td>bersepeda seputar tugu pahlawan surabaya</td>\n",
       "      <td>[bersepeda, seputar, tugu, pahlawan, surabaya]</td>\n",
       "      <td>[sepeda, putar, tugu, pahlawan, surabaya]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Centi_pade XxX</td>\n",
       "      <td>3 minggu yang lalu</td>\n",
       "      <td>Lokasi strategis tempat nya juga luas puas kal...</td>\n",
       "      <td>Lokasi strategis tempatnya juga luas puas kala...</td>\n",
       "      <td>fasilitas</td>\n",
       "      <td>positif</td>\n",
       "      <td>Lokasi strategis tempatnya juga luas puas kala...</td>\n",
       "      <td>lokasi strategis tempatnya juga luas puas kala...</td>\n",
       "      <td>[lokasi, strategis, tempatnya, juga, luas, pua...</td>\n",
       "      <td>[lokasi, strategis, tempat, juga, luas, puas, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Oktigaffelini P Yarisyah</td>\n",
       "      <td>4 minggu yang lalu</td>\n",
       "      <td>Tempat ini sangat cocok jika dijadikan wisata ...</td>\n",
       "      <td>Tetapi jika kesini siang siang jangan lupa baw...</td>\n",
       "      <td>fasilitas</td>\n",
       "      <td>negatif</td>\n",
       "      <td>Tetapi jika kesini siang siang jangan lupa baw...</td>\n",
       "      <td>tetapi jika kesini siang siang jangan lupa baw...</td>\n",
       "      <td>[tetapi, jika, kesini, siang, siang, jangan, l...</td>\n",
       "      <td>[tetapi, jika, kesini, siang, siang, jangan, l...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Qalbun Saliim</td>\n",
       "      <td>sebulan yang lalu</td>\n",
       "      <td>Tugu Pahlawan adalah salah satu tujuan wisata ...</td>\n",
       "      <td>Di dalam monumen ini, Anda bisa menjelajahi mu...</td>\n",
       "      <td>fasilitas</td>\n",
       "      <td>positif</td>\n",
       "      <td>Di dalam monumen ini  Anda bisa menjelajahi mu...</td>\n",
       "      <td>di dalam monumen ini  anda bisa menjelajahi mu...</td>\n",
       "      <td>[di, dalam, monumen, ini, anda, bisa, menjelaj...</td>\n",
       "      <td>[di, dalam, monumen, ini, anda, bisa, jajah, m...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>kepoin dong</td>\n",
       "      <td>sebulan yang lalu</td>\n",
       "      <td>tempat bersejarah yg di rawat</td>\n",
       "      <td>tempat bersejarah yang dirawat</td>\n",
       "      <td>fasilitas</td>\n",
       "      <td>positif</td>\n",
       "      <td>tempat bersejarah yang dirawat</td>\n",
       "      <td>tempat bersejarah yang dirawat</td>\n",
       "      <td>[tempat, bersejarah, yang, dirawat]</td>\n",
       "      <td>[tempat, sejarah, yang, rawat]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Erik Chosiin</td>\n",
       "      <td>sebulan yang lalu</td>\n",
       "      <td>Luas dan bersih . Bisa memepelajari sejarah ba...</td>\n",
       "      <td>Luas</td>\n",
       "      <td>fasilitas</td>\n",
       "      <td>netral</td>\n",
       "      <td>Luas</td>\n",
       "      <td>luas</td>\n",
       "      <td>[luas]</td>\n",
       "      <td>[luas]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>super MOTO</td>\n",
       "      <td>sebulan yang lalu</td>\n",
       "      <td>INSIDER'S GUIDE / SURABAYAWisata Sejarah di Tu...</td>\n",
       "      <td>kawasan alun-alun yang berupa Fasilitas berupa...</td>\n",
       "      <td>fasilitas</td>\n",
       "      <td>positif</td>\n",
       "      <td>kawasan alun alun yang berupa Fasilitas berupa...</td>\n",
       "      <td>kawasan alun alun yang berupa fasilitas berupa...</td>\n",
       "      <td>[kawasan, alun, alun, yang, berupa, fasilitas,...</td>\n",
       "      <td>[kawasan, alun, alun, yang, upa, fasilitas, up...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Ulung Tri Topan Putra Samodra</td>\n",
       "      <td>sebulan yang lalu</td>\n",
       "      <td>Salah satu objek wisata yg berada di pusat kot...</td>\n",
       "      <td>Salah satu objek wisata yang berada di pusat k...</td>\n",
       "      <td>fasilitas</td>\n",
       "      <td>netral</td>\n",
       "      <td>Salah satu objek wisata yang berada di pusat k...</td>\n",
       "      <td>salah satu objek wisata yang berada di pusat k...</td>\n",
       "      <td>[salah, satu, objek, wisata, yang, berada, di,...</td>\n",
       "      <td>[salah, satu, objek, wisata, yang, ada, di, pu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Sembako Njungkir Harganya</td>\n",
       "      <td>sebulan yang lalu</td>\n",
       "      <td>Enak buat joging pagi</td>\n",
       "      <td>Enak buat lari pelan-pelan pagi</td>\n",
       "      <td>fasilitas</td>\n",
       "      <td>positif</td>\n",
       "      <td>Enak buat lari pelan pelan pagi</td>\n",
       "      <td>enak buat lari pelan pelan pagi</td>\n",
       "      <td>[enak, buat, lari, pelan, pelan, pagi]</td>\n",
       "      <td>[enak, buat, lari, pelan, pelan, pagi]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            name  ...                                            stemmed\n",
       "0             Intan Diah Pratiwi  ...  [taman, tugu, pahlawan, biasa, jadi, tempat, s...\n",
       "1                     Wahyudi RJ  ...          [sepeda, putar, tugu, pahlawan, surabaya]\n",
       "2                 Centi_pade XxX  ...  [lokasi, strategis, tempat, juga, luas, puas, ...\n",
       "3       Oktigaffelini P Yarisyah  ...  [tetapi, jika, kesini, siang, siang, jangan, l...\n",
       "4                  Qalbun Saliim  ...  [di, dalam, monumen, ini, anda, bisa, jajah, m...\n",
       "5                    kepoin dong  ...                     [tempat, sejarah, yang, rawat]\n",
       "6                   Erik Chosiin  ...                                             [luas]\n",
       "7                     super MOTO  ...  [kawasan, alun, alun, yang, upa, fasilitas, up...\n",
       "8  Ulung Tri Topan Putra Samodra  ...  [salah, satu, objek, wisata, yang, ada, di, pu...\n",
       "9      Sembako Njungkir Harganya  ...             [enak, buat, lari, pelan, pelan, pagi]\n",
       "\n",
       "[10 rows x 10 columns]"
      ]
     },
     "execution_count": 92,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Step 4: Stemming\n",
    "from Sastrawi.StopWordRemover.StopWordRemoverFactory import StopWordRemoverFactory\n",
    "from Sastrawi.Dictionary.ArrayDictionary import ArrayDictionary\n",
    "from Sastrawi.StopWordRemover.StopWordRemover import StopWordRemover\n",
    "from Sastrawi.Stemmer.StemmerFactory import StemmerFactory\n",
    "\n",
    "def word_stemmer(text):\n",
    "  factorystemmer = StemmerFactory()\n",
    "  stemmer = factorystemmer.create_stemmer()\n",
    "  text = [stemmer.stem(x)for x in text]\n",
    "  return(text)\n",
    "\n",
    "df['stemmed'] = df['tokenize'].apply(lambda x:word_stemmer(x))\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4Sd_FfhWodQo"
   },
   "source": [
    "## STOPWORDS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 497
    },
    "id": "VbPWb2gAssVK",
    "outputId": "2499175b-4d64-41e9-efa0-6c280ea373a7"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>time</th>\n",
       "      <th>review</th>\n",
       "      <th>formal-trans</th>\n",
       "      <th>aspek</th>\n",
       "      <th>label</th>\n",
       "      <th>cleansing</th>\n",
       "      <th>case_folding</th>\n",
       "      <th>tokenize</th>\n",
       "      <th>stemmed</th>\n",
       "      <th>stopword</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Intan Diah Pratiwi</td>\n",
       "      <td>3 hari yang lalu</td>\n",
       "      <td>Taman kota yang juga menyimpan nilai sejarah p...</td>\n",
       "      <td>Taman Tugu Pahlawan biasa dijadikan tempat ber...</td>\n",
       "      <td>fasilitas</td>\n",
       "      <td>netral</td>\n",
       "      <td>Taman Tugu Pahlawan biasa dijadikan tempat ber...</td>\n",
       "      <td>taman tugu pahlawan biasa dijadikan tempat ber...</td>\n",
       "      <td>[taman, tugu, pahlawan, biasa, dijadikan, temp...</td>\n",
       "      <td>[taman, tugu, pahlawan, biasa, jadi, tempat, s...</td>\n",
       "      <td>[taman, tugu, pahlawan, biasa, jadi, tempat, s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Wahyudi RJ</td>\n",
       "      <td>3 minggu yang lalu</td>\n",
       "      <td>Gowes seputar Tugu Pahlawan Surabaya</td>\n",
       "      <td>Bersepeda seputar Tugu Pahlawan Surabaya</td>\n",
       "      <td>fasilitas</td>\n",
       "      <td>netral</td>\n",
       "      <td>Bersepeda seputar Tugu Pahlawan Surabaya</td>\n",
       "      <td>bersepeda seputar tugu pahlawan surabaya</td>\n",
       "      <td>[bersepeda, seputar, tugu, pahlawan, surabaya]</td>\n",
       "      <td>[sepeda, putar, tugu, pahlawan, surabaya]</td>\n",
       "      <td>[sepeda, putar, tugu, pahlawan, ]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Centi_pade XxX</td>\n",
       "      <td>3 minggu yang lalu</td>\n",
       "      <td>Lokasi strategis tempat nya juga luas puas kal...</td>\n",
       "      <td>Lokasi strategis tempatnya juga luas puas kala...</td>\n",
       "      <td>fasilitas</td>\n",
       "      <td>positif</td>\n",
       "      <td>Lokasi strategis tempatnya juga luas puas kala...</td>\n",
       "      <td>lokasi strategis tempatnya juga luas puas kala...</td>\n",
       "      <td>[lokasi, strategis, tempatnya, juga, luas, pua...</td>\n",
       "      <td>[lokasi, strategis, tempat, juga, luas, puas, ...</td>\n",
       "      <td>[lokasi, strategis, tempat, , luas, puas, kala...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Oktigaffelini P Yarisyah</td>\n",
       "      <td>4 minggu yang lalu</td>\n",
       "      <td>Tempat ini sangat cocok jika dijadikan wisata ...</td>\n",
       "      <td>Tetapi jika kesini siang siang jangan lupa baw...</td>\n",
       "      <td>fasilitas</td>\n",
       "      <td>negatif</td>\n",
       "      <td>Tetapi jika kesini siang siang jangan lupa baw...</td>\n",
       "      <td>tetapi jika kesini siang siang jangan lupa baw...</td>\n",
       "      <td>[tetapi, jika, kesini, siang, siang, jangan, l...</td>\n",
       "      <td>[tetapi, jika, kesini, siang, siang, jangan, l...</td>\n",
       "      <td>[tetapi, , kesini, siang, siang, jangan, lupa,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Qalbun Saliim</td>\n",
       "      <td>sebulan yang lalu</td>\n",
       "      <td>Tugu Pahlawan adalah salah satu tujuan wisata ...</td>\n",
       "      <td>Di dalam monumen ini, Anda bisa menjelajahi mu...</td>\n",
       "      <td>fasilitas</td>\n",
       "      <td>positif</td>\n",
       "      <td>Di dalam monumen ini  Anda bisa menjelajahi mu...</td>\n",
       "      <td>di dalam monumen ini  anda bisa menjelajahi mu...</td>\n",
       "      <td>[di, dalam, monumen, ini, anda, bisa, menjelaj...</td>\n",
       "      <td>[di, dalam, monumen, ini, anda, bisa, jajah, m...</td>\n",
       "      <td>[, , monumen, , , , jajah, museum, , lihat, ba...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>kepoin dong</td>\n",
       "      <td>sebulan yang lalu</td>\n",
       "      <td>tempat bersejarah yg di rawat</td>\n",
       "      <td>tempat bersejarah yang dirawat</td>\n",
       "      <td>fasilitas</td>\n",
       "      <td>positif</td>\n",
       "      <td>tempat bersejarah yang dirawat</td>\n",
       "      <td>tempat bersejarah yang dirawat</td>\n",
       "      <td>[tempat, bersejarah, yang, dirawat]</td>\n",
       "      <td>[tempat, sejarah, yang, rawat]</td>\n",
       "      <td>[tempat, sejarah, , rawat]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Erik Chosiin</td>\n",
       "      <td>sebulan yang lalu</td>\n",
       "      <td>Luas dan bersih . Bisa memepelajari sejarah ba...</td>\n",
       "      <td>Luas</td>\n",
       "      <td>fasilitas</td>\n",
       "      <td>netral</td>\n",
       "      <td>Luas</td>\n",
       "      <td>luas</td>\n",
       "      <td>[luas]</td>\n",
       "      <td>[luas]</td>\n",
       "      <td>[luas]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>super MOTO</td>\n",
       "      <td>sebulan yang lalu</td>\n",
       "      <td>INSIDER'S GUIDE / SURABAYAWisata Sejarah di Tu...</td>\n",
       "      <td>kawasan alun-alun yang berupa Fasilitas berupa...</td>\n",
       "      <td>fasilitas</td>\n",
       "      <td>positif</td>\n",
       "      <td>kawasan alun alun yang berupa Fasilitas berupa...</td>\n",
       "      <td>kawasan alun alun yang berupa fasilitas berupa...</td>\n",
       "      <td>[kawasan, alun, alun, yang, berupa, fasilitas,...</td>\n",
       "      <td>[kawasan, alun, alun, yang, upa, fasilitas, up...</td>\n",
       "      <td>[kawasan, alun, alun, , upa, fasilitas, upa, t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Ulung Tri Topan Putra Samodra</td>\n",
       "      <td>sebulan yang lalu</td>\n",
       "      <td>Salah satu objek wisata yg berada di pusat kot...</td>\n",
       "      <td>Salah satu objek wisata yang berada di pusat k...</td>\n",
       "      <td>fasilitas</td>\n",
       "      <td>netral</td>\n",
       "      <td>Salah satu objek wisata yang berada di pusat k...</td>\n",
       "      <td>salah satu objek wisata yang berada di pusat k...</td>\n",
       "      <td>[salah, satu, objek, wisata, yang, berada, di,...</td>\n",
       "      <td>[salah, satu, objek, wisata, yang, ada, di, pu...</td>\n",
       "      <td>[salah, satu, objek, wisata, , , , pusat, , , ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Sembako Njungkir Harganya</td>\n",
       "      <td>sebulan yang lalu</td>\n",
       "      <td>Enak buat joging pagi</td>\n",
       "      <td>Enak buat lari pelan-pelan pagi</td>\n",
       "      <td>fasilitas</td>\n",
       "      <td>positif</td>\n",
       "      <td>Enak buat lari pelan pelan pagi</td>\n",
       "      <td>enak buat lari pelan pelan pagi</td>\n",
       "      <td>[enak, buat, lari, pelan, pelan, pagi]</td>\n",
       "      <td>[enak, buat, lari, pelan, pelan, pagi]</td>\n",
       "      <td>[enak, buat, lari, pelan, pelan, pagi]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            name  ...                                           stopword\n",
       "0             Intan Diah Pratiwi  ...  [taman, tugu, pahlawan, biasa, jadi, tempat, s...\n",
       "1                     Wahyudi RJ  ...                  [sepeda, putar, tugu, pahlawan, ]\n",
       "2                 Centi_pade XxX  ...  [lokasi, strategis, tempat, , luas, puas, kala...\n",
       "3       Oktigaffelini P Yarisyah  ...  [tetapi, , kesini, siang, siang, jangan, lupa,...\n",
       "4                  Qalbun Saliim  ...  [, , monumen, , , , jajah, museum, , lihat, ba...\n",
       "5                    kepoin dong  ...                         [tempat, sejarah, , rawat]\n",
       "6                   Erik Chosiin  ...                                             [luas]\n",
       "7                     super MOTO  ...  [kawasan, alun, alun, , upa, fasilitas, upa, t...\n",
       "8  Ulung Tri Topan Putra Samodra  ...  [salah, satu, objek, wisata, , , , pusat, , , ...\n",
       "9      Sembako Njungkir Harganya  ...             [enak, buat, lari, pelan, pelan, pagi]\n",
       "\n",
       "[10 rows x 11 columns]"
      ]
     },
     "execution_count": 94,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def remove_stopwords(text):\n",
    "  stop_factory = df = pd.read_excel('list_stopword.xlsx')[0].tolist()\n",
    "  add_stopwords = ['kota', 'surabaya', 'sepuluh', 'nopember', 'november','bungurasih', 'jayabaya', 'nov', 'yg', 'deh', 'sih', 'lho', \n",
    "                   'nya', 'ku', 'pun', 'per', 'lah', 'pasar turi', 'pasarturi','abdul','abdurrahman','agustus','alfalegro','almarhum','ampel','doel','arnowo',\n",
    "                   'bandung','kalimantan','selatan','banjar','bar','jawa','semanggi','madura','ponorogo','km','boyo','bromo','buaya','bubut','bung',\n",
    "                   'bungkul','bungur','cakra','canalures','carden ','dardak','darmo','dnya','sutomo','soerjo','karno','jendral','dwi','eh','ekaristi',\n",
    "                   'gereja','misa','r','muhammad','sudirman','emil','rb','ken','pe','tai','jepang','raad','van','justitie','viaduct',\n",
    "                   'presiden','ri','ir','moestadjab','soemowidigdo','yard','h','r','mohammad','mayjen','sungkono','residen','soedirman','ghurka','nica',\n",
    "                   'gubenur','ifs','ih','ika','ika','jaja','jakarta','jokowi','jpo','khofifah','mallaby','komando','madura','mojokerto','museumtupal',\n",
    "                   'nkri','turi','pasar','tjokroaminoto','tjankroekan','sidoarjo','sht','org','rp','nyssa','unair','yogyakarta',\n",
    "                   'yamato','hos','supratman','wr','fi','wi','upn',\n",
    "                   '\\n']\n",
    "  # data = stop_factory + add_stopwords\n",
    "  dictionary = ArrayDictionary(stop_factory + add_stopwords)\n",
    "  str = StopWordRemover(dictionary)\n",
    "  text = [str.remove(x)for x in text]\n",
    "  return text\n",
    "\n",
    "df['stopword'] = df['stemmed'].apply(lambda x:\n",
    "remove_stopwords(x))\n",
    "# df['stopword'] = df['stopword'].apply(lambda x:\n",
    "# remove_stopwords(x))\n",
    "\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Sne6PMZHofnB"
   },
   "source": [
    "## HAPUS TOKEN KOSONG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 497
    },
    "id": "f8Ri-RnJooT6",
    "outputId": "54fa616a-7cac-453d-e559-f59d8963ae70"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>time</th>\n",
       "      <th>review</th>\n",
       "      <th>formal-trans</th>\n",
       "      <th>aspek</th>\n",
       "      <th>label</th>\n",
       "      <th>cleansing</th>\n",
       "      <th>case_folding</th>\n",
       "      <th>tokenize</th>\n",
       "      <th>stemmed</th>\n",
       "      <th>stopword</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Intan Diah Pratiwi</td>\n",
       "      <td>3 hari yang lalu</td>\n",
       "      <td>Taman kota yang juga menyimpan nilai sejarah p...</td>\n",
       "      <td>Taman Tugu Pahlawan biasa dijadikan tempat ber...</td>\n",
       "      <td>fasilitas</td>\n",
       "      <td>netral</td>\n",
       "      <td>Taman Tugu Pahlawan biasa dijadikan tempat ber...</td>\n",
       "      <td>taman tugu pahlawan biasa dijadikan tempat ber...</td>\n",
       "      <td>[taman, tugu, pahlawan, biasa, dijadikan, temp...</td>\n",
       "      <td>[taman, tugu, pahlawan, biasa, jadi, tempat, s...</td>\n",
       "      <td>[taman, tugu, pahlawan, biasa, jadi, tempat, s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Wahyudi RJ</td>\n",
       "      <td>3 minggu yang lalu</td>\n",
       "      <td>Gowes seputar Tugu Pahlawan Surabaya</td>\n",
       "      <td>Bersepeda seputar Tugu Pahlawan Surabaya</td>\n",
       "      <td>fasilitas</td>\n",
       "      <td>netral</td>\n",
       "      <td>Bersepeda seputar Tugu Pahlawan Surabaya</td>\n",
       "      <td>bersepeda seputar tugu pahlawan surabaya</td>\n",
       "      <td>[bersepeda, seputar, tugu, pahlawan, surabaya]</td>\n",
       "      <td>[sepeda, putar, tugu, pahlawan, surabaya]</td>\n",
       "      <td>[sepeda, putar, tugu, pahlawan]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Centi_pade XxX</td>\n",
       "      <td>3 minggu yang lalu</td>\n",
       "      <td>Lokasi strategis tempat nya juga luas puas kal...</td>\n",
       "      <td>Lokasi strategis tempatnya juga luas puas kala...</td>\n",
       "      <td>fasilitas</td>\n",
       "      <td>positif</td>\n",
       "      <td>Lokasi strategis tempatnya juga luas puas kala...</td>\n",
       "      <td>lokasi strategis tempatnya juga luas puas kala...</td>\n",
       "      <td>[lokasi, strategis, tempatnya, juga, luas, pua...</td>\n",
       "      <td>[lokasi, strategis, tempat, juga, luas, puas, ...</td>\n",
       "      <td>[lokasi, strategis, tempat, luas, puas, kalau,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Oktigaffelini P Yarisyah</td>\n",
       "      <td>4 minggu yang lalu</td>\n",
       "      <td>Tempat ini sangat cocok jika dijadikan wisata ...</td>\n",
       "      <td>Tetapi jika kesini siang siang jangan lupa baw...</td>\n",
       "      <td>fasilitas</td>\n",
       "      <td>negatif</td>\n",
       "      <td>Tetapi jika kesini siang siang jangan lupa baw...</td>\n",
       "      <td>tetapi jika kesini siang siang jangan lupa baw...</td>\n",
       "      <td>[tetapi, jika, kesini, siang, siang, jangan, l...</td>\n",
       "      <td>[tetapi, jika, kesini, siang, siang, jangan, l...</td>\n",
       "      <td>[tetapi, kesini, siang, siang, jangan, lupa, b...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Qalbun Saliim</td>\n",
       "      <td>sebulan yang lalu</td>\n",
       "      <td>Tugu Pahlawan adalah salah satu tujuan wisata ...</td>\n",
       "      <td>Di dalam monumen ini, Anda bisa menjelajahi mu...</td>\n",
       "      <td>fasilitas</td>\n",
       "      <td>positif</td>\n",
       "      <td>Di dalam monumen ini  Anda bisa menjelajahi mu...</td>\n",
       "      <td>di dalam monumen ini  anda bisa menjelajahi mu...</td>\n",
       "      <td>[di, dalam, monumen, ini, anda, bisa, menjelaj...</td>\n",
       "      <td>[di, dalam, monumen, ini, anda, bisa, jajah, m...</td>\n",
       "      <td>[monumen, jajah, museum, lihat, bagai, dokumen...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>kepoin dong</td>\n",
       "      <td>sebulan yang lalu</td>\n",
       "      <td>tempat bersejarah yg di rawat</td>\n",
       "      <td>tempat bersejarah yang dirawat</td>\n",
       "      <td>fasilitas</td>\n",
       "      <td>positif</td>\n",
       "      <td>tempat bersejarah yang dirawat</td>\n",
       "      <td>tempat bersejarah yang dirawat</td>\n",
       "      <td>[tempat, bersejarah, yang, dirawat]</td>\n",
       "      <td>[tempat, sejarah, yang, rawat]</td>\n",
       "      <td>[tempat, sejarah, rawat]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Erik Chosiin</td>\n",
       "      <td>sebulan yang lalu</td>\n",
       "      <td>Luas dan bersih . Bisa memepelajari sejarah ba...</td>\n",
       "      <td>Luas</td>\n",
       "      <td>fasilitas</td>\n",
       "      <td>netral</td>\n",
       "      <td>Luas</td>\n",
       "      <td>luas</td>\n",
       "      <td>[luas]</td>\n",
       "      <td>[luas]</td>\n",
       "      <td>[luas]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>super MOTO</td>\n",
       "      <td>sebulan yang lalu</td>\n",
       "      <td>INSIDER'S GUIDE / SURABAYAWisata Sejarah di Tu...</td>\n",
       "      <td>kawasan alun-alun yang berupa Fasilitas berupa...</td>\n",
       "      <td>fasilitas</td>\n",
       "      <td>positif</td>\n",
       "      <td>kawasan alun alun yang berupa Fasilitas berupa...</td>\n",
       "      <td>kawasan alun alun yang berupa fasilitas berupa...</td>\n",
       "      <td>[kawasan, alun, alun, yang, berupa, fasilitas,...</td>\n",
       "      <td>[kawasan, alun, alun, yang, upa, fasilitas, up...</td>\n",
       "      <td>[kawasan, alun, alun, upa, fasilitas, upa, tro...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Ulung Tri Topan Putra Samodra</td>\n",
       "      <td>sebulan yang lalu</td>\n",
       "      <td>Salah satu objek wisata yg berada di pusat kot...</td>\n",
       "      <td>Salah satu objek wisata yang berada di pusat k...</td>\n",
       "      <td>fasilitas</td>\n",
       "      <td>netral</td>\n",
       "      <td>Salah satu objek wisata yang berada di pusat k...</td>\n",
       "      <td>salah satu objek wisata yang berada di pusat k...</td>\n",
       "      <td>[salah, satu, objek, wisata, yang, berada, di,...</td>\n",
       "      <td>[salah, satu, objek, wisata, yang, ada, di, pu...</td>\n",
       "      <td>[salah, satu, objek, wisata, pusat, biasa, kun...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Sembako Njungkir Harganya</td>\n",
       "      <td>sebulan yang lalu</td>\n",
       "      <td>Enak buat joging pagi</td>\n",
       "      <td>Enak buat lari pelan-pelan pagi</td>\n",
       "      <td>fasilitas</td>\n",
       "      <td>positif</td>\n",
       "      <td>Enak buat lari pelan pelan pagi</td>\n",
       "      <td>enak buat lari pelan pelan pagi</td>\n",
       "      <td>[enak, buat, lari, pelan, pelan, pagi]</td>\n",
       "      <td>[enak, buat, lari, pelan, pelan, pagi]</td>\n",
       "      <td>[enak, buat, lari, pelan, pelan, pagi]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            name  ...                                           stopword\n",
       "0             Intan Diah Pratiwi  ...  [taman, tugu, pahlawan, biasa, jadi, tempat, s...\n",
       "1                     Wahyudi RJ  ...                    [sepeda, putar, tugu, pahlawan]\n",
       "2                 Centi_pade XxX  ...  [lokasi, strategis, tempat, luas, puas, kalau,...\n",
       "3       Oktigaffelini P Yarisyah  ...  [tetapi, kesini, siang, siang, jangan, lupa, b...\n",
       "4                  Qalbun Saliim  ...  [monumen, jajah, museum, lihat, bagai, dokumen...\n",
       "5                    kepoin dong  ...                           [tempat, sejarah, rawat]\n",
       "6                   Erik Chosiin  ...                                             [luas]\n",
       "7                     super MOTO  ...  [kawasan, alun, alun, upa, fasilitas, upa, tro...\n",
       "8  Ulung Tri Topan Putra Samodra  ...  [salah, satu, objek, wisata, pusat, biasa, kun...\n",
       "9      Sembako Njungkir Harganya  ...             [enak, buat, lari, pelan, pelan, pagi]\n",
       "\n",
       "[10 rows x 11 columns]"
      ]
     },
     "execution_count": 95,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Menghapus token kosong\n",
    "def clear(text):\n",
    "    text = [x for x in text if len(x)>0]\n",
    "    return text\n",
    "df['stopword'] = df['stopword'].apply(lambda x: clear(x))\n",
    "df = df[df['stopword'].apply(lambda x: len(x) != 0)]\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_Zz6aU8sowMG"
   },
   "source": [
    "## EXPORT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ezQ1u7PxoxgS"
   },
   "outputs": [],
   "source": [
    "#export\n",
    "df.to_excel('hasil_Preprocessing_fasilitas_2.xlsx', encoding='utf-8')\n",
    "# df.to_csv('hasil_textPreProcessing.csv', encoding='utf-8')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qrsx9-CwWC9m"
   },
   "source": [
    "# Term Weighting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 191
    },
    "id": "zTLSXl6qXFLq",
    "outputId": "3f202ca7-35b4-4cc2-eace-d3560b9e99b1"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>name</th>\n",
       "      <th>time</th>\n",
       "      <th>review</th>\n",
       "      <th>aspek</th>\n",
       "      <th>label</th>\n",
       "      <th>formal-trans</th>\n",
       "      <th>cleansing</th>\n",
       "      <th>case folding</th>\n",
       "      <th>tokenizing</th>\n",
       "      <th>stemming</th>\n",
       "      <th>stop-words</th>\n",
       "      <th>final preprocessing</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Supa Rto</td>\n",
       "      <td>1 hari yang lalu</td>\n",
       "      <td>Mantab</td>\n",
       "      <td>umum</td>\n",
       "      <td>positif</td>\n",
       "      <td>Mantap</td>\n",
       "      <td>Mantap</td>\n",
       "      <td>mantap</td>\n",
       "      <td>['mantap']</td>\n",
       "      <td>['mantap']</td>\n",
       "      <td>['mantap']</td>\n",
       "      <td>['mantap']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Parfum Wangi</td>\n",
       "      <td>3 hari yang lalu</td>\n",
       "      <td>Sangat bagus</td>\n",
       "      <td>umum</td>\n",
       "      <td>positif</td>\n",
       "      <td>Sangat bagus</td>\n",
       "      <td>Sangat bagus</td>\n",
       "      <td>sangat bagus</td>\n",
       "      <td>['sangat', 'bagus']</td>\n",
       "      <td>['sangat', 'bagus']</td>\n",
       "      <td>['sangat', 'bagus']</td>\n",
       "      <td>['sangat', 'bagus']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Aslam Bima.R</td>\n",
       "      <td>3 hari yang lalu</td>\n",
       "      <td>Battle of Surabaya</td>\n",
       "      <td>umum</td>\n",
       "      <td>netral</td>\n",
       "      <td>pertempuran Surabaya</td>\n",
       "      <td>pertempuran Surabaya</td>\n",
       "      <td>pertempuran surabaya</td>\n",
       "      <td>['pertempuran', 'surabaya']</td>\n",
       "      <td>['tempur', 'surabaya']</td>\n",
       "      <td>['tempur', '']</td>\n",
       "      <td>['tempur']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>Hussaini Saini</td>\n",
       "      <td>4 hari yang lalu</td>\n",
       "      <td>Sangat bagus</td>\n",
       "      <td>umum</td>\n",
       "      <td>positif</td>\n",
       "      <td>Sangat bagus</td>\n",
       "      <td>Sangat bagus</td>\n",
       "      <td>sangat bagus</td>\n",
       "      <td>['sangat', 'bagus']</td>\n",
       "      <td>['sangat', 'bagus']</td>\n",
       "      <td>['sangat', 'bagus']</td>\n",
       "      <td>['sangat', 'bagus']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>Agus almini</td>\n",
       "      <td>6 hari yang lalu</td>\n",
       "      <td>Semakin indah</td>\n",
       "      <td>umum</td>\n",
       "      <td>positif</td>\n",
       "      <td>Semakin indah</td>\n",
       "      <td>Semakin indah</td>\n",
       "      <td>semakin indah</td>\n",
       "      <td>['semakin', 'indah']</td>\n",
       "      <td>['makin', 'indah']</td>\n",
       "      <td>['makin', 'indah']</td>\n",
       "      <td>['makin', 'indah']</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0            name  ...           stop-words  final preprocessing\n",
       "0           0        Supa Rto  ...           ['mantap']           ['mantap']\n",
       "1           1    Parfum Wangi  ...  ['sangat', 'bagus']  ['sangat', 'bagus']\n",
       "2           2    Aslam Bima.R  ...       ['tempur', '']           ['tempur']\n",
       "3           3  Hussaini Saini  ...  ['sangat', 'bagus']  ['sangat', 'bagus']\n",
       "4           4     Agus almini  ...   ['makin', 'indah']   ['makin', 'indah']\n",
       "\n",
       "[5 rows x 13 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df_tw = pd.read_excel('aspekall_data.xlsx')\n",
    "# df_tw = df_tw.drop(columns=['final preprocessing','Unnamed: 0'])\n",
    "# df_tw = df_tw.drop(columns=['Unnamed: 0'])\n",
    "df_tw.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rgboV_x3WHo6"
   },
   "outputs": [],
   "source": [
    "# from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "# from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "tf_idf = TfidfVectorizer( lowercase=False)\n",
    "tfidf_mat = tf_idf.fit_transform(df_tw[\"final preprocessing\"])\n",
    "\n",
    "#mengeksport hasil tfidf ke file .csv dan excel\n",
    "feature_names = tf_idf.get_feature_names()\n",
    "dense = tfidf_mat.todense()\n",
    "denselist=dense.tolist()\n",
    "df_tfidf=pd.DataFrame(denselist, columns=feature_names)\n",
    "# dftfidf.to_csv('tfidf.csv',encoding='utf-8')\n",
    "df_tfidf.to_excel('tfidf_all_data.xlsx',encoding='utf-8', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WyPX3nUM5xax"
   },
   "source": [
    "## Manualiasi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "pmb7cBlW5ysP"
   },
   "outputs": [],
   "source": [
    "# Import pandas for data manipulation\n",
    "import pandas as pd\n",
    "\n",
    "# Read document 'manualisasi' which contains the example\n",
    "df_man = pd.read_excel('manualisasi.xlsx')\n",
    "\n",
    "# Import library contains of TF & IDF function\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "# from sklearn.feature_extraction.text import TfidfTransformer\n",
    "# from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "# Set the main method of TF IDF calculation for the example\n",
    "tf_idf_man = TfidfVectorizer()\n",
    "\n",
    "# Implement the fit transformation of TF IDF calculation for the example (matrix)\n",
    "tf_idf_manualisasi = tf_idf_man.fit_transform(df_man['final preprocessing'])\n",
    "\n",
    "# Extract data from datasets to column \n",
    "feature_names_manualisasi = tf_idf_man.get_feature_names()\n",
    "\n",
    "# Return a dense matrix representation of a matrix NDFrame\n",
    "dense_manualisasi = tf_idf_manualisasi.todense()\n",
    "\n",
    "# Convert a series into list \n",
    "denselist_manualisasi = dense_manualisasi.tolist()\n",
    "\n",
    "# Save the result to a DataFrame for the example\n",
    "df_tfidf_manualisasi = pd.DataFrame(denselist_manualisasi, columns=feature_names_manualisasi)\n",
    "\n",
    "# Export the results to Excel file\n",
    "df_tfidf_manualisasi.to_excel('tfidf_manualisasi.xlsx', encoding='utf-8')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Mu_d-50u8hoI"
   },
   "source": [
    "## Manualisasi 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1kViuieA-bBH"
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "from sklearn.preprocessing import normalize\n",
    "import pandas as pd\n",
    "\n",
    "df_man = pd.read_excel('manualisasi_hndhr.xlsx')\n",
    "\n",
    "tf_idf = TfidfVectorizer(lowercase=False, norm=None)\n",
    "tfidf_mat = tf_idf.fit_transform(df_man[\"final preprocessing\"])\n",
    "\n",
    "#mengeksport hasil tfidf ke file .csv dan excel\n",
    "feature_names = tf_idf.get_feature_names()\n",
    "dense = tfidf_mat.todense()\n",
    "denselist=dense.tolist()\n",
    "df_tfidf=pd.DataFrame(denselist, columns=feature_names)\n",
    "# dftfidf.to_csv('tfidf.csv',encoding='utf-8')\n",
    "df_tfidf.to_excel('tfidf_no_norm_hndhr.xlsx',encoding='utf-8')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "okpefJztTmx5"
   },
   "source": [
    "# KLASIFIKASI NAIVE-BAYES"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Yef_lSRiVBVp"
   },
   "source": [
    "## Split Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_lVzGyQNVusE"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# membaca data excel/csv\n",
    "df_clf_tw = pd.read_excel('tfidf_Fasilitas.xlsx').drop(columns='Unnamed: 0')\n",
    "df_clf_aspek = pd.read_excel('aspekFasilitas.xlsx').drop(columns='Unnamed: 0')\n",
    "\n",
    "# memisahkan data dengan label\n",
    "y = df_clf_aspek['label'] # data dengan label saja\n",
    "X = df_clf_tw\n",
    "\n",
    "# X = np.array(df_clf_tw.values.tolist())\n",
    "# y = np.array(df_clf_aspek['label'].values.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hiN4dHoERlga"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# membaca data excel/csv\n",
    "df_clf_tw = pd.read_excel('tfidf_Fasilitas.xlsx').drop(columns='Unnamed: 0')\n",
    "df_clf_aspek = pd.read_excel('aspekFasilitas.xlsx').drop(columns='Unnamed: 0')\n",
    "\n",
    "# memisahkan data dengan label\n",
    "y = df_clf_aspek['label'] # data dengan label saja\n",
    "X = df_clf_tw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8D0xial4J2ub",
    "outputId": "acb7d773-8ed4-4582-c916-05965f8be417"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['netral', 'positif', 'negatif'], dtype=object)"
      ]
     },
     "execution_count": 42,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "oeZdXzJfVEal",
    "outputId": "6fc060f2-8760-4f8a-cc82-eea6f1855d7f"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pandas.core.frame.DataFrame"
      ]
     },
     "execution_count": 43,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# membagi data menjadi data train dan data test dengan ukuran data tes 25% dari jumlah data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "F1qdrVTmWsry"
   },
   "source": [
    "## Melatih data dan memilih model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-FXRYGupXAp9",
    "outputId": "b02e7288-8840-49cf-fc84-27cf6e30a03d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Score:  0.7668518518518519\n",
      "Best Params:  {'alpha': 0.1, 'fit_prior': False}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Setup GridSearchCV\n",
    "alphas = [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0, 1.1, 1.2, 1.3, 1.4, 1.5, 1.6, 1.7, 1.8, 1.9, 2.0]\n",
    "clss_prior = [None, [.1,.9],[.2, .8]]\n",
    "grid_params = {\n",
    "  'alpha': alphas,\n",
    "  'fit_prior': [True, False],\n",
    "  # 'class_prior' : clss_prior \n",
    "} # tuning hyperparameter untuk model multinomial Naive Bayes\n",
    "nb_clf_1 = GridSearchCV(MultinomialNB(), grid_params, cv=5) # instansiasi method GridSearchCV\n",
    "nb_clf_1.fit(X_train, y_train)\n",
    "# nb_clf.fit(X, y)\n",
    "\n",
    "print(\"Best Score: \", nb_clf_1.best_score_)\n",
    "print(\"Best Params: \", nb_clf_1.best_params_)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kb54xCSVUmQJ"
   },
   "source": [
    "## Imbalance Validation Model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "oWBMKj_WUtaB",
    "outputId": "deee1bd9-1dde-42be-fbeb-493b38aeaab7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Score:  0.7792592592592593\n",
      "Best Params:  {'nb__alpha': 0.1, 'nb__fit_prior': True}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from imblearn.pipeline import make_pipeline, Pipeline\n",
    "from imblearn.over_sampling import SMOTE\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore') \n",
    "\n",
    "smt = SMOTE(k_neighbors=3)\n",
    "nb = MultinomialNB()\n",
    "pipeline = Pipeline([('smt', smt), ('nb', nb)])\n",
    "\n",
    "# Setup GridSearchCV\n",
    "alphas = [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0, 1.1, 1.2, 1.3, 1.4, 1.5, 1.6, 1.7, 1.8, 1.9, 2.0]\n",
    "grid_params = {\n",
    "  'nb__alpha': alphas,\n",
    "  'nb__fit_prior': [True, False]  \n",
    "} # tuning hyperparameter untuk model multinomial Naive Bayes\n",
    "nb_clf_2 = GridSearchCV(pipeline, grid_params, cv=5) # instansiasi method GridSearchCV\n",
    "nb_clf_2.fit(X_train, y_train)\n",
    "\n",
    "print(\"Best Score: \", nb_clf_2.best_score_)\n",
    "print(\"Best Params: \", nb_clf_2.best_params_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "N_NDWxwKHnal"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "var1 = 0.7792592592592593\n",
    "var2 = {'nb__alpha': 0.1, 'nb__fit_prior': True}\n",
    "datas={'best score':[var1], 'best_params' : [var2]}\n",
    "cek = pd.DataFrame(data=datas)\n",
    "# cek.head()\n",
    "cek.to_csv('tes_doang.csv', sep=\";\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "iYYIXCr_bDlg",
    "outputId": "5db1e6ea-4e06-401e-b3ee-60328b0a2b9b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "done right mean of scores 5-fold:\n",
      "accuracy: 0.715100965759438\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "# from imblearn.pipeline import make_pipeline as make_pipeline_imb\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score, roc_auc_score, accuracy_score, classification_report\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore') \n",
    "\n",
    "classifier = MultinomialNB\n",
    "\n",
    "# kf = KFold(n_splits=5, shuffle=True, random_state=1)\n",
    "skf = StratifiedKFold(n_splits=5, random_state=None, shuffle=False)\n",
    "accuracy = []\n",
    "precision = []\n",
    "recall = []\n",
    "f1 = []\n",
    "auc = []\n",
    "for train, test in skf.split(X, y):\n",
    "    # pipeline = make_pipeline_imb(SMOTE(), classifier())\n",
    "    # model = pipeline.fit(X_train[train], y_train[train])\n",
    "    # prediction = model.predict(X_train[test])\n",
    "     \n",
    "    sm = SMOTE(k_neighbors=3)\n",
    "    X_train_oversampled, y_train_oversampled = sm.fit_sample(X[train], y[train])\n",
    "\n",
    "    model = MultinomialNB(alpha = 0.1, fit_prior = True)\n",
    "    model.fit(X_train_oversampled, y_train_oversampled )\n",
    "    prediction = model.predict(X[test])\n",
    "\n",
    "    accuracy.append(model.score(X[test], y[test]))\n",
    "    # precision.append(precision_score(y[test], prediction))\n",
    "    # recall.append(recall_score(y[test], prediction))\n",
    "    # f1.append(f1_score(y[test], prediction))\n",
    "    # auc.append(roc_auc_score(y[test], prediction))\n",
    "\n",
    "print()\n",
    "print(\"done right mean of scores 5-fold:\")\n",
    "print(\"accuracy: {}\".format(np.mean(accuracy)))\n",
    "# print(\"precision: {}\".format(np.mean(precision)))\n",
    "# print(\"recall: {}\".format(np.mean(recall)))\n",
    "# print(\"f1: {}\".format(np.mean(f1)))\n",
    "print()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kdpxBZZz4FZe"
   },
   "source": [
    "## Report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "HQA09NLdX5lC",
    "outputId": "91898406-877a-47dc-a958-144996c4ff72"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tanpa Oversampling\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     negatif       0.86      0.88      0.87        34\n",
      "      netral       0.65      0.86      0.74        37\n",
      "     positif       0.90      0.72      0.80        64\n",
      "\n",
      "    accuracy                           0.80       135\n",
      "   macro avg       0.80      0.82      0.80       135\n",
      "weighted avg       0.82      0.80      0.80       135\n",
      "\n",
      "\n",
      "Dengan Oversampling\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     negatif       0.93      0.76      0.84        34\n",
      "      netral       0.70      0.86      0.77        37\n",
      "     positif       0.84      0.80      0.82        64\n",
      "\n",
      "    accuracy                           0.81       135\n",
      "   macro avg       0.82      0.81      0.81       135\n",
      "weighted avg       0.82      0.81      0.81       135\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# melakukan prediksi dengan model yang sudah di train sebelumnya\n",
    "\n",
    "hasil_prediksi_1 = nb_clf_1.predict(X_test)\n",
    "hasil_prediksi_2 = nb_clf_2.predict(X_test)\n",
    "print(\"Tanpa Oversampling\")\n",
    "print(classification_report(y_test, hasil_prediksi_1))\n",
    "print()\n",
    "print(\"Dengan Oversampling\")\n",
    "print(classification_report(y_test, hasil_prediksi_2))\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AjUEcoXtxdYz"
   },
   "source": [
    "## Klasifikasi All The Way\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 191
    },
    "id": "dEEu7rM6_2uj",
    "outputId": "0e494fba-9fa4-4a1f-c49a-396d66098778"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>netral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>netral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>positif</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>positif</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>netral</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id    label\n",
       "0   0   netral\n",
       "1   1   netral\n",
       "2   2  positif\n",
       "3   3  positif\n",
       "4   4   netral"
      ]
     },
     "execution_count": 22,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_excel('aspekEdukasi.xlsx').rename(columns = {'Unnamed: 0': 'id'})\n",
    "y = pd.DataFrame(columns=['id','label']) # data dengan label saja\n",
    "y['label'] = df['label']\n",
    "y['id'] = df['id']\n",
    "y.head()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_FMsa-L7zice",
    "outputId": "2c5e3ce7-77be-4882-f63b-0e4fe9d6f595"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========================================================================\n",
      "---Klasifikasi Aspek Umum---\n",
      "\n",
      "-Tanpa Oversampling-\n",
      "Best Score:  0.8304\n",
      "Best Params:  {'alpha': 1.2, 'fit_prior': True}\n",
      "\n",
      "\n",
      "Classification Report\n",
      "\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     negatif       0.00      0.00      0.00         8\n",
      "      netral       0.78      0.96      0.86       111\n",
      "     positif       0.90      0.71      0.80        90\n",
      "\n",
      "    accuracy                           0.82       209\n",
      "   macro avg       0.56      0.56      0.55       209\n",
      "weighted avg       0.80      0.82      0.80       209\n",
      "\n",
      "\n",
      "\n",
      "Confusion Matrix\n",
      "\n",
      "\n",
      "[[  0   5   3]\n",
      " [  0 107   4]\n",
      " [  0  26  64]]\n",
      "\n",
      "\n",
      "-Dengan Oversampling-\n",
      "Best Score:  0.808\n",
      "Best Params:  {'nb__alpha': 0.3, 'nb__fit_prior': False}\n",
      "\n",
      "\n",
      "Classification Report\n",
      "\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     negatif       0.36      0.50      0.42         8\n",
      "      netral       0.87      0.89      0.88       111\n",
      "     positif       0.83      0.78      0.80        90\n",
      "\n",
      "    accuracy                           0.83       209\n",
      "   macro avg       0.69      0.72      0.70       209\n",
      "weighted avg       0.83      0.83      0.83       209\n",
      "\n",
      "\n",
      "\n",
      "Confusion Matrix\n",
      "\n",
      "\n",
      "[[ 4  1  3]\n",
      " [ 1 99 11]\n",
      " [ 6 14 70]]\n",
      "\n",
      "\n",
      "========================================================================\n",
      "---Klasifikasi Aspek Kebersihan---\n",
      "\n",
      "-Tanpa Oversampling-\n",
      "Best Score:  0.9492307692307692\n",
      "Best Params:  {'alpha': 0.1, 'fit_prior': True}\n",
      "\n",
      "\n",
      "Classification Report\n",
      "\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     negatif       1.00      0.50      0.67         2\n",
      "      netral       0.00      0.00      0.00         3\n",
      "     positif       0.94      1.00      0.97        61\n",
      "\n",
      "    accuracy                           0.94        66\n",
      "   macro avg       0.65      0.50      0.54        66\n",
      "weighted avg       0.90      0.94      0.92        66\n",
      "\n",
      "\n",
      "\n",
      "Confusion Matrix\n",
      "\n",
      "\n",
      "[[ 1  0  1]\n",
      " [ 0  0  3]\n",
      " [ 0  0 61]]\n",
      "\n",
      "\n",
      "-Dengan Oversampling-\n",
      "Best Score:  0.9644871794871795\n",
      "Best Params:  {'nb__alpha': 0.3, 'nb__fit_prior': True}\n",
      "\n",
      "\n",
      "Classification Report\n",
      "\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     negatif       0.50      0.50      0.50         2\n",
      "      netral       0.50      0.67      0.57         3\n",
      "     positif       0.98      0.97      0.98        61\n",
      "\n",
      "    accuracy                           0.94        66\n",
      "   macro avg       0.66      0.71      0.68        66\n",
      "weighted avg       0.95      0.94      0.94        66\n",
      "\n",
      "\n",
      "\n",
      "Confusion Matrix\n",
      "\n",
      "\n",
      "[[ 1  0  1]\n",
      " [ 1  2  0]\n",
      " [ 0  2 59]]\n",
      "\n",
      "\n",
      "========================================================================\n",
      "---Klasifikasi Aspek Edukasi---\n",
      "\n",
      "-Tanpa Oversampling-\n",
      "Best Score:  0.6955294117647058\n",
      "Best Params:  {'alpha': 1.5, 'fit_prior': False}\n",
      "\n",
      "\n",
      "Classification Report\n",
      "\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     negatif       0.50      1.00      0.67         1\n",
      "      netral       0.82      0.32      0.46        28\n",
      "     positif       0.75      0.96      0.84        56\n",
      "\n",
      "    accuracy                           0.75        85\n",
      "   macro avg       0.69      0.76      0.66        85\n",
      "weighted avg       0.77      0.75      0.72        85\n",
      "\n",
      "\n",
      "\n",
      "Confusion Matrix\n",
      "\n",
      "\n",
      "[[ 1  0  0]\n",
      " [ 1  9 18]\n",
      " [ 0  2 54]]\n",
      "\n",
      "\n",
      "-Dengan Oversampling-\n",
      "Best Score:  0.7425882352941177\n",
      "Best Params:  {'nb__alpha': 1.5, 'nb__fit_prior': False}\n",
      "\n",
      "\n",
      "Classification Report\n",
      "\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     negatif       0.50      1.00      0.67         1\n",
      "      netral       0.58      0.64      0.61        28\n",
      "     positif       0.83      0.77      0.80        56\n",
      "\n",
      "    accuracy                           0.73        85\n",
      "   macro avg       0.64      0.80      0.69        85\n",
      "weighted avg       0.74      0.73      0.73        85\n",
      "\n",
      "\n",
      "\n",
      "Confusion Matrix\n",
      "\n",
      "\n",
      "[[ 1  0  0]\n",
      " [ 1 18  9]\n",
      " [ 0 13 43]]\n",
      "\n",
      "\n",
      "========================================================================\n",
      "---Klasifikasi Aspek Pelayanan---\n",
      "\n",
      "-Tanpa Oversampling-\n",
      "Best Score:  0.7483870967741935\n",
      "Best Params:  {'alpha': 0.5, 'fit_prior': False}\n",
      "\n",
      "\n",
      "Classification Report\n",
      "\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     negatif       0.60      1.00      0.75         6\n",
      "      netral       0.79      0.90      0.84        21\n",
      "     positif       0.94      0.68      0.79        25\n",
      "\n",
      "    accuracy                           0.81        52\n",
      "   macro avg       0.78      0.86      0.80        52\n",
      "weighted avg       0.84      0.81      0.81        52\n",
      "\n",
      "\n",
      "\n",
      "Confusion Matrix\n",
      "\n",
      "\n",
      "[[ 6  0  0]\n",
      " [ 1 19  1]\n",
      " [ 3  5 17]]\n",
      "\n",
      "\n",
      "-Dengan Oversampling-\n",
      "Best Score:  0.7548387096774192\n",
      "Best Params:  {'nb__alpha': 1.0, 'nb__fit_prior': True}\n",
      "\n",
      "\n",
      "Classification Report\n",
      "\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     negatif       0.86      1.00      0.92         6\n",
      "      netral       0.76      0.90      0.83        21\n",
      "     positif       0.95      0.76      0.84        25\n",
      "\n",
      "    accuracy                           0.85        52\n",
      "   macro avg       0.86      0.89      0.86        52\n",
      "weighted avg       0.86      0.85      0.85        52\n",
      "\n",
      "\n",
      "\n",
      "Confusion Matrix\n",
      "\n",
      "\n",
      "[[ 6  0  0]\n",
      " [ 1 19  1]\n",
      " [ 0  6 19]]\n",
      "\n",
      "\n",
      "========================================================================\n",
      "---Klasifikasi Aspek Fasilitas---\n",
      "\n",
      "-Tanpa Oversampling-\n",
      "Best Score:  0.796574074074074\n",
      "Best Params:  {'alpha': 0.7, 'fit_prior': False}\n",
      "\n",
      "\n",
      "Classification Report\n",
      "\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     negatif       0.97      0.82      0.89        34\n",
      "      netral       0.73      0.81      0.77        37\n",
      "     positif       0.88      0.89      0.88        64\n",
      "\n",
      "    accuracy                           0.85       135\n",
      "   macro avg       0.86      0.84      0.85       135\n",
      "weighted avg       0.86      0.85      0.85       135\n",
      "\n",
      "\n",
      "\n",
      "Confusion Matrix\n",
      "\n",
      "\n",
      "[[28  4  2]\n",
      " [ 1 30  6]\n",
      " [ 0  7 57]]\n",
      "\n",
      "\n",
      "-Dengan Oversampling-\n",
      "Best Score:  0.8089814814814815\n",
      "Best Params:  {'nb__alpha': 1.2, 'nb__fit_prior': False}\n",
      "\n",
      "\n",
      "Classification Report\n",
      "\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     negatif       0.94      0.85      0.89        34\n",
      "      netral       0.72      0.89      0.80        37\n",
      "     positif       0.91      0.83      0.87        64\n",
      "\n",
      "    accuracy                           0.85       135\n",
      "   macro avg       0.86      0.86      0.85       135\n",
      "weighted avg       0.87      0.85      0.85       135\n",
      "\n",
      "\n",
      "\n",
      "Confusion Matrix\n",
      "\n",
      "\n",
      "[[29  3  2]\n",
      " [ 1 33  3]\n",
      " [ 1 10 53]]\n",
      "\n",
      "\n",
      "========================================================================\n",
      "---Klasifikasi Aspek all_data---\n",
      "\n",
      "-Tanpa Oversampling-\n",
      "Best Score:  0.7915484838002997\n",
      "Best Params:  {'alpha': 0.8, 'fit_prior': False}\n",
      "\n",
      "\n",
      "Classification Report\n",
      "\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     negatif       0.62      0.68      0.65        38\n",
      "      netral       0.77      0.74      0.75       204\n",
      "     positif       0.80      0.81      0.80       250\n",
      "\n",
      "    accuracy                           0.77       492\n",
      "   macro avg       0.73      0.74      0.74       492\n",
      "weighted avg       0.77      0.77      0.77       492\n",
      "\n",
      "\n",
      "\n",
      "Confusion Matrix\n",
      "\n",
      "\n",
      "[[ 26   8   4]\n",
      " [  6 150  48]\n",
      " [ 10  37 203]]\n",
      "\n",
      "\n",
      "-Dengan Oversampling-\n",
      "Best Score:  0.7888458434221147\n",
      "Best Params:  {'nb__alpha': 1.1, 'nb__fit_prior': False}\n",
      "\n",
      "\n",
      "Classification Report\n",
      "\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     negatif       0.59      0.71      0.64        38\n",
      "      netral       0.77      0.75      0.76       204\n",
      "     positif       0.81      0.80      0.81       250\n",
      "\n",
      "    accuracy                           0.77       492\n",
      "   macro avg       0.72      0.76      0.74       492\n",
      "weighted avg       0.78      0.77      0.78       492\n",
      "\n",
      "\n",
      "\n",
      "Confusion Matrix\n",
      "\n",
      "\n",
      "[[ 27   7   4]\n",
      " [  8 154  42]\n",
      " [ 11  39 200]]\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from imblearn.pipeline import make_pipeline, Pipeline\n",
    "from sklearn.metrics import classification_report\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import warnings\n",
    "import os\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "\n",
    "all_data = {\n",
    "    \"Umum\" : {},\n",
    "    \"Kebersihan\" : {},\n",
    "    \"Edukasi\" : {},\n",
    "    \"Pelayanan\" : {},\n",
    "    \"Fasilitas\" : {},\n",
    "    \"all_data\" : {}\n",
    "}\n",
    "\n",
    "direktori = 'hasil'\n",
    "if not os.path.exists(f\"./{direktori}\"):\n",
    "  os.mkdir(direktori)\n",
    "\n",
    "# Read Data\n",
    "for key, val in all_data.items():\n",
    "  # membaca data excel/csv\n",
    "  tw_dir = f\"tfidf_{key}.xlsx\"\n",
    "  aspek_dir = f\"aspek{key}.xlsx\"\n",
    "  df_tw = pd.read_excel(tw_dir)\n",
    "  if \"Unnamed: 0\" in df_tw.columns :\n",
    "    df_tw = df_tw.drop(columns='Unnamed: 0')\n",
    "  df_aspek = pd.read_excel(aspek_dir)\n",
    "  if \"Unnamed: 0\" in df_aspek.columns :  \n",
    "    df_aspek = df_aspek.rename(columns = {'Unnamed: 0': 'id'})\n",
    "\n",
    "  # memisahkan data dengan label\n",
    "  y = pd.DataFrame(data={'id' : df_aspek['id'], 'label':df_aspek['label']}) # data dengan label saja\n",
    "  # y['label'] = df['label']\n",
    "  # y['id'] = df['id']\n",
    "  X = df_tw\n",
    "\n",
    "  # Append to object\n",
    "  val[\"tfidf\"] = X\n",
    "  val[\"aspek\"] = y\n",
    "\n",
    "for key, val in all_data.items():\n",
    "  outdir = f'./{direktori}/run_aspek_{key}'\n",
    "  if not os.path.exists(outdir):\n",
    "    os.mkdir(outdir) \n",
    "  # membagi data menjadi data train dan data test dengan ukuran data tes 25% dari jumlah data\n",
    "  print('========================================================================')\n",
    "  print(f\"---Klasifikasi Aspek {key}---\\n\")\n",
    "  X_train, X_test, y_train, y_test = train_test_split(val[\"tfidf\"], val[\"aspek\"], test_size=0.25, random_state=10)\n",
    "  str_export = f\"./hasil/run_aspek_{key}/y_test_{key}.xlsx\"\n",
    "  y_test.to_excel(str_export, encoding='utf-8')\n",
    "\n",
    "  # Klasifikasi tanpa oversampling\n",
    "  # Setup GridSearchCV\n",
    "  alphas = [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0, 1.1, 1.2, 1.3, 1.4, 1.5, 1.6, 1.7, 1.8, 1.9, 2.0]\n",
    "  clss_prior = [None, [.1,.9],[.2, .8]]\n",
    "  grid_params = {\n",
    "    'alpha': alphas,\n",
    "    'fit_prior': [True, False],\n",
    "  } # tuning hyperparameter untuk model multinomial Naive Bayes\n",
    "  nb_clf_1 = GridSearchCV(MultinomialNB(), grid_params, cv=5) # instansiasi method GridSearchCV\n",
    "  nb_clf_1.fit(X_train, y_train['label'])\n",
    "\n",
    "  datas={'best score':[nb_clf_1.best_score_], 'best_params' : [nb_clf_1.best_params_]}\n",
    "  hasil_1 = pd.DataFrame(data=datas)\n",
    "  str_export2 = f\"./{direktori}/run_aspek_{key}/hasil_fit_non_oversampling_{key}.csv\"\n",
    "  hasil_1.to_csv(str_export2, sep=\";\", index=False)\n",
    "  \n",
    "  print(\"-Tanpa Oversampling-\")\n",
    "  print(\"Best Score: \", nb_clf_1.best_score_)\n",
    "  print(\"Best Params: \", nb_clf_1.best_params_)\n",
    "  print('\\n')\n",
    "\n",
    "  hasil_prediksi_1 = nb_clf_1.predict(X_test)\n",
    "  df_hasil1 = pd.DataFrame(data={'hasil_prediksi':hasil_prediksi_1})\n",
    "  str_temp = f\"./{direktori}/run_aspek_{key}/hasil_prediksi_aspek_{key}_non_oversampling.xlsx\"\n",
    "  df_hasil1.to_excel(str_temp, encoding='utf-8')\n",
    "\n",
    "  print(\"Classification Report\")\n",
    "  print('\\n')\n",
    "  print(classification_report(y_test['label'], hasil_prediksi_1))\n",
    "  print('\\n')\n",
    "  print(\"Confusion Matrix\")\n",
    "  print('\\n')\n",
    "  print(confusion_matrix(y_test['label'], hasil_prediksi_1))\n",
    "  print('\\n')\n",
    "\n",
    "  # Klasifikasi dengan oversampling\n",
    "  kk=5\n",
    "  if (key == 'Edukasi' or key == 'Kebersihan'):\n",
    "    kk=3\n",
    "  else :\n",
    "    kk=5\n",
    "\n",
    "  smt = SMOTE(k_neighbors=kk)\n",
    "  nb = MultinomialNB()\n",
    "  pipeline = Pipeline([('smt', smt), ('nb', nb)])\n",
    "\n",
    "  # Setup GridSearchCV\n",
    "  grid_params = {\n",
    "    'nb__alpha': alphas,\n",
    "    'nb__fit_prior': [True, False]  \n",
    "  } # tuning hyperparameter untuk model multinomial Naive Bayes\n",
    "  nb_clf_2 = GridSearchCV(pipeline, grid_params, cv=5) # instansiasi method GridSearchCV\n",
    "  nb_clf_2.fit(X_train, y_train['label'])\n",
    "  \n",
    "  datas2={'best score':[nb_clf_2.best_score_], 'best_params' : [nb_clf_2.best_params_]}\n",
    "  hasil_1 = pd.DataFrame(data=datas2)\n",
    "  str_export2 = f\"./{direktori}/run_aspek_{key}/hasil_fit_non_oversampling_{key}.csv\"\n",
    "  hasil_1.to_csv(str_export2, sep=\";\", index=False)\n",
    "  \n",
    "  print(\"-Dengan Oversampling-\")\n",
    "  print(\"Best Score: \", nb_clf_2.best_score_)\n",
    "  print(\"Best Params: \", nb_clf_2.best_params_) \n",
    "  print('\\n')\n",
    "  \n",
    "  hasil_prediksi_2 = nb_clf_2.predict(X_test)\n",
    "  df_hasil2 = pd.DataFrame(data={'hasil_prediksi':hasil_prediksi_2})\n",
    "  str_temp2 = f\"./{direktori}/run_aspek_{key}/hasil_prediksi_aspek_{key}_oversampling.xlsx\"\n",
    "  df_hasil2.to_excel(str_temp2, encoding='utf-8')\n",
    "  \n",
    "  print(\"Classification Report\")\n",
    "  print('\\n')\n",
    "  print(classification_report(y_test['label'], hasil_prediksi_2))\n",
    "  print('\\n')\n",
    "  print(\"Confusion Matrix\")\n",
    "  print('\\n')\n",
    "  print(confusion_matrix(y_test['label'], hasil_prediksi_2))\n",
    "  print('\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "014iXhYz6lEh"
   },
   "source": [
    "## Klasifikasi All"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "mezvnRqpsaul",
    "outputId": "f8bc0b88-54ee-407d-d6e9-587d67de4bf3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========================================================================\n",
      "---Klasifikasi Aspek Umum---\n",
      "\n",
      "-Tanpa Oversampling-\n",
      "Best Score:  0.8304\n",
      "Best Params:  {'alpha': 1.2, 'fit_prior': True}\n",
      "\n",
      "\n",
      "Classification Report\n",
      "\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     negatif       0.00      0.00      0.00         8\n",
      "      netral       0.78      0.96      0.86       111\n",
      "     positif       0.90      0.71      0.80        90\n",
      "\n",
      "    accuracy                           0.82       209\n",
      "   macro avg       0.56      0.56      0.55       209\n",
      "weighted avg       0.80      0.82      0.80       209\n",
      "\n",
      "\n",
      "\n",
      "Confusion Matrix\n",
      "\n",
      "\n",
      "[[  0   5   3]\n",
      " [  0 107   4]\n",
      " [  0  26  64]]\n",
      "\n",
      "\n",
      "-Dengan Oversampling-\n",
      "Best Score:  0.8064\n",
      "Best Params:  {'nb__alpha': 0.3, 'nb__fit_prior': True}\n",
      "\n",
      "\n",
      "Classification Report\n",
      "\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     negatif       0.33      0.50      0.40         8\n",
      "      netral       0.87      0.88      0.88       111\n",
      "     positif       0.83      0.78      0.80        90\n",
      "\n",
      "    accuracy                           0.82       209\n",
      "   macro avg       0.68      0.72      0.69       209\n",
      "weighted avg       0.83      0.82      0.83       209\n",
      "\n",
      "\n",
      "\n",
      "Confusion Matrix\n",
      "\n",
      "\n",
      "[[ 4  2  2]\n",
      " [ 1 98 12]\n",
      " [ 7 13 70]]\n",
      "\n",
      "\n",
      "========================================================================\n",
      "---Klasifikasi Aspek Kebersihan---\n",
      "\n",
      "-Tanpa Oversampling-\n",
      "Best Score:  0.9492307692307692\n",
      "Best Params:  {'alpha': 0.1, 'fit_prior': True}\n",
      "\n",
      "\n",
      "Classification Report\n",
      "\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     negatif       1.00      0.50      0.67         2\n",
      "      netral       0.00      0.00      0.00         3\n",
      "     positif       0.94      1.00      0.97        61\n",
      "\n",
      "    accuracy                           0.94        66\n",
      "   macro avg       0.65      0.50      0.54        66\n",
      "weighted avg       0.90      0.94      0.92        66\n",
      "\n",
      "\n",
      "\n",
      "Confusion Matrix\n",
      "\n",
      "\n",
      "[[ 1  0  1]\n",
      " [ 0  0  3]\n",
      " [ 0  0 61]]\n",
      "\n",
      "\n",
      "-Dengan Oversampling-\n",
      "Best Score:  0.9593589743589744\n",
      "Best Params:  {'nb__alpha': 0.3, 'nb__fit_prior': True}\n",
      "\n",
      "\n",
      "Classification Report\n",
      "\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     negatif       0.50      0.50      0.50         2\n",
      "      netral       0.50      0.67      0.57         3\n",
      "     positif       0.98      0.97      0.98        61\n",
      "\n",
      "    accuracy                           0.94        66\n",
      "   macro avg       0.66      0.71      0.68        66\n",
      "weighted avg       0.95      0.94      0.94        66\n",
      "\n",
      "\n",
      "\n",
      "Confusion Matrix\n",
      "\n",
      "\n",
      "[[ 1  0  1]\n",
      " [ 1  2  0]\n",
      " [ 0  2 59]]\n",
      "\n",
      "\n",
      "========================================================================\n",
      "---Klasifikasi Aspek Edukasi---\n",
      "\n",
      "-Tanpa Oversampling-\n",
      "Best Score:  0.6955294117647058\n",
      "Best Params:  {'alpha': 1.5, 'fit_prior': False}\n",
      "\n",
      "\n",
      "Classification Report\n",
      "\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     negatif       0.50      1.00      0.67         1\n",
      "      netral       0.82      0.32      0.46        28\n",
      "     positif       0.75      0.96      0.84        56\n",
      "\n",
      "    accuracy                           0.75        85\n",
      "   macro avg       0.69      0.76      0.66        85\n",
      "weighted avg       0.77      0.75      0.72        85\n",
      "\n",
      "\n",
      "\n",
      "Confusion Matrix\n",
      "\n",
      "\n",
      "[[ 1  0  0]\n",
      " [ 1  9 18]\n",
      " [ 0  2 54]]\n",
      "\n",
      "\n",
      "-Dengan Oversampling-\n",
      "Best Score:  0.7505882352941177\n",
      "Best Params:  {'nb__alpha': 1.4, 'nb__fit_prior': True}\n",
      "\n",
      "\n",
      "Classification Report\n",
      "\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     negatif       0.50      1.00      0.67         1\n",
      "      netral       0.55      0.61      0.58        28\n",
      "     positif       0.81      0.75      0.78        56\n",
      "\n",
      "    accuracy                           0.71        85\n",
      "   macro avg       0.62      0.79      0.67        85\n",
      "weighted avg       0.72      0.71      0.71        85\n",
      "\n",
      "\n",
      "\n",
      "Confusion Matrix\n",
      "\n",
      "\n",
      "[[ 1  0  0]\n",
      " [ 1 17 10]\n",
      " [ 0 14 42]]\n",
      "\n",
      "\n",
      "========================================================================\n",
      "---Klasifikasi Aspek Pelayanan---\n",
      "\n",
      "-Tanpa Oversampling-\n",
      "Best Score:  0.7483870967741935\n",
      "Best Params:  {'alpha': 0.5, 'fit_prior': False}\n",
      "\n",
      "\n",
      "Classification Report\n",
      "\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     negatif       0.60      1.00      0.75         6\n",
      "      netral       0.79      0.90      0.84        21\n",
      "     positif       0.94      0.68      0.79        25\n",
      "\n",
      "    accuracy                           0.81        52\n",
      "   macro avg       0.78      0.86      0.80        52\n",
      "weighted avg       0.84      0.81      0.81        52\n",
      "\n",
      "\n",
      "\n",
      "Confusion Matrix\n",
      "\n",
      "\n",
      "[[ 6  0  0]\n",
      " [ 1 19  1]\n",
      " [ 3  5 17]]\n",
      "\n",
      "\n",
      "-Dengan Oversampling-\n",
      "Best Score:  0.761290322580645\n",
      "Best Params:  {'nb__alpha': 0.2, 'nb__fit_prior': True}\n",
      "\n",
      "\n",
      "Classification Report\n",
      "\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     negatif       0.67      1.00      0.80         6\n",
      "      netral       0.70      0.67      0.68        21\n",
      "     positif       0.83      0.76      0.79        25\n",
      "\n",
      "    accuracy                           0.75        52\n",
      "   macro avg       0.73      0.81      0.76        52\n",
      "weighted avg       0.76      0.75      0.75        52\n",
      "\n",
      "\n",
      "\n",
      "Confusion Matrix\n",
      "\n",
      "\n",
      "[[ 6  0  0]\n",
      " [ 3 14  4]\n",
      " [ 0  6 19]]\n",
      "\n",
      "\n",
      "========================================================================\n",
      "---Klasifikasi Aspek Fasilitas---\n",
      "\n",
      "-Tanpa Oversampling-\n",
      "Best Score:  0.796574074074074\n",
      "Best Params:  {'alpha': 0.7, 'fit_prior': False}\n",
      "\n",
      "\n",
      "Classification Report\n",
      "\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     negatif       0.97      0.82      0.89        34\n",
      "      netral       0.73      0.81      0.77        37\n",
      "     positif       0.88      0.89      0.88        64\n",
      "\n",
      "    accuracy                           0.85       135\n",
      "   macro avg       0.86      0.84      0.85       135\n",
      "weighted avg       0.86      0.85      0.85       135\n",
      "\n",
      "\n",
      "\n",
      "Confusion Matrix\n",
      "\n",
      "\n",
      "[[28  4  2]\n",
      " [ 1 30  6]\n",
      " [ 0  7 57]]\n",
      "\n",
      "\n",
      "-Dengan Oversampling-\n",
      "Best Score:  0.8115123456790124\n",
      "Best Params:  {'nb__alpha': 0.5, 'nb__fit_prior': True}\n",
      "\n",
      "\n",
      "Classification Report\n",
      "\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     negatif       0.94      0.85      0.89        34\n",
      "      netral       0.76      0.86      0.81        37\n",
      "     positif       0.89      0.86      0.87        64\n",
      "\n",
      "    accuracy                           0.86       135\n",
      "   macro avg       0.86      0.86      0.86       135\n",
      "weighted avg       0.86      0.86      0.86       135\n",
      "\n",
      "\n",
      "\n",
      "Confusion Matrix\n",
      "\n",
      "\n",
      "[[29  2  3]\n",
      " [ 1 32  4]\n",
      " [ 1  8 55]]\n",
      "\n",
      "\n",
      "========================================================================\n",
      "---Klasifikasi Aspek all_data---\n",
      "\n",
      "-Tanpa Oversampling-\n",
      "Best Score:  0.8061162079510703\n",
      "Best Params:  {'alpha': 1.1, 'fit_prior': False}\n",
      "\n",
      "\n",
      "Classification Report\n",
      "\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     negatif       0.69      0.69      0.69        42\n",
      "      netral       0.81      0.74      0.77       208\n",
      "     positif       0.82      0.87      0.85       295\n",
      "\n",
      "    accuracy                           0.81       545\n",
      "   macro avg       0.77      0.77      0.77       545\n",
      "weighted avg       0.81      0.81      0.81       545\n",
      "\n",
      "\n",
      "\n",
      "Confusion Matrix\n",
      "\n",
      "\n",
      "[[ 29   7   6]\n",
      " [  6 153  49]\n",
      " [  7  30 258]]\n",
      "\n",
      "\n",
      "-Dengan Oversampling-\n",
      "Best Score:  0.8042813455657493\n",
      "Best Params:  {'nb__alpha': 1.1, 'nb__fit_prior': True}\n",
      "\n",
      "\n",
      "Classification Report\n",
      "\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     negatif       0.53      0.79      0.63        42\n",
      "      netral       0.80      0.75      0.78       208\n",
      "     positif       0.87      0.84      0.86       295\n",
      "\n",
      "    accuracy                           0.81       545\n",
      "   macro avg       0.73      0.79      0.76       545\n",
      "weighted avg       0.82      0.81      0.81       545\n",
      "\n",
      "\n",
      "\n",
      "Confusion Matrix\n",
      "\n",
      "\n",
      "[[ 33   5   4]\n",
      " [ 18 157  33]\n",
      " [ 11  35 249]]\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from imblearn.pipeline import make_pipeline, Pipeline\n",
    "from sklearn.metrics import classification_report\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import warnings\n",
    "import os\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "\n",
    "all_data = {\n",
    "    \"Umum\" : {},\n",
    "    \"Kebersihan\" : {},\n",
    "    \"Edukasi\" : {},\n",
    "    \"Pelayanan\" : {},\n",
    "    \"Fasilitas\" : {},\n",
    "    \"all_data\" : {}\n",
    "}\n",
    "\n",
    "direktori = 'hasil'\n",
    "if not os.path.exists(f\"./{direktori}\"):\n",
    "  os.mkdir(direktori)\n",
    "\n",
    "# Read Data\n",
    "for key, val in all_data.items():\n",
    "  # membaca data excel/csv\n",
    "  tw_dir = f\"tfidf_{key}.xlsx\"\n",
    "  aspek_dir = f\"aspek{key}.xlsx\"\n",
    "  df_tw = pd.read_excel(tw_dir)\n",
    "  if \"Unnamed: 0\" in df_tw.columns :\n",
    "    df_tw = df_tw.drop(columns='Unnamed: 0')\n",
    "  df_aspek = pd.read_excel(aspek_dir)\n",
    "  if \"Unnamed: 0\" in df_aspek.columns :  \n",
    "    df_aspek = df_aspek.rename(columns = {'Unnamed: 0': 'id'})\n",
    "\n",
    "  \n",
    "\n",
    "  # memisahkan data dengan label\n",
    "  y = pd.DataFrame(data={'id' : df_aspek['id'], 'name' : df_aspek['name'], 'review' : df_aspek['formal-trans'] ,'aspek' : df_aspek['aspek'],'label':df_aspek['label']}) # data dengan label saja\n",
    "  X = df_tw\n",
    "\n",
    "  # Append to object\n",
    "  val[\"tfidf\"] = X\n",
    "  val[\"aspek\"] = y\n",
    "\n",
    "for key, val in all_data.items():\n",
    "  outdir = f'./{direktori}/run_aspek_{key}'\n",
    "  if not os.path.exists(outdir):\n",
    "    os.mkdir(outdir) \n",
    "  \n",
    "  # membagi data menjadi data train dan data test dengan ukuran data tes 25% dari jumlah data\n",
    "  print('========================================================================')\n",
    "  print(f\"---Klasifikasi Aspek {key}---\\n\")\n",
    "  X_train, X_test, y_train, y_test = train_test_split(val[\"tfidf\"], val[\"aspek\"], test_size=0.25, random_state=10)\n",
    "  str_export = f\"./hasil/run_aspek_{key}/y_test_{key}.xlsx\"\n",
    "  y_test.to_excel(str_export, encoding='utf-8', index=False)\n",
    "\n",
    "  # Klasifikasi tanpa oversampling\n",
    "  # Setup GridSearchCV\n",
    "  alphas = [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0, 1.1, 1.2, 1.3, 1.4, 1.5, 1.6, 1.7, 1.8, 1.9, 2.0]\n",
    "  clss_prior = [None, [.1,.9],[.2, .8]]\n",
    "  grid_params = {\n",
    "    'alpha': alphas,\n",
    "    'fit_prior': [True, False],\n",
    "  } # tuning hyperparameter untuk model multinomial Naive Bayes\n",
    "  nb_clf_1 = GridSearchCV(MultinomialNB(), grid_params, cv=5) # instansiasi method GridSearchCV\n",
    "  nb_clf_1.fit(X_train, y_train['label'])\n",
    "\n",
    "  datas={'best score':[nb_clf_1.best_score_], 'best_params' : [nb_clf_1.best_params_]}\n",
    "  hasil_1 = pd.DataFrame(data=datas)\n",
    "  str_export2 = f\"./{direktori}/run_aspek_{key}/hasil_fit_non_oversampling_{key}.csv\"\n",
    "  hasil_1.to_csv(str_export2, sep=\";\", index=False)\n",
    "  \n",
    "  print(\"-Tanpa Oversampling-\")\n",
    "  print(\"Best Score: \", nb_clf_1.best_score_)\n",
    "  print(\"Best Params: \", nb_clf_1.best_params_)\n",
    "  print('\\n')\n",
    "\n",
    "  hasil_prediksi_1 = nb_clf_1.predict(X_test)\n",
    "  df_hasil1 = pd.DataFrame(data={'hasil_prediksi':hasil_prediksi_1})\n",
    "  str_temp = f\"./{direktori}/run_aspek_{key}/hasil_prediksi_aspek_{key}_non_oversampling.xlsx\"\n",
    "  df_hasil1.to_excel(str_temp, encoding='utf-8', index=False)\n",
    "  y_test['prediksi_non_os'] = hasil_prediksi_1\n",
    "  y_test.to_excel(f\"./{direktori}/run_aspek_{key}/hasil_prediksi_aspek_{key}_non_oversampling_lengkap.xlsx\", encoding='utf-8', index=False)\n",
    "\n",
    "  print(\"Classification Report\")\n",
    "  print('\\n')\n",
    "  print(classification_report(y_test['label'], hasil_prediksi_1))\n",
    "  print('\\n')\n",
    "  print(\"Confusion Matrix\")\n",
    "  print('\\n')\n",
    "  print(confusion_matrix(y_test['label'], hasil_prediksi_1))\n",
    "  print('\\n')\n",
    "\n",
    "  # Klasifikasi dengan oversampling\n",
    "  kk=5\n",
    "  if (key == 'Edukasi' or key == 'Kebersihan'):\n",
    "    kk=3\n",
    "  else :\n",
    "    kk=5\n",
    "\n",
    "  smt = SMOTE(k_neighbors=kk)\n",
    "  nb = MultinomialNB()\n",
    "  pipeline = Pipeline([('smt', smt), ('nb', nb)])\n",
    "\n",
    "  # Setup GridSearchCV\n",
    "  grid_params = {\n",
    "    'nb__alpha': alphas,\n",
    "    'nb__fit_prior': [True, False]  \n",
    "  } # tuning hyperparameter untuk model multinomial Naive Bayes\n",
    "  nb_clf_2 = GridSearchCV(pipeline, grid_params, cv=5) # instansiasi method GridSearchCV\n",
    "  nb_clf_2.fit(X_train, y_train['label'])\n",
    "  \n",
    "  datas2={'best score':[nb_clf_2.best_score_], 'best_params' : [nb_clf_2.best_params_]}\n",
    "  hasil_1 = pd.DataFrame(data=datas2)\n",
    "  str_export2 = f\"./{direktori}/run_aspek_{key}/hasil_fit_non_oversampling_{key}.csv\"\n",
    "  hasil_1.to_csv(str_export2, sep=\";\", index=False)\n",
    "  \n",
    "  print(\"-Dengan Oversampling-\")\n",
    "  print(\"Best Score: \", nb_clf_2.best_score_)\n",
    "  print(\"Best Params: \", nb_clf_2.best_params_) \n",
    "  print('\\n')\n",
    "  \n",
    "  hasil_prediksi_2 = nb_clf_2.predict(X_test)\n",
    "  df_hasil2 = pd.DataFrame(data={'hasil_prediksi':hasil_prediksi_2})\n",
    "  str_temp2 = f\"./{direktori}/run_aspek_{key}/hasil_prediksi_aspek_{key}_oversampling.xlsx\"\n",
    "  df_hasil2.to_excel(str_temp2, encoding='utf-8')\n",
    "  y_test['prediksi_os'] = hasil_prediksi_2\n",
    "  y_test.to_excel(f\"./{direktori}/run_aspek_{key}/hasil_prediksi_aspek_{key}_oversampling_lengkap.xlsx\", encoding='utf-8', index=False)\n",
    "\n",
    "  \n",
    "  print(\"Classification Report\")\n",
    "  print('\\n')\n",
    "  print(classification_report(y_test['label'], hasil_prediksi_2))\n",
    "  print('\\n')\n",
    "  print(\"Confusion Matrix\")\n",
    "  print('\\n')\n",
    "  print(confusion_matrix(y_test['label'], hasil_prediksi_2))\n",
    "  print('\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "G6KkiqLNcEKY"
   },
   "source": [
    "## Klasifikasi 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "RdGpZF5EcLGC",
    "outputId": "3493ea1a-6b52-4e58-cb5b-4b89a3a11400"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/sklearn/externals/six.py:31: FutureWarning: The module is deprecated in version 0.21 and will be removed in version 0.23 since we've dropped support for Python 2.7. Please rely on the official version of six (https://pypi.org/project/six/).\n",
      "  \"(https://pypi.org/project/six/).\", FutureWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/utils/deprecation.py:144: FutureWarning: The sklearn.neighbors.base module is  deprecated in version 0.22 and will be removed in version 0.24. The corresponding classes / functions should instead be imported from sklearn.neighbors. Anything that cannot be imported from sklearn.neighbors is now part of the private API.\n",
      "  warnings.warn(message, FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========================================================================\n",
      "---Klasifikasi Aspek Edukasi---\n",
      "\n",
      "-Tanpa Oversampling-\n",
      "Best Score:  0.6955294117647058\n",
      "Best Params:  {'alpha': 1.5, 'fit_prior': False}\n",
      "\n",
      "\n",
      "Classification Report\n",
      "\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     negatif       0.50      1.00      0.67         1\n",
      "      netral       0.82      0.33      0.47        27\n",
      "     positif       0.76      0.96      0.85        57\n",
      "\n",
      "    accuracy                           0.76        85\n",
      "   macro avg       0.69      0.77      0.66        85\n",
      "weighted avg       0.78      0.76      0.73        85\n",
      "\n",
      "\n",
      "\n",
      "Confusion Matrix\n",
      "\n",
      "\n",
      "[[ 1  0  0]\n",
      " [ 1  9 17]\n",
      " [ 0  2 55]]\n",
      "\n",
      "\n",
      "-Dengan Oversampling-\n",
      "Best Score:  0.7308235294117648\n",
      "Best Params:  {'nb__alpha': 1.9, 'nb__fit_prior': True}\n",
      "\n",
      "\n",
      "Classification Report\n",
      "\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     negatif       0.25      1.00      0.40         1\n",
      "      netral       0.59      0.63      0.61        27\n",
      "     positif       0.85      0.77      0.81        57\n",
      "\n",
      "    accuracy                           0.73        85\n",
      "   macro avg       0.56      0.80      0.60        85\n",
      "weighted avg       0.76      0.73      0.74        85\n",
      "\n",
      "\n",
      "\n",
      "Confusion Matrix\n",
      "\n",
      "\n",
      "[[ 1  0  0]\n",
      " [ 2 17  8]\n",
      " [ 1 12 44]]\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from imblearn.pipeline import make_pipeline, Pipeline\n",
    "from sklearn.metrics import classification_report\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import warnings\n",
    "import os\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "\n",
    "all_data = {\n",
    "    # \"Umum\" : {},\n",
    "    # \"Kebersihan\" : {},\n",
    "    \"Edukasi\" : {},\n",
    "    # \"Pelayanan\" : {},\n",
    "    # \"Fasilitas\" : {},\n",
    "    # \"all_data\" : {}\n",
    "}\n",
    "\n",
    "direktori = 'hasil4'\n",
    "if not os.path.exists(f\"./{direktori}\"):\n",
    "  os.mkdir(direktori)\n",
    "\n",
    "# Read Data\n",
    "for key, val in all_data.items():\n",
    "  # membaca data excel/csv\n",
    "  tw_dir = f\"tfidf_{key}.xlsx\"\n",
    "  aspek_dir = f\"aspek{key}.xlsx\"\n",
    "  df_tw = pd.read_excel(tw_dir)\n",
    "  if \"Unnamed: 0\" in df_tw.columns :\n",
    "    df_tw = df_tw.drop(columns='Unnamed: 0')\n",
    "  df_aspek = pd.read_excel(aspek_dir)\n",
    "  if \"Unnamed: 0\" in df_aspek.columns :  \n",
    "    df_aspek = df_aspek.rename(columns = {'Unnamed: 0': 'id'})\n",
    "\n",
    "  # memisahkan data dengan label\n",
    "  y = pd.DataFrame(data={'id' : df_aspek['id'], 'name' : df_aspek['name'], 'review' : df_aspek['formal-trans'] ,'aspek' : df_aspek['aspek'],'label':df_aspek['label']}) # data dengan label saja\n",
    "  X = df_tw\n",
    "\n",
    "  # Append to object\n",
    "  val[\"tfidf\"] = X\n",
    "  val[\"aspek\"] = y\n",
    "\n",
    "for key, val in all_data.items():\n",
    "  outdir = f'./{direktori}/run_aspek_{key}'\n",
    "  if not os.path.exists(outdir):\n",
    "    os.mkdir(outdir) \n",
    "  \n",
    "  # membagi data menjadi data train dan data test dengan ukuran data tes 25% dari jumlah data\n",
    "  print('========================================================================')\n",
    "  print(f\"---Klasifikasi Aspek {key}---\\n\")\n",
    "  X_train, X_test, y_train, y_test = train_test_split(val[\"tfidf\"], val[\"aspek\"], test_size=0.25, random_state=10)\n",
    "  str_export = f\"./{direktori}/run_aspek_{key}/y_test_{key}.xlsx\"\n",
    "  y_test.to_excel(str_export, encoding='utf-8', index=False)\n",
    "\n",
    "  # Klasifikasi tanpa oversampling\n",
    "  # Setup GridSearchCV\n",
    "  alphas = [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0, 1.1, 1.2, 1.3, 1.4, 1.5, 1.6, 1.7, 1.8, 1.9, 2.0]\n",
    "  clss_prior = [None, [.1,.9],[.2, .8]]\n",
    "  grid_params = {\n",
    "    'alpha': alphas,\n",
    "    'fit_prior': [True, False],\n",
    "  } # tuning hyperparameter untuk model multinomial Naive Bayes\n",
    "  nb_clf_1 = GridSearchCV(MultinomialNB(), grid_params, cv=5) # instansiasi method GridSearchCV\n",
    "  nb_clf_1.fit(X_train, y_train['label'])\n",
    "\n",
    "  datas={'best score':[nb_clf_1.best_score_], 'best_params' : [nb_clf_1.best_params_]}\n",
    "  hasil_1 = pd.DataFrame(data=datas)\n",
    "  str_export2 = f\"./{direktori}/run_aspek_{key}/hasil_fit_non_oversampling_{key}.csv\"\n",
    "  hasil_1.to_csv(str_export2, sep=\";\", index=False)\n",
    "  \n",
    "  print(\"-Tanpa Oversampling-\")\n",
    "  print(\"Best Score: \", nb_clf_1.best_score_)\n",
    "  print(\"Best Params: \", nb_clf_1.best_params_)\n",
    "  print('\\n')\n",
    "\n",
    "  hasil_prediksi_1 = nb_clf_1.predict(X_test)\n",
    "  df_hasil1 = pd.DataFrame(data={'hasil_prediksi':hasil_prediksi_1})\n",
    "  str_temp = f\"./{direktori}/run_aspek_{key}/hasil_prediksi_aspek_{key}_non_oversampling.xlsx\"\n",
    "  df_hasil1.to_excel(str_temp, encoding='utf-8', index=False)\n",
    "  y_test['prediksi_non_os'] = hasil_prediksi_1\n",
    "  y_test.to_excel(f\"./{direktori}/run_aspek_{key}/hasil_prediksi_aspek_{key}_non_oversampling_lengkap.xlsx\", encoding='utf-8', index=False)\n",
    "\n",
    "  print(\"Classification Report\")\n",
    "  print('\\n')\n",
    "  print(classification_report(y_test['label'], hasil_prediksi_1))\n",
    "  print('\\n')\n",
    "  print(\"Confusion Matrix\")\n",
    "  print('\\n')\n",
    "  print(confusion_matrix(y_test['label'], hasil_prediksi_1))\n",
    "  print('\\n')\n",
    "\n",
    "  # Klasifikasi dengan oversampling\n",
    "  kk=5\n",
    "  if (key == 'Edukasi' or key == 'Kebersihan'):\n",
    "    kk=3\n",
    "  else :\n",
    "    kk=5\n",
    "\n",
    "  smt = SMOTE(k_neighbors=kk)\n",
    "  nb = MultinomialNB()\n",
    "  pipeline = Pipeline([('smt', smt), ('nb', nb)])\n",
    "\n",
    "  # Setup GridSearchCV\n",
    "  grid_params = {\n",
    "    'nb__alpha': alphas,\n",
    "    'nb__fit_prior': [True, False]  \n",
    "  } # tuning hyperparameter untuk model multinomial Naive Bayes\n",
    "  nb_clf_2 = GridSearchCV(pipeline, grid_params, cv=5) # instansiasi method GridSearchCV\n",
    "  nb_clf_2.fit(X_train, y_train['label'])\n",
    "  \n",
    "  datas2={'best score':[nb_clf_2.best_score_], 'best_params' : [nb_clf_2.best_params_]}\n",
    "  hasil_1 = pd.DataFrame(data=datas2)\n",
    "  str_export2 = f\"./{direktori}/run_aspek_{key}/hasil_fit_non_oversampling_{key}.csv\"\n",
    "  hasil_1.to_csv(str_export2, sep=\";\", index=False)\n",
    "  \n",
    "  print(\"-Dengan Oversampling-\")\n",
    "  print(\"Best Score: \", nb_clf_2.best_score_)\n",
    "  print(\"Best Params: \", nb_clf_2.best_params_) \n",
    "  print('\\n')\n",
    "  \n",
    "  hasil_prediksi_2 = nb_clf_2.predict(X_test)\n",
    "  df_hasil2 = pd.DataFrame(data={'hasil_prediksi':hasil_prediksi_2})\n",
    "  str_temp2 = f\"./{direktori}/run_aspek_{key}/hasil_prediksi_aspek_{key}_oversampling.xlsx\"\n",
    "  df_hasil2.to_excel(str_temp2, encoding='utf-8')\n",
    "  y_test['prediksi_os'] = hasil_prediksi_2\n",
    "  y_test.to_excel(f\"./{direktori}/run_aspek_{key}/hasil_prediksi_aspek_{key}_oversampling_lengkap.xlsx\", encoding='utf-8', index=False)\n",
    "\n",
    "  \n",
    "  print(\"Classification Report\")\n",
    "  print('\\n')\n",
    "  print(classification_report(y_test['label'], hasil_prediksi_2))\n",
    "  print('\\n')\n",
    "  print(\"Confusion Matrix\")\n",
    "  print('\\n')\n",
    "  print(confusion_matrix(y_test['label'], hasil_prediksi_2))\n",
    "  print('\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "D9gsuNLdamTP"
   },
   "source": [
    "## Klasifikasi 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "YDilQpKtapi1"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from imblearn.pipeline import make_pipeline, Pipeline\n",
    "from sklearn.metrics import classification_report\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import warnings\n",
    "import os\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Read Data\n",
    "# membaca data excel/csv\n",
    "df_tw = pd.read_excel(\"tfidf\")\n",
    "df_tw = df_tw.drop(columns='Unnamed: 0')\n",
    "\n",
    "df_aspek = pd.read_excel(\"aspek\")\n",
    "df_aspek = df_aspek.rename(columns = {'Unnamed: 0': 'id'})\n",
    "\n",
    "  \n",
    "# memisahkan data dengan label\n",
    "y = pd.DataFrame(data={'id' : df_aspek['id'], 'name' : df_aspek['name'], 'review' : df_aspek['formal-trans'] ,'aspek' : df_aspek['aspek'],'label':df_aspek['label']}) # data dengan label saja\n",
    "X = df_tw\n",
    "\n",
    "# membagi data menjadi data train dan data test dengan ukuran data tes 25% dari jumlah data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=10)\n",
    "y_test.to_excel(\"y_test.xlsx\", encoding='utf-8', index=False)\n",
    "\n",
    "# Klasifikasi tanpa oversampling\n",
    "# Setup GridSearchCV\n",
    "alphas = [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0, 1.1, 1.2, 1.3, 1.4, 1.5, 1.6, 1.7, 1.8, 1.9, 2.0]\n",
    "grid_params = {\n",
    "  'alpha': alphas,\n",
    "  'fit_prior': [True, False],\n",
    "} # tuning hyperparameter untuk model multinomial Naive Bayes\n",
    "nb_clf_1 = GridSearchCV(MultinomialNB(), grid_params, cv=5) # instansiasi method GridSearchCV\n",
    "nb_clf_1.fit(X_train, y_train['label'])\n",
    "\n",
    "datas={'best score':[nb_clf_1.best_score_], 'best_params' : [nb_clf_1.best_params_]}\n",
    "hasil_1 = pd.DataFrame(data=datas)\n",
    "hasil_1.to_csv(\"best_train\", sep=\";\", index=False)\n",
    "print(\"Best Score: \", nb_clf_1.best_score_)\n",
    "print(\"Best Params: \", nb_clf_1.best_params_)\n",
    "\n",
    "hasil_prediksi = nb_clf_1.predict(X_test)\n",
    "y_test['prediksi_non_os'] = hasil_prediksi_1\n",
    "y_test.to_excel(\"hasilprediksi\", encoding='utf-8', index=False)\n",
    "\n",
    "print(classification_report(y_test['label'], hasil_prediksi_1))\n",
    "print(confusion_matrix(y_test['label'], hasil_prediksi_1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HrokV3V8ryQ0"
   },
   "source": [
    "# KLASIFIKASI SVM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UURIXj8kr7rb"
   },
   "source": [
    "## Split Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mMOtsTY2r3NR"
   },
   "outputs": [],
   "source": [
    "# Step 1: Split Train & Test Data\n",
    "# Import the libraries needed\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Read data from Excel file\n",
    "df_aspek = pd.read_excel('aspekPelayanan.xlsx')\n",
    "df_tw = pd.read_excel('tfidf_pelayanan.xlsx')\n",
    "\n",
    "# Identifies the X and y values\n",
    "X = df_tw # took all feature values of weighting\n",
    "y = df_aspek['label'] # only took sentiment label feature \n",
    "\n",
    "# Split the data into train data and test data with a test data size 25% of the total data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1ER3SdxTr-gj"
   },
   "source": [
    "## Memilih Model dan Melatih Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ML2ZsqJEsKsr",
    "outputId": "c32fddf8-b69f-47f6-e445-d37d277b7df4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Score:  0.7615686274509803\n",
      "Best Params:  {'dual': False, 'multi_class': 'ovr'}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Setup GridSearchCV\n",
    "# Tuning hyperparameter untuk model Support Vector Classifier\n",
    "grid_params = {\n",
    "  #'C': [0.01, 0.1, 1, 10, 100, 1000],\n",
    "  'multi_class' : ['ovr', 'crammer_singer'],\n",
    "  'dual' : [True, False]\n",
    "  #'class_weight' : [{0:100,1:1}, {0:10,1:1}, {0:1,1:1}, {0:1,1:10}, {0:1,1:100}]\n",
    "} \n",
    "\n",
    "# instansiasi method GridSearchCV\n",
    "svm_clf_1 = GridSearchCV(LinearSVC(), grid_params, cv=5) # instansiasi method GridSearchCV\n",
    "svm_clf_1.fit(X_train, y_train)\n",
    "\n",
    "print(\"Best Score: \", svm_clf_1.best_score_)\n",
    "print(\"Best Params: \", svm_clf_1.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KHDyE33zmeI4"
   },
   "source": [
    "## Imbalance Validation Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "CLnuKakzmyNQ",
    "outputId": "59337d44-5b0d-4877-a7f1-61e971d01821"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Score:  nan\n",
      "Best Params:  {'svc__dual': True, 'svc__multi_class': 'ovr'}\n"
     ]
    }
   ],
   "source": [
    "# Step 2: Set Classifier Optimazion with Oversampling\n",
    "# Import the libraries needed\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from imblearn.pipeline import make_pipeline, Pipeline\n",
    "from imblearn.over_sampling import SMOTE\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore') \n",
    "\n",
    "# Define the oversampling method \n",
    "#smt = SMOTE(k_neighbors=3) # khusus edukasi aja karena kelas negatifnya dikit\n",
    "smt = SMOTE() # untuk selain edukasi\n",
    "# Define the classifier\n",
    "svc = LinearSVC()\n",
    "# Define the pipeline\n",
    "pipeline = Pipeline([('smt', smt), ('svc', svc)])\n",
    "\n",
    "# Setup GridSearchCV\n",
    "#balance = [{0:100,1:1}, {0:10,1:1}, {0:1,1:1}, {0:1,1:10}, {0:1,1:100}]\n",
    "grid_params = {\n",
    "  #'svc__C': [0.01, 0.1, 1, 10, 100, 1000],\n",
    "  'svc__multi_class' : ['ovr', 'crammer_singer'],\n",
    "  'svc__dual' : [True, False]\n",
    "  #'svc__class_weight' : [{0:100,1:1}, {0:10,1:1}, {0:1,1:1}, {0:1,1:10}, {0:1,1:100}]\n",
    "} \n",
    "\n",
    "# instansiasi method GridSearchCV\n",
    "svm_clf_2 = GridSearchCV(pipeline, grid_params, cv=5) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rVAGReS0sDm0"
   },
   "source": [
    "## Melakukan Klasifikasi / Predict Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "b_gPt2IOsNCz"
   },
   "outputs": [],
   "source": [
    "# melakukan prediksi dengan model yang sudah di train sebelumnya\n",
    "hasil_prediksi_biasa = svm_clf_1.predict(X_test)\n",
    "hasil_prediksi_oversampling = svm_clf_2.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GT10f-UXsGjK"
   },
   "source": [
    "## Classification Report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "rbYflRPqsOZt",
    "outputId": "5e3b6f14-a6f3-4e73-ea0b-8d16fca461d0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tanpa Oversampling\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     negatif       0.00      0.00      0.00         1\n",
      "      netral       0.67      0.55      0.60        29\n",
      "     positif       0.77      0.85      0.81        55\n",
      "\n",
      "    accuracy                           0.74        85\n",
      "   macro avg       0.48      0.47      0.47        85\n",
      "weighted avg       0.73      0.74      0.73        85\n",
      "\n",
      "\n",
      "Dengan Oversampling\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     negatif       0.33      1.00      0.50         1\n",
      "      netral       0.71      0.17      0.28        29\n",
      "     positif       0.69      0.95      0.80        55\n",
      "\n",
      "    accuracy                           0.68        85\n",
      "   macro avg       0.58      0.71      0.53        85\n",
      "weighted avg       0.70      0.68      0.62        85\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# Tanpa Oversampling\n",
    "print(\"Tanpa Oversampling\")\n",
    "print(classification_report(y_test, hasil_prediksi_biasa))\n",
    "print()\n",
    "\n",
    "# Dengan Oversampling\n",
    "print(\"Dengan Oversampling\")\n",
    "print(classification_report(y_test, hasil_prediksi_oversampling))\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "gH-gyftuofOk",
    "outputId": "32eca9e0-99c0-4b9d-b47b-06ff6ff12e36"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "276    negatif\n",
       "169    negatif\n",
       "166    negatif\n",
       "158    negatif\n",
       "Name: label, dtype: object"
      ]
     },
     "execution_count": 31,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train[y_train=='negatif']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aolrED6qZAIv"
   },
   "source": [
    "## klasifikasi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "TGbfVWZBZFr1"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from imblearn.pipeline import make_pipeline, Pipeline\n",
    "from sklearn.metrics import classification_report\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import warnings\n",
    "import os\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Read Data\n",
    "# membaca data excel/csv\n",
    "df_tw = pd.read_excel(\"tfidf\")\n",
    "df_tw = df_tw.drop(columns='Unnamed: 0')\n",
    "\n",
    "df_aspek = pd.read_excel(\"aspek\")\n",
    "df_aspek = df_aspek.rename(columns = {'Unnamed: 0': 'id'})\n",
    "\n",
    "  \n",
    "# memisahkan data dengan label\n",
    "y = pd.DataFrame(data={'id' : df_aspek['id'], 'name' : df_aspek['name'], 'review' : df_aspek['formal-trans'] ,'aspek' : df_aspek['aspek'],'label':df_aspek['label']}) # data dengan label saja\n",
    "X = df_tw\n",
    "\n",
    "# membagi data menjadi data train dan data test dengan ukuran data tes 25% dari jumlah data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=10)\n",
    "y_test.to_excel(\"y_test.xlsx\", encoding='utf-8', index=False)\n",
    "\n",
    "# Klasifikasi tanpa oversampling\n",
    "# Setup GridSearchCV\n",
    "alphas = [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0, 1.1, 1.2, 1.3, 1.4, 1.5, 1.6, 1.7, 1.8, 1.9, 2.0]\n",
    "grid_params = {\n",
    "  'alpha': alphas,\n",
    "  'fit_prior': [True, False],\n",
    "} # tuning hyperparameter untuk model multinomial Naive Bayes\n",
    "nb_clf_1 = GridSearchCV(MultinomialNB(), grid_params, cv=5) # instansiasi method GridSearchCV\n",
    "nb_clf_1.fit(X_train, y_train['label'])\n",
    "\n",
    "datas={'best score':[nb_clf_1.best_score_], 'best_params' : [nb_clf_1.best_params_]}\n",
    "hasil_1 = pd.DataFrame(data=datas)\n",
    "hasil_1.to_csv(\"best_train\", sep=\";\", index=False)\n",
    "print(\"Best Score: \", nb_clf_1.best_score_)\n",
    "print(\"Best Params: \", nb_clf_1.best_params_)\n",
    "\n",
    "hasil_prediksi = nb_clf_1.predict(X_test)\n",
    "y_test['prediksi_non_os'] = hasil_prediksi_1\n",
    "y_test.to_excel(\"hasilprediksi\", encoding='utf-8', index=False)\n",
    "\n",
    "print(classification_report(y_test['label'], hasil_prediksi_1))\n",
    "print(confusion_matrix(y_test['label'], hasil_prediksi_1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ko3Hoiafby7W"
   },
   "source": [
    "# Analisis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6l_aECI3b1DJ"
   },
   "source": [
    "## Unigram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "EnEYzZLkb37d",
    "outputId": "18269479-59c4-4c75-c75e-86a5c06c1dbb"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:29: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:30: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:31: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "all_datas = {\n",
    "    \"Umum\" : [],\n",
    "    \"Kebersihan\" : [],\n",
    "    \"Edukasi\" : [],\n",
    "    \"Pelayanan\" : [],\n",
    "    \"Fasilitas\" : []\n",
    "}\n",
    "\n",
    "def join(text):\n",
    "  text = text.replace('[','')\n",
    "  text = text.replace(']','')\n",
    "  text = text.replace(',','')\n",
    "  text = text.replace(\"'\",\"\")\n",
    "  return text\n",
    "\n",
    "# Read Data\n",
    "for key, val in all_datas.items():\n",
    "  # membaca data excel/csv\n",
    "  aspek_dir = f\"aspek{key}.xlsx\"\n",
    "  df = pd.read_excel(aspek_dir).rename(columns = {'Unnamed: 0': 'id'})\n",
    "  df_negatif = df[df['label'] == 'negatif']\n",
    "  df_netral = df[df['label'] == 'netral']\n",
    "  df_positif = df[df['label'] == 'positif']\n",
    "\n",
    "  df_negatif['process'] = df_negatif['final preprocessing'].apply(lambda x: join(x))\n",
    "  df_netral['process'] = df_netral['final preprocessing'].apply(lambda x: join(x))\n",
    "  df_positif['process'] = df_positif['final preprocessing'].apply(lambda x: join(x))\n",
    "\n",
    "  cv_negatif = CountVectorizer()\n",
    "  cv_netral = CountVectorizer()\n",
    "  cv_positif = CountVectorizer()\n",
    "  cv_fit_negatif = cv_negatif.fit_transform(df_negatif['process']).toarray().sum(axis=0)\n",
    "  cv_fit_netral = cv_netral.fit_transform(df_netral['process']).toarray().sum(axis=0)\n",
    "  cv_fit_positif = cv_positif.fit_transform(df_positif['process']).toarray().sum(axis=0)\n",
    "  \n",
    "  unigram_negatif = pd.DataFrame(data={\n",
    "      \"kata\" : cv_negatif.get_feature_names(), \n",
    "      \"jumlah\" : cv_fit_negatif\n",
    "  })\n",
    "  unigram_netral = pd.DataFrame(data={\n",
    "      \"kata\" : cv_netral.get_feature_names(), \n",
    "      \"jumlah\" : cv_fit_netral\n",
    "  })\n",
    "  unigram_positif = pd.DataFrame(data={\n",
    "      \"kata\" : cv_positif.get_feature_names(), \n",
    "      \"jumlah\" : cv_fit_positif\n",
    "  })\n",
    "\n",
    "  unigram_negatif.to_excel(f\"unigram_{key}_negatif.xlsx\", encoding='utf-8', index=False)\n",
    "  unigram_netral.to_excel(f\"unigram_{key}_netral.xlsx\", encoding='utf-8', index=False)\n",
    "  unigram_positif.to_excel(f\"unigram_{key}_positif.xlsx\", encoding='utf-8', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "93LPmIlYKHoT"
   },
   "source": [
    "## Bigram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 448
    },
    "id": "IbJ5Jao9Kouh",
    "outputId": "0497aaed-ba92-441f-9bd6-9580e18476a8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>term</th>\n",
       "      <th>rank</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>acara bazar</td>\n",
       "      <td>0.938879</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>acara tjangkroean</td>\n",
       "      <td>0.243413</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>adakan hias</td>\n",
       "      <td>0.273840</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>adem tidak</td>\n",
       "      <td>0.168517</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>agak kotor</td>\n",
       "      <td>1.314431</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>agung sedap</td>\n",
       "      <td>0.730239</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>air ganjil</td>\n",
       "      <td>0.212005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>air keran</td>\n",
       "      <td>0.273840</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>air nikmat</td>\n",
       "      <td>0.262886</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>ajak anak</td>\n",
       "      <td>0.505550</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                term      rank\n",
       "0        acara bazar  0.938879\n",
       "1  acara tjangkroean  0.243413\n",
       "2        adakan hias  0.273840\n",
       "3         adem tidak  0.168517\n",
       "4         agak kotor  1.314431\n",
       "5        agung sedap  0.730239\n",
       "6         air ganjil  0.212005\n",
       "7          air keran  0.273840\n",
       "8         air nikmat  0.262886\n",
       "9          ajak anak  0.505550"
      ]
     },
     "execution_count": 15,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "from sklearn.preprocessing import normalize\n",
    "import pandas as pd\n",
    "\n",
    "df_bigram = pd.read_excel('aspekKebersihan.xlsx')\n",
    "\n",
    "# ngram_range (1, 3) to use unigram, bigram, trigram\n",
    "cvect = CountVectorizer(ngram_range=(2,2))\n",
    "counts = cvect.fit_transform(df_bigram['final preprocessing'])\n",
    "\n",
    "normalized_counts = normalize(counts, norm='l1', axis=1)\n",
    "\n",
    "tf_idf = TfidfVectorizer(ngram_range=(2,2), smooth_idf=False)\n",
    "tfs = tf_idf.fit_transform(df_bigram['final preprocessing'])\n",
    "\n",
    "tfidf_mat = normalized_counts.multiply(tf_idf.idf_).toarray()\n",
    "print(tfidf_mat)\n",
    "\n",
    "#Ranking\n",
    "terms = tf_idf.get_feature_names()\n",
    "\n",
    "# sum tfidf frequency of each term through documents\n",
    "sums = tfidf_mat.sum(axis=0)\n",
    "\n",
    "# connecting term to its sums frequency\n",
    "data = []\n",
    "for col, term in enumerate(terms):\n",
    "  data.append((term, sums[col] ))\n",
    "\n",
    "ranking = pd.DataFrame(data, columns=['term','rank'])\n",
    "# ranking.sort_values(by = 'rank', ascending=False)\n",
    "ranking.head(10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-87Ez66XcG7S"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "all_datas = {\n",
    "    \"Umum\" : [],\n",
    "    \"Kebersihan\" : [],\n",
    "    \"Edukasi\" : [],\n",
    "    \"Pelayanan\" : [],\n",
    "    \"Fasilitas\" : []\n",
    "}\n",
    "\n",
    "# Read Data\n",
    "for key, val in all_datas.items():\n",
    "  # membaca data excel/csv\n",
    "  aspek_dir = f\"aspek{key}.xlsx\"\n",
    "  all_datas[key] = pd.read_excel(aspek_dir)['final preprocessing']\n",
    "\n",
    "for key, val in all_datas.items():\n",
    "  cv = CountVectorizer(ngram_range=(2,2))\n",
    "  cv_fit = cv.fit_transform(val)\n",
    "  word_list = cv.get_feature_names()\n",
    "  count_list = cv_fit.toarray().sum(axis=0)\n",
    "\n",
    "  term = pd.DataFrame(count_list, word_list, columns = [\"frequency\"])\n",
    "  # print(term)\n",
    "  term.to_excel(f'bigram_{key}.xlsx',encoding='utf-8' )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xU_XcC6eb-h9"
   },
   "source": [
    "## Trigam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "PJq2_nDXbAIS"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "all_datas = {\n",
    "    \"Umum\" : [],\n",
    "    \"Kebersihan\" : [],\n",
    "    \"Edukasi\" : [],\n",
    "    \"Pelayanan\" : [],\n",
    "    \"Fasilitas\" : []\n",
    "}\n",
    "\n",
    "# Read Data\n",
    "for key, val in all_datas.items():\n",
    "  # membaca data excel/csv\n",
    "  aspek_dir = f\"aspek{key}.xlsx\"\n",
    "  # all_datas[key] = pd.read_excel(aspek_dir)['tokenizing']\n",
    "  df = pd.read_excel(aspek_dir)\n",
    "  all_datas[key] = df[df[\"label\"] == \"negatif\"]['tokenizing']\n",
    "\n",
    "for key, val in all_datas.items():\n",
    "  cv = CountVectorizer(ngram_range=(3,3))\n",
    "  cv_fit = cv.fit_transform(val)\n",
    "  word_list = cv.get_feature_names()\n",
    "  count_list = cv_fit.toarray().sum(axis=0)\n",
    "\n",
    "  term = pd.DataFrame(count_list, word_list, columns = [\"frequency\"])\n",
    "  # print(term)\n",
    "  term.to_excel(f'trigram{key}_tokenize_negatif.xlsx',encoding='utf-8' )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "IG3rC-8ffLak",
    "outputId": "85cdfe18-aa7d-463c-951d-0c6a0cfb0f79"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "158    ['anak', 'anak', 'kurang', 'tertarik', 'belaja...\n",
       "166    ['niat', 'untuk', 'mengerjakan', 'tugas', 'tet...\n",
       "169    ['darmawisata', 'ke', 'sini', 'sama', 'anak', ...\n",
       "174    ['anak', 'saya', 'diajak', 'ke', 'sini', 'kok'...\n",
       "276    ['kurang', 'banyak', 'untuk', 'menambah', 'edu...\n",
       "Name: tokenizing, dtype: object"
      ]
     },
     "execution_count": 5,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_excel(\"aspekEdukasi.xlsx\")\n",
    "df = df[df[\"label\"] == \"negatif\"]['tokenizing']\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "W_jELC1pmAyF"
   },
   "source": [
    "## Komen Terbanyak\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pTMWSw9_O5pw"
   },
   "source": [
    "## Juplek"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "s3xdt27SmDWl",
    "outputId": "741f9b2d-6ac0-4e37-e9f6-3b6e7805215d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "taman tugu pahlawan biasa jadi tempat santa olahraga warga unjung tugu pahlawan monumen tugu pahlawan beberapa kendara zaman merdeka museum taman pahlawan biasa jadi demo juang merdeka tanggal sepeda putar tugu pahlawan lokasi strategis tempat luas puas kalau mau keliling keliling konsep keren seru tetapi kesini siang siang jangan lupa bawa topi cuaca panas monumen jajah museum lihat bagai dokumentasi bangun tugu pahlawan masa lalu monumen bangun bagai ingat tempur rupa tempat wisata cocok rupa cinta wisata sejarah bagai tuju wisata sama keluarga sekadar duduk santai nikmat milir angin tengah rumput hijau kawasan tugu pahlawan tempat sejarah rawat luas kawasan alun alun upa fasilitas upa trotoar kanopi keliling area alun alun makin manja kala telusur kawasan tugu pahlawan bahkan trotoar lengkap tempat duduk ciri khas jumpa unjung tugu patung proklamator indonesia soekarno drs moh hatta ukur besar objek wisata kunjung kawasan tugu pahlawan museum museum diri lantai tampung jumlah tinggal sejarah putar peristiwa saji kisah heroik arek arek cara tarik lewat bagai media sepet foto film diorama salah satu objek wisata pusat biasa kunjung wisatawan tiap hari minggu tempat sangat ramai kunjung bagai tempat olahraga banyak dagang kaki lima jual enak buat lari pelan pelan pagi banyak meja tidak fungsi buat jarak antar langgan sangat representasi pahlawan juang arek arek lawan jajah masa merdeka lokasi tugu cukup bersih luas fasilitas dukung museum kunjung isi ratus koleksi tinggal juang jajah sangat bagus museum taman tempat rekreasi sarana prasarana lengkap dukung tiap butuh orang sedang aktivitas banyak simpan barang kuno monumen sejarah museum bagus ikon pahlawan populer lengkap museum ruang diorama videorama rapi fasilitas tempat favorit buru barang bekas sekali jalan jalan sepeda santai hari minggu tempat pas buat rakyat lepas penat hari olahraga badminton sehat nikmat jajan tradisional belanja butuh tetapi waktu hari minggu ramai dagang asong mudah jangkau dekat jalan raya tempat sangat luas tempat sejarah monumen tugu pahlawan tuju bagai pahlawan terus museum tuju peristiwa penuh sejarah cerita warga lawan belanda bebas senjata tempat tempat nyaman main anak anak keluarga lebih mudah awas bagus foto tiap minggu paling ramai olahraga pagi pacar main main sama keluarga jajan banyak tempat bagus malam hari sangat cantik banyak lampu warna warninya tempat sangat besar lokasi bagus semua awat urus tempat bagus buat foto foto luas ramai perlu renovasi lebih atraktif monumen juang rakyat ruang buka luas taman kolam ikan arca tinggal perang museum bagus jalan pahlawan patung bapak soekarno wakil bapak moh hatta sedang proklamasi merdeka republik indonesia tanggal diri tegak sambut tugu pahlawan museum indonesia buah museum letak bawah monumen museum tunjuk banyak barang sejarah tempur diorama cerita tempur halaman monumen temu beberapa patung pahlawan libat tempur tomo beberapa studio tampil video suara rekam sejarah juang pahlawan toilet sembunyi bawah tugu pahlawan museum juang pajang bagai senjata lama juang lengkap lihat monumen pahlawan dokumentasi sejarah dengar pidato tomo lihat pamer senjata juang waktu diorama pagi hari minggu ramai orang jual parkir motor mobil pinggir jalan tugu pahlawan museum puluh tengah tengah mana sini monumen museum juang lahan tugu pahlawan museum puluh sangat luas sama alun alun parkir luas tak jarang beberapa bus pariwisata mampir sini tempat bagus sangat bagus jadi tempat foto lihat bagai koleksi sejarah museum apabila hari minggu tempat ramai kaget barang paling suka cari pakai bekas haha museum putar singkat tempur diorama diorama keren banget luar biasa indah asyik olahraga pagi belanja pakai murah cocok buat olahraga tempat bersih parkir banyak koleksi museum makin lengkap tata taman rapi halaman sangat luas taman cantik aksesibilitas teman difabel oke inti buat olahraga tempat bersih rapi jalan parkir monumen manja tanam spot foto rekomendasi segala usia sedia pandu tani masuk hingga selesai putar film pasuk area hampar lapang sangat luas tengah tengah diri megah buah tugu julang tinggi sisi utara bangun upa museum diorama gambar juang arek arek rebut merdeka situ tonton film juang taman istirahat jenak meditasi piknik warga taman bersih lumayan luas seru teatrikal tugu pahlawan lokasi mudah jangkau kendara pribadi maupun angkut umum parkir motor mobil sangat luas masuk area tugu pahlawan lihat hampar rumput hijau lapang sepak bola kanan kiri taman bunga tutup kanopi monumen pahlawan senjata perang mobil tua sejarah museum bawah tanah taman bunga tiap tanggal sering acara ingat peristiwa tahun drama treatikal tualang senang tempat museum keren banget interior tempat olahraga tugu tinggi awat sangat baik keliling kanopi keliling lapang tugu mirip stonehenge patung pak soekarno pak hatta gagah berani tempat keren indah tata sangat bagus museum juang lengkap sejarah teknologi baru nikmat anak anak ruang berac jadi tidak takut panas kondisi panas ac perlu baik tempat keren lokasi ikonik museum bawah tugu pahlawan lokasi sangat gampang temu cuma agak hati hati bawa kendara mobil sendiri perhati marka jalan banyak polisi siap tilang salah marka makin bagus barang tinggal masa juang pampang awat bersih kenal manca negara tugu pahlawan bagus foto cocok instragram monumen ciri khas bentuk paku balik sering jadi ajang lomba jadi titik mulai henti diorama statis banyak tempat jadi foto cocok libur sama anak tempat cocok buat lari pelan pelan rekreasi buat orang suka tempat sejarah nih tarik buat suka foto dar manja mata tempat bagus nyaman banyak sekali benda benda sejarah lukis ajar sana tempat lihat sejarah peperangan dulu sana ruang auditorium jadi buat malas baca tinggal tekan main terus dengar koleksi senjata keren banget tembak suar bagus bersih cocok buat foto foto kecil kecil sama olahraga tanam bagus taman cukup bagus tempat santa ramai tempat sejarah rupa tinggal leluhur juang sekarang sangat bagus buat foto foto segera kunjung tugu pahlawan biar tidak penasaran keren banyak spot foto lingkung panas kak tempat sejarah cocok acara acara sekolah ajar sejarah museum gambar juang juang pahlawan dulu gambar miniatur miniatur museum tempat bagus banyak pohon tata rapi museum tempat luas bagus jadi swafoto tempat sejarah spot foto bagus monumen indah seluruh taman indah anak anak sekolah laku olahraga taman pagi hari orang tua temu lari meditasi tempat bagus piknik tempat bagus libur foto foto fasilitas toilet makin sangat historis museum bawah tanah lengkap asa hati main sana dekat dekat tanggal dengar pidato banyak spot foto buat milenial dekat masjid masjid bersih ac spot rekomendasi buat foto swafoto maupun foto ramai ramai tidak kapok tugu pahlawan ayo ajak keluarga maupun kerabat tugu pahlawan cus pohon biasa lari pelan pelan sore hari museum banyak spot foto saran kesini pagi sore hari cuma kalo hujan lumayan basah kuyup bagai tempat sana lapang main area istirahat museum spot foto upa ornamen sejarah banyak tinggal tinggal sejarah perang patung patung pahlawan mantap sangat dukung latih fisik khusus olahraga lari tempat dukung ramai mbak mbak cantik hari minggu tahu tempat sejarah waris temu sana sempat kecoh sama tulis parkir mobil penuh padahal kondisi parkir kosong nyata tulis tidak halang pintu masuk mobil kok kalau main monumen tugu pahlawan jangan cuma foto foto sekali masuk museum dong kalau minggu hari libur putar diorama elektrik keren banget jadi lebih erti sejarah cara asyik lingkung nyaman lalu kali unjung tempat turun jalan sama teman teman mahasiswa suara adil waktu siang hari panas saudara haha tempat bagus swafoto sayang listrik mati monumen tugu pahlawan sangat bagus cocok buat foto foto kemarin tanggal januari tugu pahlawan drama kolosal juang butuh parkir khusus sepeda ajar sejarah juang arek arek zaman merdeka tahun sini sangat komplit diorama senjata senjata zaman tinggal laku sejarah juang namun panas karna tidak ac ac hanya ruang dimensi ruang umum tidak ac tempat lapang anak main luar ruang luas bagus tiap minggu cocok buat jalan jalan pagi temu monumen tinggi tugu patung soekarno wakil hatta tempat fungsi bagai taman biasa minggu pagi sore hari keluarga laku semua jenis giat olahraga harap jadi sangat penuh hari minggu pagi panas monumen tugu pahlawan museum tidak masuk tempat sejarah pahlawan tembok depan tugu pahlawan banyak relief gambar sejarah juang rakyat lawan jajah monumen pahlawan museum banyak senjata perang merdeka dengar rekam asli suara tomo obar semangat juang arek parkir luas kenang jasa pahlawan tiap iring musik monumen sangat sejarah tempat pusat akses tuju monumen sangat mudah tempat nyaman hampar rumput hijau jadi semua unjung betah sini suka foto swafoto pas banget tempat bagus cocok tempat foto diorama perlu baik dingin ruang perlu rajin cek kunjung komunitas sekolah jadi kurang nyaman kalau sirkulasi udara kurang oke keren tempat spot bagus buat foto museum cerita sejarah tempat kurang dingin ac hanya pakai kipas museum dingin tempat bagus cocok spot foto monumen bagus museum sejarah museum dengar audio tiap situasi indonesia merdeka utama tempat parkir banyak buat olahraga minggu pagi salah satu objek wisata sejarah letak strategis banget segala transportasi umum sedia arah tempat lokasi jalan pahlawan alun alun contong sana diorama kena sejarah rupa monumen wujud hormat juang arek arek khusus juang gugur taruh nyawa merdeka utuh bumi indonesia cinta diorama jelas media bagus banyak spot foto hari minggu seru tunjuk teatrikalnya wisata sejarah bagus swafoto kunjung tugu pahlawan museum rupa wisata sejarah memang perlu laku kenang juang arek arek bawah pimpin toemo hadap sekutu belanda jaman jajah mana kenal peristiwa tempat foto ria lihat museum tinggal tinggal zaman jajah senjata senjata pajang rapi pokok jangan lewat kalau mampir tugu pahlawan museum orang suka nilai sejarah wajib banget sini cocok instagram romantis kalau mungkin cari angin segar banget lihat pandang hijau lapang tugu pahlawan kalau hari sabtu minggu bakal rasa banget hijau haha buat suka keliling wajib banget kesini tempat sekadar jalan jalan kumpul keluarga ajak anak istri tempat parkir luas hari hari minggu pagi misal banyak jual aneka barang baju celana makan minum lumayan lengkap silah langsung cus tugu mungkin taman tambah tempat teduh nyaman monumen tugu pahlawan letak bekas markas polisi militer tugu pahlawan museum puluh msn rupa penting seluruh monumen pasuk museum bawa banyak cerita relief tempel dinding depan enam patung kuningan tokoh juang lihat relief jumpa patung proklamator soekarno hatta pintu masuk enam patung tokoh kenal tempo dulu gubernur suryo tomo keliling tampak mobil kuno senjata patung buah museum juang sini sayang diorama statis rusak rekam jadi istimewa mata tugu pahlawan diri megah salah satu sudut bawah monumen hias ukir trisula gambar stamba padma bagai simbol api juang tugu museum museum puluh diri lantai pamer patung melambang bentuk semangat juang rakyat orasi tomo buah ruang auditorium lantai sedang lantai rupa ruang pamer senjata reproduksi foto foto dokumenter pamer koleksi tinggal tomo ruang diorama saji delapan peristiwa jadi lengkap narasi museum bawah lahan tugu pahlawan meter buat museum olah olah sembul tanah bagus banget tengah tugu pahlawan besar banget bawah biasa buat anak kecil perosot lengkung perosot belakang monumen pahlawan nama keliling kolam ikan banyak samping kiri monumen apa tidak paham museum depan lapang rumput buat segala macam aktivitas kayak keliling lapang bangku kanopi rindang luar keliling tembok pagar bunga riah gapura kanan kiri air mancur kanan luar depan tempat parkir patung pak soekarno hatta baca apa naskah proklamasi kali latar belakang tiang mau runtuh apa bingung jelas haha iya kalau sabtu minggu malam sekarang festival kuliner nusantara tempo dulu indah bagus suka rute bangun museum tata tata letak media tidak cuma lihat barang kuno media audio animasi visual asyik simak bahkan anak bahkan putar film bila jadwal tugu pahlawan museum rupa wisata sejarah lihat juang sini bagai koleksi lihat museum stan souvenir dekat pintu keluar wilayah banyak wisata kuliner salah satu tempat sejarah tugu pahlawan ikut tur bus rumah sampoerna bawa keliling tempat sejarah tur jadi waktu destinasi beda beda pahlawan nih teman teman jelajah dulu sini museum baju perang senjata tomo bahkan rekam pidato tomo depan temu patung sama hatta tengah taman patung walikota pertama masuk museum lantai kasih jalur naik turun stiker eskalator jalur khusus kursi roda haha dingin kalau malam tugu pahlawan tembak lampu warna warni jadi makin keren lampu ubah ubah warna kalo jangan lupa absen dulu sini teman teman akhir tugu pahlawan masuk sini langsung kental suasana sejarah gerbang identik tembok zaman patung bapak wakil pertama latar penuh beberapa patung tokoh penting mobil tomo meriam perang museum museum putar lagu lagu sejarah gitu jadi asa kental banget museum tidak luas tetapi cukup kenal sejarah indonesia lantai isi juang warga rekam pidato tomo lantai khusus tempat senjata perang museum tunjuk drama seni sejarah tetapi jam jam tetapi sayang monitor ruang sedikit ganggu kayak acnya mati anak anak ajak mampir tugu pahlawan museum luar biasa sensasi keliling museum mana dengar pidato tomo bangkit semangat arek arek merinding dengar pandang foto juang bawa hadir luar biasa juang rebut merdeka tepat sebut bagai pahlawan bangsa letak tugu pahlawan pinggir jalan besar sini patung pahlawan mobil tomo tempat luas cocok anak kecil dewasa tugu pahlawan sangat bagus lengkap museum saji film dokumenter sekarang hari sabtu minggu acara asyik tongkrong situ jual aneka jajan jadul harga jangkau hibur musik langsung film dokumenter tampil proyektor asyik sekarang makin bagus tata rapi suara diorama makin jelas namun sayang beberapa diorama suranya mati perlu baik segera kalau kafetaria saji makan minum asli tema kolonial mungkin lebih keren kali letak jantung tempat luas asri museum pustaka masuk gratis parkir mobil puluh ribu kurang mungkin tidak jelas tiap rute jadi baca sendiri dalamanya museum pahlawan luas lantai museum lihat juang pahlawan merdeka indonesia sangat suka sama kelola tempat sejarah rapi awat taman museum datang sini balik masa lalu keren banget kesini wajib banget didatangin pas spotnya bagus buat foto tempat wajib kunjung kalian sering betul kemarin kunjung tempat sebut tempat bagus historikal foto foto banyak spot foto tarik tempat sebut museum hitung lengkap modern tunjuk suara video bagai dukung ornamen juang masa masa sebut wajib kunjung apa momen momen merdeka salah satu tugu bangga khusus timur umum tempat nyaman malam banyak kuliner akses mudah tempat agak panas tetapi kalau melipir tidak panas museum cuma saran kalau jual minum dingin soal gerah haha kemarin cuma air mineral tidak dingin tetapi museum lengkap bagai diorama statis maupun elektronik sangat tarik tahu sejarah tayang film tempur visual efek meta video sangat tarik museum isi lengkap sejarah juang hingga kendara senjata lawan jajah lokasi museum satu kompleks tugu pahlawan jadi nilai tambah unjung lebih kenal sejarah pahlawan tugu pahlawan museum sejarah juang arek arek juang merdeka proklamasi soekarno tahun kalau kunjung museum baik ajak anak anak kenal sejarah juang rakyat indonesia umum juang arek arek khusus bela negara merdeka rasa setel diorama masing ruang lantai enak tidak desak museum dingin banyak spot estetis buat foto jalur lari pelan pelan sini jadi enak pas pagi sini kalau mau olahraga jalan cari tempat buat olahraga jalan kaki haha paling sering aku tugu pahlawan memang selalu pagi memang tuju lari pelan pelan haha kalau emang kunjung siang mending pas hari kerja sekali museum biar dingin haha tempat keren banyak spot foto tempat parkir luas kalau datang hari minggu dada barang bekas baru harga relatif jangkau kadang teatrikal bangsa cuma sempat masuk museum parkir luas saran teman kalau sini enak malam hari tidak panas lampu tugu pas nyala jadi bagus tetapi kalau mau foto bagus siang hari lebih jelas kalau sini wajib banget masuk museum terus bagai artefak jaman jajah dulu seru pokok wajib kesini tugu monumen pahlawan mampir sebentar buat renung arti juang pahlawan tidak rugi foto tarik museum tugu pahlawan tempat kenang juang pahlawan saran generasi terus unjung museum biar rasa suasana juang sana banyak benda tinggal pakai perang lengkap bioskop mini putar video juang sana mobil asli pakai tomo dulu salah satu tempat sejarah monumen jadi saksi juang arek arek hadap tentara sekutu tugu bangun masa soekarno bawah tugu museum isi kisah sejarah jadi baju baju diorama senjata bagai tempat dekat kantor gubernur timur jangan kunjung tengah hari musim kemarau panas luar biasa tidak tempat luar ruang teduh pinggir jalan raya mudah transportasi tuju tempat nyaman luas lengkap teknologi canggih papar jelas sejarah lantai atas museum kantin pendopo cocok santa salah satu tugu jadi ikon simpan banyak sekali cerita sejarah misteri sana tugu bagai tanda hormat pahlawan nama depan pintu masuk patung sang proklamator bangsa indonesia soekarno wakil preseden pertama muh hatta maksud beri hormat mere berani proklamasi bebas jajah waktu iku diorama cerita juang tempo dulu kalau wisata sejarah bagus salah satu sini nih tugu pahlawan tempat bagus tata monumen suka banget sama museum pas banget jujur masuk sini kagum taman rapi luas museum jelas banget film tiap jam lihat kilas kena wajib kalian kunjung kalau teman monumen pahlawan bagus tempat sangat pelihara museum lihat betapa sangat heroik berani sekali pahlawan lawan jajah diorama kena tempur bangga jadi arek berani pertama kali sini tahu lebih banyak peristiwa tugu pahlawan patung pertama soekarno museum bagus lengkap tempat tonton film dokumenter peristiwa pidato tomo fenomenal museum cocok instagram banyak spot bagus foto tempat sejarah buat tempat luas buat jalan jalan pagi sore hari banyak anak main sana museum cerita juang tada bagai macam kendara senjata jaman juang lantai isi banyak tahu juang arek masuk diorama agak seram diorama pas sana sepi tugu sini museum lapang upacara diorama masuk gedung bekas runtuh asli jaman jajah kurang tempat lokasi pintu masuk tidak rambu tunjuk sering unjung luar susah sekali temu pintu masuk monumen area luar bagus tata rapi awat baik tanam bagus bagus banyak tempat duduk tepi kotak tanam manfaat istirahat lihat lihat pandang obrol nikmat suasana museum lokasi belakang tugu pahlawan bawah tanah tetapi sosok atap bangun piramid kaca lihat tonjol atas koleksi museum macam macam mulai pajang barang barang antik senjata pernak pernik penting masa perang tahan merdeka beberapa diorama statis gambar situasi masa diorama terang visual maupun audio sangat informatif interior museum tampak awat baik nilai plus kalau unsur juang gambar video museum modern diorama keren tempat strategis wisata sejarah lihat bangun awat parkir luas sedia beberapa fasilitas dukung musala kantin toilet museum awat barang sejarah tata bagus rapi dengar suara asli tomo museum diri lantai hubung eskalator fungsi baik jalan sore sana tempat luas banget waktu malam hari lampu indah masyarakat lokal kesini bukan hanya tempat sejarah tetapi tempat rekreasi edukasi buat anak dewasa harga jasa pahlawan tempat tempat bagus olahraga taman sejuk rindang tempat cukup luas pemuda indonesia kumpul puluh tahun tidak kunjung kesini nyata jauh lebih bagus sekarang pas suasana sepi jadi lebih spot foto bocor bocor unjung ramah buat anak anak lapang rumput sangat luas kalau siang tidak perlu khawatir panas tempat duduk tutup rekomendasi buat orang tua cari tempat hibur santai bareng keluarga tempat luas kapan sana agak panas waktu diorama tempat enak banget buat kumpul bareng teman tempat ruang rapat lengkap lokasi pojok parkir luas minum enak tidak sesal tempat dingin banyak isi diorama rekam suara tomo durasi menit isi pidato semangat tempur tempat wisata sejarah strategis dekat stasiun stasiun jalan menit tempat sangat luas banyak spot foto bagus museum kecil tetapi informatif fasilitas lumayan lengkap museum kantin dekat pintu keluar museum kecil nyaman wisata sejarah oke banget tugu sejarah kunjung museum tempat sangat luas nikmat sama keluarga duduk santai museum bagus banyak cerita layak tahu utama jadi jadi jangan lupa datang kesini kalau suasana tugu pahlawan sekarang dulu pas aku kecil dulu sekarang sumpah bagus banget anak hibur air mancur buat kesana tadi pagi ramai banget banyak orang olahraga santa lari main bola duduk santai foto sama keluarga luas museum bioskop mini cerita juang pahlawan tempat indah malam hari penuh hias lampu tidak terlalu ramai lalu lintas kopi pinggir jalan foto latar belakang tugu pahlawan monumen tugu pahlawan benda sejarah kena tempur lokasi parkir tugu pahlawan hari sabtu minggu sore hari tjangkroean djoeang bagai macam kuliner khas sini tetapi agak seram patung peragawati lawas lihat jadi seram gitu jelas peristiwa sangat saran tonton bioskop diorama museum hanya sedia hingga jam wib cuma bayar parkir foto buat foto kalau malam walaupun panas lihat tinggal bukti juang pahlawan tahan merdeka indonesia keren buat foto malam omong omong lebih baik main nyata banding aman banget soal gila tempat foto ria lihat museum tinggal tinggal zaman jajah senjata senjata pajang rapi pokok jangan lewat kalau mampir tugu pahlawan museum tetapi museum tidak kalah bagus buat objek foto pokok asyik kalau sana ramai ramai asyik buat foto foto beri edukasi anak anak museum tempat utama buat wisatawan kunjung tiap minggu pagi gelar pagelaran perang ingat hari pahlawan museum bagus sekarang ketimbang dulu dulu tempat sejarah orang malam hari tugu pahlawan lihat warna warni main lampu lanjut mau masuk museum lihat tinggal sejarah juang arek arek ayo anak anak milenial main kesini kesini sekali sekali tidak masalah kalau untung nonton putar film dokumenter jadi awal mau sini ekspektasinya tidak terlalu tinggi paling cuma tetapi nyata sini tidak kecewa sama sekali tempat asyik banyak spot foto bagus akses stasiun kereta dekat lalu jalan kaki lebih asyik lewat titik nol beberapa spot foto lama jalan lokasi jangan lupa bawa minum banyak lokasi cukup luas minim tempat teduh meski banyak pintu masuk jual minum es seluruh bagus sini tidak sesal balik kesini pas waktu monumen sangat sejarah bukti lawan arek arek lawan tentara sekutu banyak bukti bukti sejarah sini masuk museum puluh lihat banyak cerita sejarah bukti sejarah bambu runcing baju radio zaman foto foto masuk museum tempat nonton bareng kisah juang tempat sejarah perlu lestari anak cucu tempat sejuk sehat olahraga tarik buat foto monumen juang arek unjung museum lihat benda sejarah juang video cerita kisah heroik arek tugu pahlawan museum puluh rupa salah satu tempat sejarah penting bikin merinding bangga ajak masa lalu kenang semua peristiwa sejarah waktu zaman jajah museum banyak koleksi koleksi baju benda hari hari aneka senjata masa jajah rebut merdeka indonesia museum sangat rekomendasi kunjung mampir karna letak strategis gampang jangkau monumen sejarah asyik jadi tempat belibur ramah lingkung lokasi strategis fasilitas wc monumen museum museum isi sejarah juang merdeka peristiwa putar sini tanggal desember banyak benda sejarah unjung suguh beberapa napak tilas juang arek arek zaman unjung bebas foto ria spot bagus heroik tempat rekomendasi bawa anak anak mana bagus tumbuh jiwa nasionalisme terus kalau wajib hukum mampir tugu pahlawan berani tugu pahlawan tempat sejarah juang arek arek tugu foto audio juang tempo dulu jangan takut lapar haus dekat pintu keluar museum kantin menu lumayan lengkap harga jangkau museum kantin jual air mineral macam macam buah tangan khas tugu pahlawan penat padat buat masyarakat rasa segar sekarang lepas penat sabtu minggu malam tugu pahlawan banyak orang tidak tahu tugu pahlawan sini museum banyak spot cocok instagram museum awat lengkap jelas gambar video benda tinggal salah satu destinasi wisata sejarah budaya bagus kunjung fasilitas bagus putar film ruang diorama putar rekam suara tomo radio obar semangat juang arek arek ramai penuh musik klasik haha tempat duduk rasa kurang tempat penuh sejarah sini tempat tugu pahlawan tempat tata rapi bersih unjung mudah akses segala butuh kait tempat tugu pahlawan banyak ajar khusus anak tahu sejarah tempat parkir relief juang arek makin tinggal sejarah museum diafragma gambar juang arek masuk museum kenal lebih jauh bagaimana juang arek museum lantai istimewa lantai pertama bawah muka tanah lantai pertama tunjuk bioskop kecil tempur lama menit jam putar lihat tempat kemudian rekam suara tomo pidato ikut putar sedang lantai ruang diorama statik koleksi bagai macam jenis senjata pakai tempur sebut tugu pahlawan drama teatrikal sejarah jadwal lihat tempat bagus bersih banyak benda sejarah rekam suara pahlawan nasional kalau kesini jangan lupa ikut nonton film peristiwa juang patung heroik masuk museum asa waktu peperangan zaman jajah luar negeri tiap minggu pagi sering teaterikal juang arek arek keren tempat bagus sekadar jalan jalan kumpul keluarga ajak anak istri tempat parkir luas hari hari minggu pagi misal banyak jual aneka barang baju celana makan minum monumen tugu pahlawan kunjung memang kalau hari libur agak susah cari tempat parkir foto tetapi sabar aja orang sabar sayang tuhan tempat kenang jasa juang juang arek arek awal masuk relief tembok tembok juang awal masuk taman sambut patung bapak soekarno hatta tengah tengah taman tugu jadi ikonik museum tempat sejarah letak mampu buat kepala kenang zaman merdeka tatanan taman tarik mampu buat hati lirik pose foto situ utama cinta swafoto foto sama tempat spot foto ajar sejarah beberapa patung pahlawan tank area tugu olahraga paket komplit sini bisasambil kenang sejarah juang arek segar foto pandang indah belanja harga miring tetapi kaget cuma hari minggu banyak kayak jomblo niat cari jodoh sini kunjung tugu pahlawan masa lalu tata letak sejarah sangat jelas gambar sini tempat bersih tepat tengah diorama pajang benda benda sejarah masa lalu tata rapi sangat senang jelas diorama perang cukup pencet tunggu audio animasi jelas detail awal sejarah sungguh sangat keren sekali kunjung tepat tanggal luar biasa sekali semangat hari pahlawan mulai kecil banyak orang tua bondong bondong bawa anak kenal keren tempat favorit buru foto lari monumen juang warga tahun sekarang sangat awat museum isi sejarah masa juang main foto bila dekat hari pahlawan biasa macam teatrikal perang lawan belanda seru sekali monumen kenang jasa juang arek arek tahan jajah lapang luas sering jadi bagai upacara panggung teatrikal hari libur minggu jadi tempat kumpul orang orang jalan olahraga sini banyak dagang jual bagai macam butuh pinggir jalan pagi hari wisata tugu pahlawan rupa wisata lengkap unjung tugu pahlawan unjung museum museum bagai jenis senjata mulai bambu runcing ketapel keris pistol hingga senapan bagai asal milik barang barang penting juang tempur buku catat hari tomo seragam arek arek lengkap medis hingga lengkap navigasi perang deskripsi singkat padat tiap benda ilustrasi bagai peristiwa penting beri gambar kait juang pahlawan seluruh warga hadap tempur hingga akhir asai fasilitas umum toilet musala bagus bersih toko cendera mata khas jangan bilang kalau monumen tugu pahlawan museum jarang masuk keluarga tetapi museum bagus jelas sejarah indonesia upa rekam video suara pahlawan merdeka tempat parkir area tugu pahlawan tata rapi museum tugu isi kurang agam ruang audio visual kalah sama museum kapal selam cuma ruang audio visual beberapa tutup pintu masuk pidato tomo suasana museum sepi lagu merdeka dukung buat aura sendiri unjung baik bakal balik kesini insyaallah area museum simpan bagai benda bukti sejarah diorama tempat sangat cocok segala usia bagus wisatawan lokal mancanegara cocok lari pelan pelan minggu pagi sejarah monumen tugu pahlawan bersih taman indah rapi bagus banget buat foto museum ingat juang masa jajah rekomendasi buat jalan museum bangga makin lihat indah megah tarik pesona museum banyak simpan kenang sejarah senjata tempur lawan jajah sini lihat film juang berani arek tahan kemerdekaaan indonesia jamin lihat film jadi bangga jadi arek tempat bagus olahraga santai piknik kalau mau tambah ilmu museum tugu pahlawan banyak spot bagus foto area hijau sangat asri tiap pagi lapang drama teatrikal cukup keren jam buka tepat pukul pagi salah satu tempat wajib kunjung fasilitas cukup lengkap mulai parkir musala bangku taman duduk sini museum sejarah kalau unjung ramai putar video juang tempat nyaman kesini akses ojek online bus wisata sedia tetapi tidak tahu titik kumpul mana mulai pukul berapa rekam jejak semangat juang pahlawan temu sini sekarang museum tata bersih lift lantai beberapa diorama fungsi sayang lift tidak jalan sayang lift tidak jalan museum bagus sekali sangat informatif museum monumen sendiri sangat kagum kamar mandi luar museum sekira dekat tempat parkir sangat jijik bau air ganjil kamar mandi penuh aroma tidak enak buat siapa masuk toilet jadi tidak nyaman objek spot foto sekaligus kenal budaya timur lihat karapan sapi tari singo barong tugu nol depan kantor bupati timur sekaligus bahan tugu pahlawan suasana pagi segar aku suka banget tempat tempat sejarah sekarang sini banyak ikan cantik anak suka banget kasih makan ikan jadi kalau tugu pahlawan jangan lupa bawa pakan ikan sering pakai acara bazar lingkung hijau museum belakang fasilitas cukup lengkap toilet musala intip video salur youtube jalan jalan beda akhir kunjung kesini banyak dinding putih mungkin tempat manfaat beri relief cerita macam gambar peristiwa sekadar masuk salah satu simbol bawah tanah monumen museum lantai wajib kunjung siapa tahu sejarah lawan lapang luas kalau monas cuma versi mini haha syukur bagai generasi muda lihat saksi benda buat bela tanah air lihat tempo dulu mudah an selalu jaga lapang kalau akhir pekan banyak olahraga museum buka jalan luar monumen kalau akhir pekan gitu macam cfd lumayan jalan jalan pagi museum awat baik isi sangat tarik sangat bagus tetapi sayang tradisi pagi hari libur minggu jangan hilang tahu mulai waktu kecil punya anak warga selalu bondong bondong datang pahlawan pagi hari minggu tradisi warga libur belanja tetapi sekarang tidak tiada bu risma bijaksana bukan jual punya lahan situ sekadar unjung bagus tata sistem atur ikon tidak lengkap kalau tidak kesini monumen tugu pahlawan museum isi tarik banget barang barang tinggal zaman kolonial belanda kabar taman tugu pahlawan alun alun utara suka banget kalau ruang bioskop pertama ruang gelap teman takut aku bentur tembok stasiun jalan kaki nikmat riuh banyak sedia kursi taman kalau kunjung sini lebih baik sedia payung topi masker panas sekali jam atas tadi panas banyak spot foto bagus lumayan sejuk dikit kena ac banyak foto foto dokumentasi bangun monumen tugu pahlawan foto dokumentasi juang arek arek lawan jajah barang antik senjata kelola cukup profesional harga tiket cukup murah cukup bagus bagai objek wisata saran kalau tambah pohon biar lebih sejuk ac museum buat lebih dingin kalo kesini paling enak hari minggu pagi ramai banyak jual cfd tetapi kalau malam bagus keren buat foto foto cocok banget buat kunjung wisatawan asing utama museum cocok buat siswa sekolah tambah tahu juang arek arek tempat luas banget museum dingin bagus modern banget pertama kali tempat cuma mau tahu kaya bagaimana tempat bagus banget cocok buat tempat foto tugu pahlawan bukti juang rakyat kenang pahlawan museum sejarah hingga diorama juang bangsa indonesia lawan jajah yakin keluar area bagai terus bangsa mungkin apa apa banding memang juang keras jaga negara mungkin tunjuk parkir kurang agak bingung waktu mau masuk banyak sejarah sini sangat bagus buat kalang anak anak muda biar kenal lebih sana beberapa tempat sangat favorit tempat spot foto sangat bagus museum tidak kalah museum baik sayang sobat ambyar jangan lupa bawa minum agak susah cari jual museum awat sangat baik beberapa minggu lalu teman teman kelas kumpul tugu pahlawan laku foto buku kenang mau foto buku kenang teman teman tidak kena biaya apa kecuali parkir haha tidak lampir surat namun alangkah baik jaga jaga bawa surat saran datang agak pagi kalau siang cuaca sangat panas tugu pahlawan pagi hari banyak dagang makan salah satu sate sate daging ayam rasa enak murah jangan lupa suka kalau ulas bantu tempat rekreasi sejarah bagus museum pustaka museum cukup canggih tidak perlu baca hanya cukup tekan tombol dengar tetapi sayang terlalu panas tidak tahan agak lama museum bagus barang pajang diorama putar film jam jam biasa jam gazebonya kalau capek tiket masuk murah riah penuh tahu buru foto lumayan lihat film dokumenter tahu sejarah juang banyak spot foto bagus sangat riah tambah musik jajan tradisional moga studio diorama selalu buka meski sepi unjung jam operasional sangat gugah pidato tomo putar tiap unjung dengar bagaimana rap pidato gerak juang tempat bersih bagus buat foto foto sangat nyaman buat kumpul jalan jalan lepas penat tempat tepat kalau turis lokal mancanegara main tempat sejarah spot tarik buat foto foto kenal banget tempat banyak orang cari cuma gang tetapi sangat bagus buat foto sini museum sini benar sejarah banget banyak seka ilmu juang pahlawan zaman tempat luas ruang khusus dengar cerita lewat layar lokasi pusat jadi tempat bagai salah satu destinasi wisata cukup kenal ramai kunjung akhir pekan acara penting cukup sering selenggara tempat sedia lokasi parkir tepat depan area wisata monumen sejarah museum lengkap cerita sejarah tempat bersih rapi awat tempat sangat bagus cocok instagram beri banyak tahu baru kena sejarah sejarah tempat bagus banyak jajan zaman kala musik aktif keroncong film zaman pokok mantap malam tugu pahlawan tugu pahlawan tepat depan titik nol timur sini unjung masuk hanya bayar parkir akhir pekan area olahraga main datang hari minggu tempat ramai banyak orang bagus buat santai foto bahkan olahraga lari kalau pas datang malam hari enak sejuk tempat duduk tengah halaman foto bagus banget rapi bersih lapang luas banget spot foto ikon kalau malam kafe angkring depan halaman pintu masuk masuk museum tugu pahlawan lihat diorama dinding museum bawa masa juang arek berswafoto pakai kostum juang pertama kali sini sering lewat tetapi tidak pernah masuk bagus buat foto parkir musala ber ac kamar mandi masuk museum tetapi turut kalau siang panas banget saran pakai pakai tutup pakai payung taman bagus tata rapi banget toilet tua tetapi tetap awat baik musala bersih banget parkir luas tetapi mau kasih saran mohon kasih lebih banyak cahaya serasa remang biasa kalo malam monumen museum kunjung eskalator lift mudah akses unjung koleksi pajang sangat gambar juang arek kala diorama bagus rekomendasi lebih harga jasa pahlawan pagi sore waktu bagus kalau mau foto luar museum museum bagus kutip kutip bakar semangat cinta tanah air tetapi kalau siang panas museum sangat estetik rapi tarik monumen keren pahlawan sini museum bawah tanah isi juang arek perang merdeka spot foto keren banyak sini tempat cukup asri tata tanam indah area monumen sini mobil tomo asli pajang taman area monumen masuk area tugu pahlawan sini unjung lari pelan pelan nikmat pandang sana museum bangun bawah tanah pistol aneka senjata pakai pihak sekutu bambu runcing pamer kotak kaca bentuk piramida tiap sabtu minggu tempat nongkrong bagai macam makan minum tradisional sinom dawet ayu memang jual tidak berapa banyak tidak kumpul sama tempat sejarah parkir mobil motor buat sangat suka tempat monumen puluh masuk sedang tunjuk kolosal bagaimana juang pahlawan indonesia juang merdeka konsep tempat sangat apik perintah sangat perhati tiap detail buat terima kasih perintah tugu pahlawan tempat luas taman jadi sejuk sedap pandang hari minggu pagi jalan protokol bakal ramai jadi pusat dagang kaki lima tempat sangat bagus indah rapi bersih suasana nyaman sekali cocok buat foto tuju wisata tugu pahlawan museum puluh banyak tinggal masa jajah sekarang banyak ubah bentuk bangun namun tetap tinggal selalu awat jaga sekarang putar video kronologi perang cinta kenang tempat asyik libur sama keluarga cocok suka berswafoto apabila siang panas banget tempat parkir susah temu suatu destinasi jadi ikon wisata sejarah lengkap museum murah tarik informatif manfaat tugu pahlawan bagus tempat tepat lam sejarah balik juluk pahlawan isi museum bersih awat lokasi strategis tidak terlalu luas sangat awat tempat hanya saji tugu pahlawan taman keliling luas bersih parkir cocok swafoto sekadar foto museum tempat tinggal sejarah bagus banget desain tempat estetis lengkap sarana tahu sejarah museum kecil tetapi syarat informasi cocok banget buat grup darmawisata jangan lewat sini bukan hanya nikmat taman cantik tugu bangga museum juang rakyat lengkap film dokumenter sungguh kunjung kenal anak cinta tanah air keliling bangun lama sangat awat cantik terimakasih banyak bu risma meski hanya kunjung sangat kagum luar biasa indah sekarang terimakasih warga bantu perintah jaga tugu pahlawan monumen sarana prasarana sangat bagus museum toilet cukup bagus mewah spot spot foto banyak agam wajib jadi salah tuju kalian kalo tidak nyesel jamin mungkin taman tambah tempat teduh nyaman tempat parkir tidak besar banyak orang foto tiap monumen pahlawan beberapa orang foto sentuh patung naik senjata senjata zaman tugu pahlawan buah monumen sengaja bangun hormat jasa pahlawan timur khusus juang arek sana banyak informasi bagaimana juang warga usir jajah sana edukasi juang mulai putar video perang suara asli tomo beliau juang mampu bakar semangat juang usir jajah sana museum simpan benda peperangan ayo kunjung tugu pahlawan taman modernisasi indah sejuk cocok keluarga hari acara teatrikal historikal gelar sini tempat sejarah warga banyak tinggal masa jajah sekarang banyak ubah bentuk bangun namun tetap tinggal selalu awat jaga sekarang putar video kronologi perang cinta kenang isi penuh nilai historis mulai foto jadi patung alat perang film jadi taman bunga parkir luas bersih nyaman tugu pahlawan pahlawan tempat sejarah tempur arek arek lawan jajah tempat sangat strategis mudah lihat tepat tengah tengah area tugu pahlawan diri museum senjata senjata sejarah tempur masa lalu sangat baik kenal generasi terus harga jasa pahlawan tempur gigih juang khusus tidak sumber makan kantin gitu tahu bersih awat luas buah tugu ingat juang arek arek tahan merdeka lawan jajah belanda lukis museum senjata mampu lawan jajah belanda tempat asyik luas cocok buat anak muda masa kini suka foto ajar sejarah paling penting banyak spot foto lihat diorama juang rakyat sama tomo rekam suara bungtomo gera arek arek saran sini hari minggu pagi sangat ramai aktivitas orang olahraga museum tugu pahlawan banyak tinggal masa juang arek arek makam pahlawan tak kenal monumen sejarah bagai koleksi sini museum beberapa patung koleksi mobil letak strategis dekat stasiun buah ruang buka hijau tengah tugu pahlawan sangat sejarah resmi kenang jasa arek arek tempur lawan sekutu pimpin tomo sini patung patung pahlawan gubernur gubernur timur pertama walikota tahun tomo milik nama asli terus taman putar lagu bangsa tambah khidmat nuansa pahlawan bangun sejarah jadi kalau sini agak pagi siang lapang buat foto teduh pinggir lapang alam senang kunjung museum seru eskalator monumen paling kenal hormat jasa pahlawan indonesia gugur juang tahan merdeka indonesia museum bawah mobil tokoh nasional alutsista tahun kembang monumen kelola kembang jadi museum unsur ajar tambah tata cahaya bagus buat kompleks monumen tugu pahlawan jauh lebih indah tempat ramai hari minggu dada pagi hari banyak masyarakat olahraga sini museum tugu pahlawan suguh bagai diorama juang arek rebut merdeka barang tinggal sejarah abadi jejak juang rakyat indonesia wujud negara merdeka sejahtera taman sejuk foto foto bagus sini luar daerah pas siang panas tidak bagus kalau sore tetapi tenang tempat duduk atap jalan besar tidak terlalu ramai tetapi hati menyebrang depan tugu persis kantor gubernur timur coba jalan area situ banyak bangun lawas kalian suka bangun tinggal salah satu ikon enak pakai jalan santai hari sabtu minggu pagi dekat stasiun bersih indah tata toilet bersih awat terima kasih bu risma suka banget sini bagus pandang keren buat foto tempat asyik buat segar wisata sejarah tempat bersih awat parkir lumayan luas tugu pahlawan tupal tempat bagus lapang luas buat olahraga drama kolosal pas hari minggu enak bagus buat libur sayang tidak kantin jadi lapar capai jalan keluar monumen cari makan tempat sangat tarik kunjung milik nilai sejarah sangat tinggi buat merinding rasa bagaimana juang kala akses mudah tempat luas buat unjung sangat nyaman museum bawah tanah bioskop d mini tampil juang pahlawan banyak monumen sejarah tempat lumayan tarik lapanganya luas banyak benda sejarah tinggal zaman juang mulai senjata alat transportasi putar film dokumenter putar beberapa kali hari tidak hanya museum pustaka mini museum mungkin tambah ac kalau kunjung banyak orang asa agak panas sejarah kurang toilet keren banget tambah wawas sejarah banget paling enak kalau sini minta tani bapak pandu biar paham isi apa tempat bagus buat foto foto depan hanya fasilitas tempat parkir kurang enak tugu pahlawan paling tarik perhati museum museum banyak sekali benda benda sejarah apa diorama duh keren banget tempat olahraga sini ajar sejarah anak dewasa sana makam pahlawan tidak kenal monumen sejarah tempat bersih tetap awat diorama putar film dokumenter pendek sejarah dulu datang jajah inggris hingga tembak aws jembatan merah kalian suka sejarah cinta wajib banget tau sejarah semua tuang museum tugu pahlawan senang tempat penuh informasi toilet bersih musala salat semua awat baik diri tugu pahlawan monumen diorama diorama juang arek bela tetapi kurang fasilitas toilet bagai air sering tidak tidak lengkap rasa kunjung lewat tempat sini rupa monumen museum buat ajar bagai pahlawan lokasi jantung beri informasi unjung sejarah juang museum saji diorama alias tiru suasana jadi masa perang arek juang senjata bambu runcing tahan merdeka indonesia pertama kali injak kaki lokasi getar denyut nadi putar pidato akbar tomo peristiwa saksi tinggal sejarah juang arek patung patriotik tegak bendera merah putih tangan kanan tangan kiri lumur darah lihat kawasan tugu pahlawan saksi film visual kena juang rebut indonesia jajah belanda ikut senjata sederhana juang tugu pahlawan masuk destinasi wisata area tugu pahlawan museum juang merdeka segala lengkap perang juang pertama kali kunjung kesini malam hari suasana sepi sekali sedikit orang kunjung tetapi kalau malam malah tugu nyala jadi indah banyak bangku buat duduk duduk nyaman buat nikmat pandang haha tetapi museum panas sekali main wajib mampir tugu pahlawan ikon selamat foto sana jadi sejarah tempat parkir lumayan bersih cukup museum sangat manfaat muda tahu bagaimana juang alat perang bioramanya sangat bantu museum sangat jaga sangat tarik sekali meski baru pertama kali sini rasa sangat kagum diorama museum salah satu museum baik pahlawan rekam suara asli tomo bakar semangat arek arek peperangan lawan pasu inggris tempur tewas jenderal salah orang besar inggris pertama kali sini kagum monumen tengah tengah jalan pahlawan dekat kantor gubernur timur tugu pahlawan rupa salah satu ikon bagai pahlawan masuk banyak orang asyik foto santa ria pandang indah sorot lampu tugu pahlawan monumen realistis bangun baik paling hanya cat tetapi kantin sana sangat minim bahkan kata tidak fasilitas unjung tugu pahlawan salah satu ikon wajib kunjung turut sini sedia bagai ilmu tahu nuansa alam manja mata fasilitas awat tugas bersih tambah rasa nyaman unjung panas saran bawa payung tempat sejarah sini jadi tahu kalau daerah waru nyata sejarah iya sini diorama film sejarah selalu tayang parkir depan lalu masuk lalu taman arah tugu pahlawan lantai banyak sejarah sejarah tampil sana mulai alat perang baju tongkat lihat barang sejarah lihat langsung tinggal pahlawan koleksi sangat lengkap film dokumenter cuman sayang kemarin eskalator mati kata tugas rusak lebih sip beri akses masuk unjung difabel unjung kursi roda cocok buat mau ajar sejarah buat foto bagus hanya dar santa sama keluarga main sama teman bagus kalau waktu hari minggu tumpah jadi museum tugu pahlawan lihat barang panjang jalan olahraga halaman tugu pahlawan kalau masuk museum tahu sejarah arek tempat bagus awat gejolak waktu dengar suara tomo putar museum juang pahlawan bangsa sini banyak sejarah kisah heroik sini bersih awat baik wajib banget kalau datang kesini banyak tempat foto seru sekarang bangun lebih indah elegan bagai ikon penting mungkin penting coba koleksi tambah tempat sangat bagus orang tua remaja maupun anak anak kenang sejarah sini ajar masa lalu foto foto sini banyak tempat foto semua kalang ingat jaga bersih lingkung jangan rusak benda benda sejarah sana cuma lampu depan pintu masuk kurang terang tempat baru suasana asyik tengah mana sana benda benda sejarah tempat sejarah punya banyak tempat kunjung museum lapang luas patung pahlawan tahu sejarah indonesia tempat sangat sejarah banyak tempat foto bagus museum risi sejarah perang merdeka kolam ikan museum taman jadi main kasih makan ikan kantin dekat pintu keluar museum tempat sejarah tugu pahlawan bagus foto foto ruang main anak anak segera tugu pahlawan punya sikap nasionalisme monumen bangga arek arek bagai bentuk wujud jati diri simbol pahlawan bagai pahlawan monumen makin hari makin tarik tata pugar moles bangun unsur unsur lengkap museum makin jadi monumen tugu pahlawan jadi makin hidup milik jiwa terimakasih banyak walikota selaku pegang bijak buat tugu pahlawan hingga jadi lihat nikmat sekarang terus perhati tidak lupa jasa pahlawan beri buah korban tidak ukur materi hingga semua jadi sekarang bagus wisata semua umur banyak tinggal sejarah jaman juang bagus buat ajar sejarah mantap buat jalan aja mantap buat anak main air tempat sangat bagus wisata edukasi berswafoto rekomendasi banget kalau cuma jarang orang jual makan jadi repot kala lapar bagus pandang cocok buang libur tumbuh hijau tugu pahlawan ikonik banget museum museum bahas detail peristiwa banyak diorama film dokumenter tarik banget sangat tambah tahu soal sejarah keren lanjut biar generasi muda datang tidak lupa sejarah bangsa sendiri iring waktu jalan teatrikal macam film hanya hari minggu sesuai minta kalau rombong rekomendasi sekali film keren waktu malam hari lihat lampu warna warni sayang halaman atas kurang tunjuk informasi monumen luas koleksi lumayan lengkap kalau akhir pekan banyak acara sini suka sejarah datang sini tempat cukup nyaman orang tua guru pupuk generasi suka sejarah bangsa suka pergi museum kalau kesini waktu teatrikal foto bareng main keliling tumpah tiap hari minggu nikmat kuliner tempat wisata sejarah kalau pagi hari minggu cocok tempat olahraga kalau kesini siang hari jangan lupa bawa payung cuaca panas aku pernah kesini moga kesini kalau suasana malam banyak lampu bagus banget moga suatu sana sekali cuci mata siapa tahu ketemu jodoh orang tempat foto bagus senang sini tempat histori kenang jasa pahlawan museum sarana wisata manfaat anak keluarga bagus banget tempat sejarah bagus tempat foto diorama musikal diorama statis banyak ikan bersih rapi awat bagai tempat sejarah juang pahlawan nasional indonesia seru buat kunjung fotografi tetap jaga asli nyaman oke sayang diorama hanya hari minggu sayang diorama hanya hari minggu cari lahan parkir susah akses masuk tidak segala arah salah satu tempat wajib kunjung waktu museum bagus diorama benda sejarah banyak tempat nyaman tempat luas cuma panas waktu kesana sangat suka tempat banyak tinggal sejarah sini kalau siang tugu pahlawan panas lapang dingin ac tiap minggu buka umum cocok buat olahraga jalan jalan bareng keluarga museum simpan beberapa tinggal peristiwa kalau museum prosedur biar gratis bonus putar diorama elektronik keren hampir mirip sama bioskop tiga dimensi keren banget mending kesana waktu pagi sore kalau malam tambah banyak lampu sayang kalau sana waktu jam an panas buat tidak kuat banyak giat sini museum lapang luas banyak acara rekreasi cuma lampu lampu kurang terang hasil foto bagus tempat seru banyak tempat foto tarik tempat enak buat jalan kitar taman tugu jarak parkir tuju pintu masuk museum cukup jauh jalan kaki lima menit monumen tugu museum lantai simpan sejarah arek arek lawan belanda ramai utama hari sabtu minggu sabtu minggu area ramai banyak dagang kaki lima jual bagai macam museum bagus tata keren jadi makin betah liat paling suka lihat film juang arek arek tempat sejarah warga indonesia warga khusus tempat simpan banyak sejarah juang pahlawan tugu pahlawan museum sejarah juang pahlawan tempat banyak kunjung wisatawan lokal mancanegara tempat nyaman banyak taman fasilitas lengkap toilet musala tempat informasi minggu pagi cocok buat lari sini sama teman keluarga awat baik parkir sedang taman bagus tempat lumayan luas tempat wisata area kelola baik area bersih bagus banget buat foto tugu pahlawan salah satu tempat wisata sangat layak kunjung wisatawan fasilitas lumayan lengkap museum diorama statis sangat takjub fasilitas kamar mandi musala bersih tempat parkir cukup luas museum halaman hijau taman awat interior museum modern wisata sejarah bagus swafoto monumen tugu pahlawan monumen kenang juang arek lawan jajah lokasi depan kantor gubernur timur lapang luas monumen tinggi bentuk paku balik lokasi sebut museum diorama tugu pahlawan tidak hanya tugu patung proklamator tetapi museum juang arek arek bawah monumen mobil tomo sangat tarik salah satu tempat wajib kunjung kalau monumen tugu pahlawan lihat sejarah indonesia lengkap diorama suara pilih bahasa sedia sangat rapi bersih awat patung soekarno hatta tiang belakang sangat artistik sayang daerah sini panas kalau siang sini foto tahu sejarah paling jadi pusat perhati puncak tugu tugu pahlawan museum akses masyarakat banyak koleksi zaman jajah simpan museum tempat mana kamu semua saksi simbol simbol pahlawan arek seluruh pemuda indonesia pernah datang tempur habis an waktu tarik kunjung museum tiga dimensi gambar sejarah bangsa tempat sejarah tempur arek arek kolonial belanda inggris luar biasa tempat nyaman indah museum putar film ruang bawah tanah banyak jual makan murah riah tugu pahlawan bersih nyaman buat olahraga kesini betul pas malam hari makan kuliner kenal monumen pahlawan bebek monumen pahlawan seberang jalan suasana cenderung sepi padahal kira sangat ramai monumen sangat kenal hanya beberapa orang sedang santa foto foto bebas masuk lihat lebih dekat tampak monumen pahlawan kalau mau sini waktu siang pandang bangun bangun kawasan jelas lebih bagus tiap sudut benar tidak jelajah banyak hanya beberapa titik patung patung pahlawan bangun tinggi tengah tengah rasa kalau malam malah lihat monas jauh tetapi alam pertama kunjung sangat kes lihat megah awat keren bangun kurang teduh mungkin monumem juang arek arek patut kenang juang merdeka hormat bangsa negara indonesia tanah lapang luas kalau hari minggu hari libur banyak giat olahraga maupun rekreasi keluarga area tugu pahlawan museum letak bawah tanah museum lihat sejarah juang arek arek lihat sejarah tempo salah satu ikon kurang lengkap datang lihat megah monumen tugu juang arek lawan jajah sini santa kumpul sama keluarga hari minggu monumen sangat ramai jual komunitas unjung nikmat hari libur fasilitas lengkap museum lapang hijau luas sini lokasi strategis pintu masuk utama pintu masuk cocok suka swafoto suka keliling tempat wisata monumen juang sejarah arek arek museum sejarah juang tahan diri jajah kolonial belanda lokasi hendak tempat parkir luas kelola museum profesional awat rumput tanam hias bagus monumen sejarah sini lihat saksi saksi bisu merdeka republik indonesia keliling tempat banyak gedung gedung sejarah kokoh tempat museum tempat keluarga nyaman luas santai tugu pahlawan rupa buah monumen paling kenal monumen letak jalan pahlawan punya tinggi lebih meter bentuk sepet paku balik tugu pahlawan buat atas lahan luas lebih hektar ingat hormat seluruh prajurit gugur perang lawan jajah bawah tanah tugu pahlawan museum isi foto foto dokumentasi kalau minggu pagi lapang buat olahraga monumen sejarah juang arek arek sangat bagus museum lihat gambar bagaimana juang rakyat waktu tempat bagus buat swafoto wisatawan lengkap kunjung kalau singgah sini museum tugu pahlawan letak jalan pahlawan seberang kantor gubernur jatim rupa museum diri kenang tempur arek lawan jajah buah area bagai gedung adil tinggi masa jajah belanda bagai kantor kempetai polisi militer jajah ambil alih juang lalu tempur sengit jadi markas juang arek namun sayang markas gempur pasu sekutu mana tempur tewas jenderal rupa jenderal pihak sekutu museum diorama tempur letak m tanah tempat wisata rapi luas cocok segala usia minggu pagi jadi tempat paling enak kunjung sarap murah belanja perlu hari murah olahraga lapang tugu cocok keluarga tempat sangat rekomendasi desain arsitek modern banyak alat tempur nama nama pahlawan kontribusi tugu bangga timur luas kolam ikan museum juang modern parkir luas strategis dekat bank indonesia enak buat ajak keluarga sini lapang luas rumput nyaman salah satu destinasi wisata tuju wisatawan domestik mancanegara museum tugu pahlawan salah satu tempat ikonik beberapa tinggal sejarah diorama cerita sejarah juang kunjung monumen jadi ikon tinggi monumen meter letak tengah tepat jalan pahlawan tugu pahlawan taman saran kesini hari minggu pagi samping banyak dagang kaki lima ramai jadi olahraga jalan jalan sekaligus belanja tempat tepat habis akhir pekan sama keluarga masuk serasa rasa ikut bawa suasana jaman perang bayang apa cara pakai benda apa bayang betapa semangat bela bangsa indonesia libur manfaat ganda laku museum tugu pahlawan konsep tawar sangat agam mulai taman tempat foto bagai macam tinggal sejarah tempur tidak hanya unjung suguh aneka aroma statis narasi cerita tinggal dengar gedung bioskop kemas unik jelas konsep tawar modern bukan museum banyak museum putar film tempat sejarah paling penting kurang lengkap kunjung tetapi tidak mampir swafoto tugu pahlawan bagus sekali sayang beberapa fasilitas ruang tidak manfaat sedang baik museum isi senjata sepeda miniatur hubung tempur tempat tata rapi tempat nyaman tempat toilet sangat parkir luas tempat keren banyak barang barang sejarah diorama diorama museum taman bagus jadi tempat foto fasilitas kurang banyak baik tempat enak sepi walaupun tengah kurang kemarin waktu kunjung eskalator mati kasihan orang tua naik turun tangga tempat sejarah wajib kunjung libur lokasi monumen mudah temu banyak kendara umum lewat jalan tugu pahlawan monumen cukup mudah akses kendara umum maupun pribadi titik nol cantik asli waktu malam hari pakai ponsel waktu sesi foto tugu pahlawan pernah jadi tempat shalawat akbar kata tiba tiba milik dorong pergi toilet pergi toilet kelola tidak sedia tisu toilet tidak masalah sabun cuci tangan tidak bahkan tidak air keran sini tidak tempat parkir bingung cari tempat parkir bukan orang situ panas tempat panas kalau datang siang museum kurang ac panas lihat beberapa kisah kisah pahlawan milik harap besar tempat tetapi kecewa lumayan buat rute jalan hari minggu salah satu rute tuju favorit sepeda foto foto tiap hari minggu kaget hanya hari minggu pagi banyak jual baju macam macam makan museum pahlawan isi diorama area buka sering pakai acara rapat umum kurang atur perlu baik kawasan lihat drama juang arek alat perang sisa merdeka bagus ramai unjung cocok buat olahraga nama museum fasilitas kurang perlu lebih banyak fasilitas parkir susah unjung banyak makan sedikit bagus buat ajar sejarah sana museum buat swafoto bagus museum isi patung juang merdeka hingga aksesoris merdeka dulu fasilitas wilayah mungkin kurang tunjuk lokasi fasilitas umum awat baik parkir ribet waktu pulang tempat jalan jalan pagi olahraga luar ruang awat lokasi kurang asyik buat foto foto sulit cari parkir mobil akhir kali kunjung acnya tidak cukup dingin kadang sangat panas capai c sistem suara dengar sangat buruk treble terlalu tinggi cukup oke kelola sedia tempat parkir luar museum hari sabtu minggu malam jadi orang datang lihat tjangkroean djoeang datang sulit parkir lebih baik kunjung transportasi umum datang pagi sore hari hindar panas matahari siang jadi temu sudut baik tempat gagal bunuh bosan suka bagaimana hias taman tempat butuh lebih banyak fasilitas lindung unjung panas siang hari kecewa tidak tempat foto kostum pahlawan jadi nilai sendiri terlalu panas lebih banyak vegetasi monumen tunjuk juang indonesia merdeka relief dinding patung sangat panas butuh dingin ruang sini tempat lapang monumen patung pertama wakil indonesia tambah sedikit sejarah tulis dinding\n"
     ]
    }
   ],
   "source": [
    "#import library dan data yang dibutuhkan\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "def join(text):\n",
    "  text = text.replace('[','')\n",
    "  text = text.replace(']','')\n",
    "  text = text.replace(',','')\n",
    "  text = text.replace(\"'\",\"\")\n",
    "  return text\n",
    "\n",
    "df = pd.read_excel('aspekFasilitas.xlsx')\n",
    "# komentar['clean'] = komentar['final preprocessing'].apply(lambda x: join(x))\n",
    "komentar = pd.DataFrame()\n",
    "komentar['final'] = df['final preprocessing']\n",
    "komentar['clean'] = df['final preprocessing'].apply(lambda x: join(x))\n",
    "komentar.head()\n",
    "\n",
    "#mendefinisikan dan menyimpan data pada variabel\n",
    "# words = []\n",
    "# words = komentar['clean'].tolist() #menyimpan data list komentar\n",
    "kalimat = komentar['clean'].str.cat(sep=' ')\n",
    "print(kalimat)\n",
    "# kalimat = kalimat.split() #menyimpan data komentar yang ditokenisasi\n",
    "# print(kalimat)\n",
    "\n",
    "#mendefinisikan fungsi hitung score tiap kata\n",
    "def freq(text):\n",
    "  str = []\n",
    "  for i in text:\n",
    "    if i not in str:\n",
    "      str.append(i)\n",
    "  scoreList = {'word' : [], 'score' : []}\n",
    "  for i in range(0,len(str)):\n",
    "    scoreList['word'].append(str[i])\n",
    "    scoreList['score'].append(text.count(str[i]))\n",
    "  rankedList = []\n",
    "  rankedList = scoreList\n",
    "  return rankedList\n",
    "\n",
    "# rankedList = freq(kalimat)\n",
    "# data = pd.DataFrame(rankedList)\n",
    "# print(data)\n",
    "# data.sort_values(by=['score'], ascending = False).head()\n",
    "\n",
    "#mendefinisikan fungsi untuk menghapus kata yang sama dalam satu komentar\n",
    "def cleanSentence(text):\n",
    "  text = text.split()\n",
    "  str = []\n",
    "  for i in text:\n",
    "    if i not in str:\n",
    "      str.append(i)\n",
    "  text = \" \".join(str)\n",
    "  return text\n",
    "\n",
    "# komentar['text'] = komentar['clean'].apply(lambda x: cleanSentence(x))\n",
    "# komentar.head()\n",
    "\n",
    "#mendefinisikan fungsi untuk menghitung score komentar\n",
    "def sentenceScore(text):\n",
    "  score = 0\n",
    "  text = text.split()\n",
    "  for t in text:\n",
    "    for i in range(0,len(data)):\n",
    "      if t == data.iloc[i][0]:\n",
    "        score += data.iloc[i][1]\n",
    "        break;\n",
    "  score = score/len(text)\n",
    "  return score\n",
    "\n",
    "# komentar['score']=komentar['text'].apply(lambda x: sentenceScore(x))\n",
    "# komentar.to_csv('commentScore.csv',encoding='utf-8')\n",
    "# komentar.head()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iJ2Wlj-lO97J"
   },
   "source": [
    "## TF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "FHy7SAG_7JmP"
   },
   "outputs": [],
   "source": [
    "#import library dan data yang dibutuhkan\n",
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "all_datas = {\n",
    "    \"Umum\" : {},\n",
    "    \"Kebersihan\" : {},\n",
    "    \"Edukasi\" : {},\n",
    "    \"Pelayanan\" : {},\n",
    "    \"Fasilitas\" : {},\n",
    "}\n",
    "\n",
    "def join(text):\n",
    "  text = text.replace('[','')\n",
    "  text = text.replace(']','')\n",
    "  text = text.replace(',','')\n",
    "  text = text.replace(\"'\",\"\")\n",
    "  return text\n",
    "\n",
    "#mendefinisikan fungsi untuk menghapus kata yang sama dalam satu komentar\n",
    "def duplicateDrop(kalimat):\n",
    "  kalimat = kalimat.split()\n",
    "  temp = []\n",
    "  for i in kalimat:\n",
    "    if i not in temp:\n",
    "      temp.append(i)\n",
    "  kalimat = \" \".join(temp)\n",
    "  return kalimat\n",
    "\n",
    "#mendefinisikan fungsi untuk menghitung score komentar\n",
    "def calculateScore(kalimat, unigram):\n",
    "  score = 0\n",
    "  kalimat = kalimat.split()\n",
    "  for t in kalimat:\n",
    "    for i in range(0,len(unigram)): #wordcount dilooping\n",
    "      if t == unigram.iloc[i][0]: #\n",
    "        score += unigram.iloc[i][1]\n",
    "        break;\n",
    "  score = score/len(kalimat)\n",
    "  return score\n",
    "\n",
    "for key, val in all_datas.items():\n",
    "  df = pd.read_excel(f'aspek{key}.xlsx')\n",
    "  df_negatif = pd.DataFrame()\n",
    "  df_netral = pd.DataFrame()\n",
    "  df_positif = pd.DataFrame()\n",
    "  df_negatif['ulasan'] = df[df['label'] == 'negatif']['formal-trans']\n",
    "  df_netral['ulasan'] = df[df['label'] == 'netral']['formal-trans']\n",
    "  df_positif['ulasan'] = df[df['label'] == 'positif']['formal-trans']\n",
    "  df_negatif['preprocessing'] = df[df['label'] == 'negatif']['final preprocessing'].apply(lambda x: join(x))\n",
    "  df_netral['preprocessing'] = df[df['label'] == 'netral']['final preprocessing'].apply(lambda x: join(x))\n",
    "  df_positif['preprocessing'] = df[df['label'] == 'positif']['final preprocessing'].apply(lambda x: join(x))\n",
    "\n",
    "  cv_negatif = CountVectorizer()\n",
    "  cv_netral = CountVectorizer()\n",
    "  cv_positif = CountVectorizer()\n",
    "  cv_fit_negatif=cv_negatif.fit_transform(df_negatif['preprocessing'])\n",
    "  cv_fit_netral=cv_netral.fit_transform(df_netral['preprocessing'])\n",
    "  cv_fit_positif=cv_positif.fit_transform(df_positif['preprocessing'])\n",
    "\n",
    "  unigram_negatif = pd.DataFrame(data={\n",
    "      \"kata\" : cv_negatif.get_feature_names(), \n",
    "      \"jumlah\" : cv_fit_negatif.toarray().sum(axis=0)\n",
    "  })\n",
    "  unigram_netral = pd.DataFrame(data={\n",
    "      \"kata\" : cv_netral.get_feature_names(), \n",
    "      \"jumlah\" : cv_fit_netral.toarray().sum(axis=0)\n",
    "  })\n",
    "  unigram_positif = pd.DataFrame(data={\n",
    "      \"kata\" : cv_positif.get_feature_names(), \n",
    "      \"jumlah\" : cv_fit_positif.toarray().sum(axis=0)\n",
    "  })\n",
    "\n",
    "  df_negatif['text'] = df_negatif['preprocessing'].apply(lambda x: duplicateDrop(x))\n",
    "  df_netral['text'] = df_netral['preprocessing'].apply(lambda x: duplicateDrop(x))\n",
    "  df_positif['text'] = df_positif['preprocessing'].apply(lambda x: duplicateDrop(x))\n",
    "\n",
    "  df_negatif['score'] = df_negatif['text'].apply(lambda x: calculateScore(x, unigram_negatif))\n",
    "  df_netral['score'] = df_netral['text'].apply(lambda x: calculateScore(x, unigram_netral))\n",
    "  df_positif['score'] = df_positif['text'].apply(lambda x: calculateScore(x, unigram_positif))\n",
    "\n",
    "  df_negatif.to_excel(f'komen_terbanyak_{key}_negatif_mean.xlsx',encoding='utf-8' )\n",
    "  df_netral.to_excel(f'komen_terbanyak_{key}_netral_mean.xlsx',encoding='utf-8' )\n",
    "  df_positif.to_excel(f'komen_terbanyak_{key}_positif_mean.xlsx',encoding='utf-8' )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "J4B8sgFkPDw2"
   },
   "source": [
    "## debugging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "YczlMDMZA9XI",
    "outputId": "9957972a-b338-4947-adcd-dbdedc49f206"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['agak', 'air', 'area', 'aroma', 'atas', 'bagaimana', 'bahkan', 'banget', 'bau', 'buang', 'buat', 'cuci', 'dekat', 'depan', 'dorong', 'enak', 'ganjil', 'halo', 'harap', 'indonesia', 'jadi', 'jijik', 'kamar', 'kata', 'kelola', 'keran', 'kotor', 'kurang', 'lebih', 'luar', 'mandi', 'masalah', 'masuk', 'milik', 'moga', 'monumen', 'mungkin', 'museum', 'namun', 'nih', 'nyaman', 'pahlawan', 'parkir', 'pas', 'peduli', 'penuh', 'pergi', 'perhati', 'rindang', 'sabun', 'sama', 'sampah', 'sangat', 'satu', 'sayang', 'sedia', 'segera', 'sejarah', 'sekira', 'sembarang', 'sepi', 'siapa', 'sini', 'suka', 'tangan', 'teman', 'tempat', 'temu', 'tiba', 'tidak', 'tisu', 'toilet', 'unjung']\n"
     ]
    }
   ],
   "source": [
    "#import library dan data yang dibutuhkan\n",
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "def join(text):\n",
    "  text = text.replace('[','')\n",
    "  text = text.replace(']','')\n",
    "  text = text.replace(',','')\n",
    "  text = text.replace(\"'\",\"\")\n",
    "  return text\n",
    "\n",
    "#mendefinisikan fungsi untuk menghapus kata yang sama dalam satu komentar\n",
    "def cleanSentence(text):\n",
    "  text = text.split()\n",
    "  str = []\n",
    "  for i in text:\n",
    "    if i not in str:\n",
    "      str.append(i)\n",
    "  text = \" \".join(str)\n",
    "  return text\n",
    "\n",
    "#mendefinisikan fungsi untuk menghitung score komentar\n",
    "def sentenceScore(text, wc):\n",
    "  score = 0\n",
    "  text = text.split()\n",
    "  for t in text:\n",
    "    for i in range(0,len(data)):\n",
    "      if t == wc.iloc[i][0]:\n",
    "        score += wc.iloc[i][1]\n",
    "        break;\n",
    "  score = score/len(text)\n",
    "  return score\n",
    "\n",
    "df = pd.read_excel(f'aspekKebersihan.xlsx')\n",
    "df_negatif = pd.DataFrame()\n",
    "df_negatif['ulasan'] = df[df['label'] == 'negatif']['final preprocessing'].apply(lambda x: join(x))\n",
    "df_negatif['ulasan'] = df_negatif['ulasan'].apply(lambda x: str(x))\n",
    "df_negatif['token'] = df_negatif['ulasan'].apply(lambda x: str(x).split())\n",
    "\n",
    "cv_negatif = CountVectorizer(lowercase=False)\n",
    "cv_fit_negatif=cv_negatif.fit_transform(df_negatif['ulasan'])\n",
    "print(cv_negatif.get_feature_names())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2UKaXU_CDbLC",
    "outputId": "162d223c-60a7-492a-80db-150a95282a62"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['hello', 'there', 'guys']\n"
     ]
    }
   ],
   "source": [
    "kal = \"hello there guys\"\n",
    "print(kal.split())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rsoeXg3vx30u"
   },
   "source": [
    "## 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8UbsCpVux5sa"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "df = pd.read_excel(\"\").rename(columns = {'Unnamed: 0': 'id'})\n",
    "df_negatif = df[df['label'] == 'negatif']\n",
    "df_netral = df[df['label'] == 'netral']\n",
    "df_positif = df[df['label'] == 'positif']\n",
    "\n",
    "df_negatif['process'] = df_negatif['final preprocessing'].apply(lambda x: join(x))\n",
    "df_netral['process'] = df_netral['final preprocessing'].apply(lambda x: join(x))\n",
    "df_positif['process'] = df_positif['final preprocessing'].apply(lambda x: join(x))\n",
    "\n",
    "cv_negatif = CountVectorizer()\n",
    "cv_netral = CountVectorizer()\n",
    "cv_positif = CountVectorizer()\n",
    "cv_fit_negatif=cv_negatif.fit_transform(df_negatif['process'])\n",
    "cv_fit_netral=cv_netral.fit_transform(df_netral['process'])\n",
    "cv_fit_positif=cv_positif.fit_transform(df_positif['process'])\n",
    "unigram_negatif = pd.DataFrame(data={\"kata\" : cv_negatif.get_feature_names(), \"jumlah\" : cv_fit_negatif.toarray().sum(axis=0)})\n",
    "unigram_netral = pd.DataFrame(data={\"kata\" : cv_netral.get_feature_names(), \"jumlah\" : cv_fit_netral.toarray().sum(axis=0)})\n",
    "unigram_positif = pd.DataFrame(data={\"kata\" : cv_positif.get_feature_names(), \"jumlah\" : cv_fit_positif.toarray().sum(axis=0)})\n",
    "\n",
    "unigram_negatif.to_excel(\"unigram_negatif.xlsx\", encoding='utf-8', index=False)\n",
    "unigram_netral.to_excel(\"unigram_netral.xlsx\", encoding='utf-8', index=False)\n",
    "unigram_positif.to_excel(\"unigram_positif.xlsx\", encoding='utf-8', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NdMxpuVjyA44"
   },
   "source": [
    "## 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1bvWRuoCyCdg"
   },
   "outputs": [],
   "source": [
    "#import library dan data yang dibutuhkan\n",
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "def join(text):\n",
    "  text = text.replace('[','')\n",
    "  text = text.replace(']','')\n",
    "  text = text.replace(',','')\n",
    "  text = text.replace(\"'\",\"\")\n",
    "  return text\n",
    "\n",
    "#mendefinisikan fungsi untuk menghapus kata yang sama dalam satu komentar\n",
    "def cleanSentence(text):\n",
    "  text = text.split()\n",
    "  str = []\n",
    "  for i in text:\n",
    "    if i not in str:\n",
    "      str.append(i)\n",
    "  text = \" \".join(str)\n",
    "  return text\n",
    "\n",
    "#mendefinisikan fungsi untuk menghitung score komentar\n",
    "def sentenceScore(text, wc):\n",
    "  score = 0\n",
    "  text = text.split()\n",
    "  for t in text:\n",
    "    for i in range(0,len(wc)): #wordcount dilooping\n",
    "      if t == wc.iloc[i][0]: #\n",
    "        score += wc.iloc[i][1]\n",
    "        break;\n",
    "  score = score/len(text)\n",
    "  return score\n",
    "\n",
    "df = pd.read_excel(\"\")\n",
    "df_negatif = pd.DataFrame()\n",
    "df_netral = pd.DataFrame()\n",
    "df_positif = pd.DataFrame()\n",
    "df_negatif['ulasan'] = df[df['label'] == 'negatif']['formal-trans']\n",
    "df_netral['ulasan'] = df[df['label'] == 'netral']['formal-trans']\n",
    "df_positif['ulasan'] = df[df['label'] == 'positif']['formal-trans']\n",
    "df_negatif['preprocessing'] = df[df['label'] == 'negatif']['final preprocessing'].apply(lambda x: join(x))\n",
    "df_netral['preprocessing'] = df[df['label'] == 'netral']['final preprocessing'].apply(lambda x: join(x))\n",
    "df_positif['preprocessing'] = df[df['label'] == 'positif']['final preprocessing'].apply(lambda x: join(x))\n",
    "\n",
    "cv_negatif = CountVectorizer()\n",
    "cv_netral = CountVectorizer()\n",
    "cv_positif = CountVectorizer()\n",
    "cv_fit_negatif=cv_negatif.fit_transform(df_negatif['preprocessing'])\n",
    "cv_fit_netral=cv_netral.fit_transform(df_netral['preprocessing'])\n",
    "cv_fit_positif=cv_positif.fit_transform(df_positif['preprocessing'])\n",
    "unigram_negatif = pd.DataFrame(data={\"kata\" : cv_negatif.get_feature_names(), \"jumlah\" : cv_fit_negatif.toarray().sum(axis=0)})\n",
    "unigram_netral = pd.DataFrame(data={\"kata\" : cv_netral.get_feature_names(), \"jumlah\" : cv_fit_netral.toarray().sum(axis=0)})\n",
    "unigram_positif = pd.DataFrame(data={\"kata\" : cv_positif.get_feature_names(), \"jumlah\" : cv_fit_positif.toarray().sum(axis=0)})\n",
    "\n",
    "df_negatif['text'] = df_negatif['preprocessing'].apply(lambda x: cleanSentence(x))\n",
    "df_netral['text'] = df_netral['preprocessing'].apply(lambda x: cleanSentence(x))\n",
    "df_positif['text'] = df_positif['preprocessing'].apply(lambda x: cleanSentence(x))\n",
    "\n",
    "df_negatif['score'] = df_negatif['text'].apply(lambda x: sentenceScore(x, unigram_negatif))\n",
    "df_netral['score'] = df_netral['text'].apply(lambda x: sentenceScore(x, unigram_netral))\n",
    "df_positif['score'] = df_positif['text'].apply(lambda x: sentenceScore(x, unigram_positif))\n",
    "\n",
    "df_negatif.to_excel('komen_terbanyak_negatif_mean.xlsx',encoding='utf-8' )\n",
    "df_netral.to_excel('komen_terbanyak_netral_mean.xlsx',encoding='utf-8' )\n",
    "df_positif.to_excel('komen_terbanyak_positif_mean.xlsx',encoding='utf-8' )"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [
    "va8Bo3SPml__",
    "eCO-mpMkmgbx",
    "vq0M_zS9n-ye",
    "2P0mNwz1oOij",
    "38daivjnoRHv",
    "4Sd_FfhWodQo",
    "Sne6PMZHofnB",
    "_Zz6aU8sowMG",
    "qrsx9-CwWC9m",
    "WyPX3nUM5xax",
    "Mu_d-50u8hoI",
    "Yef_lSRiVBVp",
    "F1qdrVTmWsry",
    "kb54xCSVUmQJ",
    "kdpxBZZz4FZe",
    "AjUEcoXtxdYz",
    "014iXhYz6lEh",
    "G6KkiqLNcEKY",
    "D9gsuNLdamTP",
    "UURIXj8kr7rb",
    "1ER3SdxTr-gj",
    "KHDyE33zmeI4",
    "rVAGReS0sDm0",
    "GT10f-UXsGjK"
   ],
   "name": "workspace_skripsi.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
